{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "578fe4b4",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2aa2247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import ToTensor\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ad7356",
   "metadata": {},
   "source": [
    "## File paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5adfe821",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = 'output'\n",
    "img_folder = 'eccv_18_all_images_sm'\n",
    "\n",
    "cis_test_ann_path = 'eccv_18_annotation_files/cis_test_annotations.json'\n",
    "cis_val_ann_path = 'eccv_18_annotation_files/cis_val_annotations.json'\n",
    "train_ann_path = 'eccv_18_annotation_files/train_annotations.json'\n",
    "trans_test_ann_path = 'eccv_18_annotation_files/trans_test_annotations.json'\n",
    "trans_val_ann_path = 'eccv_18_annotation_files/trans_val_annotations.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2abcf0",
   "metadata": {},
   "source": [
    "## Basic data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c31db297",
   "metadata": {},
   "outputs": [],
   "source": [
    "cis_test_ann = json.load(open(cis_test_ann_path))\n",
    "cis_val_ann = json.load(open(cis_val_ann_path))\n",
    "train_ann = json.load(open(train_ann_path))\n",
    "trans_test_ann = json.load(open(trans_test_ann_path))\n",
    "trans_val_ann = json.load(open(trans_val_ann_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a366a2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cis test set length: 15827\n",
      "cis val set length: 3484\n",
      "train set length: 13553\n",
      "trans test set length: 23275\n",
      "trans val set length: 1725\n"
     ]
    }
   ],
   "source": [
    "print('cis test set length:', len(cis_test_ann['images']))\n",
    "print('cis val set length:', len(cis_val_ann['images']))\n",
    "print('train set length:', len(train_ann['images']))\n",
    "print('trans test set length:', len(trans_test_ann['images']))\n",
    "print('trans val set length:', len(trans_val_ann['images']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6514f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = random.randint(0, len(train_ann['images'])-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2da375d",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.random.choice(range(len(train_ann['images'])), 1000)\n",
    "images = [train_ann['images'][i] for i in index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c4514c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_test_ann.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e398d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_test_ann['info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08de553f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ann['images'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0f6ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_val_ann['images'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43731239",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ann['images'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181f2075",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cis_test_ann['images'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934b6bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cis_test_ann['images'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f689394f",
   "metadata": {},
   "source": [
    "## Horizontal flip debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b8385d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.random.choice(range(len(train_ann['images'])), 1000)\n",
    "images = [train_ann['images'][i] for i in index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed3d8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3\n",
    "print(trans_test_ann['images'][i])\n",
    "img_path = os.path.join('eccv_18_all_images_sm', trans_test_ann['images'][i]['file_name']) # to change\n",
    "\n",
    "image = read_image(img_path)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(image[0].squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7885c147",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "boxes = [trans_test_ann['annotations'][j]['bbox'] for j in range(len(trans_test_ann['annotations'])) \n",
    "         if trans_test_ann['annotations'][j]['image_id']==trans_test_ann['images'][i]['id'] \n",
    "         and 'bbox' in trans_test_ann['annotations'][j].keys()]\n",
    "\n",
    "img_path = os.path.join('eccv_18_all_images_sm', trans_test_ann['images'][i]['file_name']) # to change\n",
    "\n",
    "image = read_image(img_path)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(image[0].squeeze(), cmap='gray')\n",
    "\n",
    "scale_x = image.shape[2] / trans_test_ann['images'][i]['width'] \n",
    "scale_y = image.shape[1] / trans_test_ann['images'][i]['height']\n",
    "\n",
    "boxes = torch.as_tensor(boxes)\n",
    "\n",
    "for i in range(boxes.shape[0]):\n",
    "    boxes[i][0] = torch.round(boxes[i][0] * scale_x)\n",
    "    boxes[i][1] = torch.round(boxes[i][1] * scale_y)\n",
    "    boxes[i][2] = torch.round(boxes[i][2] * scale_x)\n",
    "    boxes[i][3] = torch.round(boxes[i][3] * scale_y)\n",
    "\n",
    "    boxes[i][2] = boxes[i][0] + boxes[i][2]\n",
    "    boxes[i][3] = boxes[i][1] + boxes[i][3]\n",
    "\n",
    "target = {}\n",
    "target[\"boxes\"] = boxes\n",
    "\n",
    "rect = patches.Rectangle((boxes[0][0], boxes[0][1]), boxes[0][2]-boxes[0][0], \n",
    "                         boxes[0][3]-boxes[0][1], linewidth=2, edgecolor='r', facecolor='none')\n",
    "ax.add_patch(rect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07ea727",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979432fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "image2 = Image.open(img_path).convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa230744",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8da8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image2.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ad2d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = torchvision.transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd17529b",
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height = image2.size[0], image2.size[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecea1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('width:', width)\n",
    "print('height:', height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b72c905",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_new = conv(image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8503db0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('image_new.shape:', image_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f62458",
   "metadata": {},
   "source": [
    "## Utils part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badbc9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In paper :  ' ... and employ horizontal flipping for data augmentation. ( for detection)\n",
    "\n",
    "import transforms as T   # from local files (from github repo)\n",
    "\n",
    "data_transform = {'train': T.RandomHorizontalFlip(0.5)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11229c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a list with the idx of images with at least one bounding box (img_wbbox) and a \n",
    "# list with the number of bbox for each valid image (num_bbox)\n",
    "def get_img_with_bbox(file_path):\n",
    "  \n",
    "    file = json.load(open(file_path))\n",
    "    img_wbbox = []\n",
    "    num_bbox = []\n",
    "\n",
    "    for i in range(len(file['images'])):\n",
    "        bboxes = [file['annotations'][j]['bbox'] \n",
    "                  for j in range(len(file['annotations'])) \n",
    "                  if file['annotations'][j]['image_id']==file['images'][i]['id'] \n",
    "                  and 'bbox' in file['annotations'][j].keys()]\n",
    "\n",
    "        if len(bboxes)!=0:\n",
    "            img_wbbox.append(i)\n",
    "\n",
    "            num_bbox.append(len(bboxes))\n",
    "\n",
    "    return img_wbbox, num_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b474765c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, label_path, img_dir, valid_img, transform = None, target_transform=None):\n",
    "        self.label_file = json.load(open(label_path))\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.valid_img = valid_img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_img)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        idx = self.valid_img[idx] # consider only images with bbox annotations\n",
    "        img_path = os.path.join(self.img_dir, self.label_file['images'][idx]['file_name'])\n",
    "        image = read_image(img_path)\n",
    "\n",
    "        conv = torchvision.transforms.ToTensor()\n",
    "        # if image.shape[0]==1:\n",
    "        # some images have only one channel, we convert them to rgb\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        image = conv(image)\n",
    "\n",
    "        boxes = [self.label_file['annotations'][j]['bbox'] \n",
    "                 for j in range(len(self.label_file['annotations'])) \n",
    "                 if self.label_file['annotations'][j]['image_id']==self.label_file['images'][idx]['id']]\n",
    "        \n",
    "        label = [self.label_file['annotations'][j]['category_id'] \n",
    "                 for j in range(len(self.label_file['annotations'])) \n",
    "                 if self.label_file['annotations'][j]['image_id']==self.label_file['images'][idx]['id']]\n",
    "\n",
    "        # transform bbox coords to adjust for resizing\n",
    "        scale_x = image.shape[2] / self.label_file['images'][idx]['width'] \n",
    "        scale_y = image.shape[1] / self.label_file['images'][idx]['height']\n",
    "\n",
    "        boxes = torch.as_tensor(boxes)\n",
    "        for i in range(boxes.shape[0]):\n",
    "            boxes[i][0] = torch.round(boxes[i][0] * scale_x)\n",
    "            boxes[i][1] = torch.round(boxes[i][1] * scale_y)\n",
    "            boxes[i][2] = torch.round(boxes[i][2] * scale_x)\n",
    "            boxes[i][3] = torch.round(boxes[i][3] * scale_y)\n",
    "\n",
    "            boxes[i][2] = boxes[i][0] + boxes[i][2] # to transform to pytorch bbox format\n",
    "            boxes[i][3] = boxes[i][1] + boxes[i][3]\n",
    "\n",
    "            #boxes[i][0]*=scale_x\n",
    "            #boxes[i][1]*=scale_y\n",
    "            #boxes[i][2]*=scale_x\n",
    "            #boxes[i][3]*=scale_y\n",
    "\n",
    "        label=torch.as_tensor(label)\n",
    "        label=torch.where(label==30,0,1)  # 0 if empty (categ id = 30), 1 if animal\n",
    "        image_id = torch.tensor([idx])\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        iscrowd = torch.zeros((boxes.shape[0],), dtype=torch.int64)\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = label\n",
    "        target[\"image_id\"] = image_id\n",
    "        target['area']=area\n",
    "        target['iscrowd']=iscrowd\n",
    "\n",
    "        # TO DO : resize all to same size\n",
    "\n",
    "        if self.transform:\n",
    "            # transform image AND target\n",
    "            image, target = self.transform(image, target)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c6d6a7",
   "metadata": {},
   "source": [
    "## Exemple of use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d141254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the images bounding boxes *takes about 25sec*\n",
    "train_valid_img,_ = get_img_with_bbox(train_ann_path)\n",
    "cis_val_valid_img,_ = get_img_with_bbox(cis_val_ann_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bb69fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = CustomImageDataset(train_ann_path, img_folder, train_valid_img)\n",
    "valid_data = CustomImageDataset(cis_val_ann_path, img_folder, cis_val_valid_img)\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=1, shuffle=True, collate_fn=utils.collate_fn)\n",
    "\n",
    "# In paper : ' We use a batch size of 1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72456c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "#print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Target (Bbox) batch shape: {train_labels[0]['boxes'].size()}\")\n",
    "print(f\"Target (category) batch shape: {train_labels[0]['labels'].size()}\")\n",
    "\n",
    "img = train_features[0][0].squeeze()\n",
    "label = train_labels[0]['labels']\n",
    "label_categ='animal'\n",
    "\n",
    "if label[0]==0:\n",
    "    label_categ='background'\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(img,cmap=\"gray\")\n",
    "rect = patches.Rectangle((train_labels[0]['boxes'][0][0], train_labels[0]['boxes'][0][1]), train_labels[0]['boxes'][0][2]-train_labels[0]['boxes'][0][0], train_labels[0]['boxes'][0][3]-train_labels[0]['boxes'][0][1], linewidth=2, edgecolor='r', facecolor='none')\n",
    "ax.add_patch(rect)\n",
    "print(f\"Label: {label_categ}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f70a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = data_transform['train']\n",
    "img2, target2 = trans(image, target)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(img2, cmap=\"gray\")\n",
    "\n",
    "rect = patches.Rectangle((target2['boxes'][0][0], target2['boxes'][0][1]), \n",
    "                         target2['boxes'][0][2] - target2['boxes'][0][0], \n",
    "                         target2['boxes'][0][3] - target2['boxes'][0][1], \n",
    "                         linewidth=2, edgecolor='r', facecolor='none')\n",
    "ax.add_patch(rect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c22061",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e5990b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imported logs - format: name = \"NAME_OR_TIME\"      Exemple file format: \"NAME_OR_TIME_train_logs\"\n",
    "\n",
    "file_time_or_nickname = '25_roi' # VALUE TO CHANGE TO THE IMPORTED FILES\n",
    "\n",
    "# Import training logs\n",
    "with open('saved_logs/' + file_time_or_nickname + '_train_logs.json', \"r\") as f:\n",
    "    train_logs = train_logs + json.load(f)\n",
    "\n",
    "# Import cis valid logs\n",
    "with open('saved_logs/' + file_time_or_nickname + '_cis_valid_logs.json', \"r\") as f:\n",
    "    cis_valid_logs = cis_valid_logs + json.load(f)\n",
    "\n",
    "# Import trans valid logs\n",
    "with open('saved_logs/' + file_time_or_nickname + '_trans_valid_logs.json', \"r\") as f:\n",
    "    trans_valid_logs = trans_valid_logs + json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f7b48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imported logs - format: name = \"NAME_OR_TIME\"      Exemple file format: \"NAME_OR_TIME_train_logs\"\n",
    "\n",
    "file_time_or_nickname = '10_roi' # VALUE TO CHANGE TO THE IMPORTED FILES\n",
    "\n",
    "# Import training logs\n",
    "with open('saved_logs/' + file_time_or_nickname + '_train_logs.json', \"r\") as f:\n",
    "    train_logs = json.load(f)\n",
    "\n",
    "# Import cis valid logs\n",
    "with open('saved_logs/' + file_time_or_nickname + '_cis_valid_logs.json', \"r\") as f:\n",
    "    cis_valid_logs = json.load(f)\n",
    "\n",
    "# Import trans valid logs\n",
    "with open('saved_logs/' + file_time_or_nickname + '_trans_valid_logs.json', \"r\") as f:\n",
    "    trans_valid_logs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bdd94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_logs = train_logs_to_lst(last_train_logs)\n",
    "cis_valid_logs = valid_logs_to_lst(last_cis_valid_logs)\n",
    "trans_valid_logs = valid_logs_to_lst(last_trans_valid_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d14c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To confirm that the data is loaded properly\n",
    "len(train_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c9c4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train loss to print (here we use global_avg but we can use: value, median, avg, max or global_avg)\n",
    "results_train_loss = []\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    results_train_loss.append(train_logs[i]['loss_box_reg']['global_avg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd48d09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cis valid loss to print\n",
    "results_cis_valid_loss = [] # cis\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    loss_interm = 0\n",
    "    for j in range(167):\n",
    "        loss_interm += cis_valid_logs[(167 * i) + j]['loss_box_reg']\n",
    "    results_cis_valid_loss.append(loss_interm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cee486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e2fdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_logs_0_9 = [train_logs[i]['loss_box_reg'] for i in range(0, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a457e103",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_logs_10_25 = [train_logs[i]['loss_box_reg']['global_avg'] for i in range(10, 25)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3467fafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_logs = train_logs_0_9 + train_logs_10_25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4df23df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "x = np.array([[[1,2,3],\n",
    "               [3,4,5],\n",
    "               [5,6,7]],\n",
    "              [[5,6,7],\n",
    "               [7,8,9],\n",
    "               [9,0,1]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2accc5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "i,j,k = x.shape\n",
    "\n",
    "xx = x.reshape(i,j*k).T\n",
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87e973f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([[[8,7,6],\n",
    "               [6,5,4],\n",
    "               [4,3,2]],\n",
    "              [[4,3,2],\n",
    "               [2,1,0],\n",
    "               [0,1,2]]])\n",
    "\n",
    "\n",
    "yy = y.reshape(i,j*k).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2120ec1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdist(xx,yy,'mahalanobis')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244167d8",
   "metadata": {},
   "source": [
    "## Plots with data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ba4141",
   "metadata": {},
   "source": [
    "## Logs utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935c870f",
   "metadata": {},
   "source": [
    "#### Train logs utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd32d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a676c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the smoothed values to a dictionnary of each values\n",
    "def smoothed_value_to_str(smoothed_value):\n",
    "    d_values = {}\n",
    "    d_values['median'] = smoothed_value.median\n",
    "    d_values['avg'] = smoothed_value.avg\n",
    "    d_values['global_avg'] = smoothed_value.global_avg\n",
    "    d_values['max'] = smoothed_value.max\n",
    "    d_values['value'] = smoothed_value.value\n",
    "    return d_values\n",
    "\n",
    "\n",
    "# Converts the train logs from MetricLogger to list\n",
    "def train_logs_to_lst(logs):\n",
    "    lst = []\n",
    "    for i in range(len(logs)):\n",
    "        d = {}\n",
    "        for key in logs[i].meters.keys():\n",
    "            d[key] = smoothed_value_to_str(logs[i].meters[key])\n",
    "        lst.append(d)\n",
    "    return lst\n",
    "\n",
    "\n",
    "# Puts the training logs into a json file with time dependent file name\n",
    "def train_logs_to_json(logs, ftime=time.strftime(\"%Y%m%d_%H%M%S\")):\n",
    "    train_metric_logs = train_logs_to_lst(logs)\n",
    "    filename = ftime + \"_train_logs.json\"\n",
    "    \n",
    "    with open('saved_logs/' + filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(train_metric_logs, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1712a89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the train logs from MetricLogger to list\n",
    "def train_logs_to_lst(logs):\n",
    "    lst = []\n",
    "    for i in range(len(logs)):\n",
    "        d = {}\n",
    "        for key in logs[i].meters.keys():\n",
    "            d[key] = smoothed_value_to_str(logs[i].meters[key])\n",
    "        lst.append(d)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9df588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puts the training logs into a json file with time dependent file name\n",
    "def train_logs_to_json(logs, ftime=time.strftime(\"%Y%m%d_%H%M%S\")):\n",
    "    train_metric_logs = train_logs_to_lst(logs)\n",
    "    filename = ftime + \"_train_logs.json\"\n",
    "    \n",
    "    with open('saved_logs/' + filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(train_metric_logs, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177f5843",
   "metadata": {},
   "source": [
    "#### Valid logs utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85601550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dicts of a list \n",
    "def merge_dict(logs):\n",
    "    logs_better = []\n",
    "    try:\n",
    "        for i in range(len(logs)):\n",
    "            logs_better.append({**logs[i][0], **logs[i][1], **logs[i][2], **logs[i][3]})\n",
    "        return logs_better\n",
    "    except:\n",
    "        print(logs[0])\n",
    "        logs_better = logs\n",
    "        return logs_better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7e2604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the valid logs from list of dictionnaries to string\n",
    "# TODO: add if type == list to not do anything if its already a list\n",
    "def valid_logs_to_lst(valid_logs):\n",
    "    logs = merge_dict(valid_logs)\n",
    "    lst = []\n",
    "    for i in range(len(logs)):\n",
    "        d = {}\n",
    "        for key in logs[i].keys():\n",
    "            d[key] = logs[i][key].cpu().numpy().tolist()\n",
    "        lst.append(d)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313c943d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puts the cis validation logs into a json file with time dependent file name\n",
    "def cis_valid_logs_to_json(logs, ftime=time.strftime(\"%Y%m%d_%H%M%S\")):\n",
    "    valid_metric_logs = valid_logs_to_lst(logs)\n",
    "    filename = ftime + \"_cis_valid_logs.json\"\n",
    "    \n",
    "    with open('saved_logs/' + filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(valid_metric_logs, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a439bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puts the trans validation logs into a json file with time dependent file name\n",
    "def trans_valid_logs_to_json(logs, ftime=time.strftime(\"%Y%m%d_%H%M%S\")):\n",
    "    valid_metric_logs = valid_logs_to_lst(logs)\n",
    "    filename = ftime + \"_trans_valid_logs.json\"\n",
    "    \n",
    "    with open('saved_logs/' + filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(valid_metric_logs, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849085e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c3a0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS TO TUNE BEFORE TRAINING\n",
    "num_epochs = 25\n",
    "\n",
    "# CHECK DEVICE BEFORE TRAINING\n",
    "# torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7777021",
   "metadata": {},
   "source": [
    "## Looking at/Loading the logs in convenient ways\n",
    "Here we define the variables \"train_logs\", \"cis_valid_logs\" and \"trans_valid_logs\" that will be used in the methods for the results and the visualisations.\n",
    "\n",
    "We can import logs or use the ones from training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15decee1",
   "metadata": {},
   "source": [
    "### OPTIONAL - Can load some logs right here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb72e3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imported logs - format: name = \"NAME_OR_TIME\"      Exemple file format: \"NAME_OR_TIME_train_logs\"\n",
    "\n",
    "file_time_or_nickname = '50_rpn_roi_2' # VALUE TO CHANGE TO THE IMPORTED FILES\n",
    "\n",
    "# Import training logs\n",
    "with open('saved_logs/' + file_time_or_nickname + '_train_logs.json', \"r\") as f:\n",
    "    train_logs = json.load(f)\n",
    "\n",
    "# Import cis valid logs\n",
    "with open('saved_logs/' + file_time_or_nickname + '_cis_valid_logs.json', \"r\") as f:\n",
    "    cis_valid_logs = json.load(f)\n",
    "\n",
    "# Import trans valid logs\n",
    "with open('saved_logs/' + file_time_or_nickname + '_trans_valid_logs.json', \"r\") as f:\n",
    "    trans_valid_logs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d701d19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imported logs - format: name = \"NAME_OR_TIME\"      Exemple file format: \"NAME_OR_TIME_train_logs\"\n",
    "\n",
    "file_time_or_nickname = '75_rpn_roi_1' # VALUE TO CHANGE TO THE IMPORTED FILES\n",
    "\n",
    "# Import training logs\n",
    "with open('saved_logs/' + file_time_or_nickname + '_train_logs.json', \"r\") as f:\n",
    "    train_logs = train_logs + json.load(f)\n",
    "\n",
    "# Import cis valid logs\n",
    "with open('saved_logs/' + file_time_or_nickname + '_cis_valid_logs.json', \"r\") as f:\n",
    "    cis_valid_logs = cis_valid_logs + json.load(f)\n",
    "\n",
    "# Import trans valid logs\n",
    "with open('saved_logs/' + file_time_or_nickname + '_trans_valid_logs.json', \"r\") as f:\n",
    "    trans_valid_logs = trans_valid_logs + json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e85e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To confirm that the data is loaded properly\n",
    "len(train_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2700fe49",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = len(train_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789cd180",
   "metadata": {},
   "outputs": [],
   "source": [
    "cis_valid_logs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5128b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train loss to print (here we use global_avg but we can use: value, median, avg, max or global_avg)\n",
    "results_train_loss = []\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    results_train_loss.append(train_logs[i]['loss_box_reg']['global_avg'])\n",
    "    \n",
    "# Cis valid loss to print\n",
    "results_cis_valid_loss = [] # cis\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    loss_interm = 0\n",
    "    for j in range(167):\n",
    "        loss_interm += cis_valid_logs[(167 * i) + j]['loss_rpn_box_reg']\n",
    "    results_cis_valid_loss.append(loss_interm)\n",
    "\n",
    "# Trans valid loss to print\n",
    "results_trans_valid_loss = [] # cis\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    loss_interm = 0\n",
    "    for j in range(154):\n",
    "        loss_interm += trans_valid_logs[(154 * i) + j]['loss_rpn_box_reg']\n",
    "    results_trans_valid_loss.append(loss_interm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b6e3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the different plots\n",
    "fig, ax = plt.subplots(1,2, figsize=(20,6))\n",
    "\n",
    "ax[0].plot(np.arange(1, num_epochs + 1), results_train_loss, label='train')\n",
    "ax[0].set_title('Train loss per epoch')\n",
    "ax[0].set_ylabel('loss_box_reg')\n",
    "ax[0].set_xlabel('epoch')\n",
    "\n",
    "plt.title('Train loss per epoch')\n",
    "ax[1].plot(np.arange(1, num_epochs + 1), results_cis_valid_loss, label='cis')\n",
    "ax[1].plot(np.arange(1, num_epochs + 1), results_trans_valid_loss, label='trans')\n",
    "ax[1].set_title('Valid loss per epoch')\n",
    "ax[1].set_ylabel('loss_rpn_box_reg')\n",
    "ax[1].set_xlabel('epoch')\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519a1950",
   "metadata": {},
   "source": [
    "#### Save the figure to pdf format in the figures folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce24f5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"figures/\" + time.strftime(\"%Y%m%d_%H%M%S\") + \"_figure.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60560b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"figures/full_75_rpn_roi_1_figure.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599a3310",
   "metadata": {},
   "source": [
    "## Table to show results (manually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515f1909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RPN + ROI\n",
    "cis_results = [0.863, 0.895, 0.897]\n",
    "trans_results = [0.781, 0.794, 0.785]\n",
    "delta_results = [cis_results[i]-trans_results[i] for i in range(len(cis_results))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301ce1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RPN + ROI: Printing the different plots\n",
    "fig, ax = plt.subplots(1,2, figsize=(20,6))\n",
    "\n",
    "ax[0].plot(np.arange(1, len(cis_results) + 1), cis_results, label='cis')\n",
    "ax[0].plot(np.arange(1, len(trans_results) + 1), trans_results, label='trans')\n",
    "ax[0].axhline(y=0.7, c=\"white\")\n",
    "ax[0].set_title('Average precision over number of epochs')\n",
    "ax[0].set_ylabel('Average precision @IoU=0.50')\n",
    "ax[0].set_xlabel('epoch')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(np.arange(1, len(cis_results) + 1), delta_results,'r', label='train')\n",
    "ax[1].axhline(y=0.05, c=\"white\")\n",
    "ax[1].set_title('Difference in average precision over number of epochs')\n",
    "ax[1].set_ylabel('Difference in average precision')\n",
    "ax[1].set_xlabel('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345d038e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2996d024",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddb863b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(1, 3 + 1), cis_results, label='xd')\n",
    "plt.bar(np.arange(1, 3 + 1), trans_results)\n",
    "plt.title('Precision over number of epochs')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba0aebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base vs roi vs roi+rpn\n",
    "cis_results = [0.863, 0.895, 0.897]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c23c3d",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db89b6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imported logs - format: name = \"NAME_OR_TIME\"      Exemple file format: \"NAME_OR_TIME_train_logs\"\n",
    "\n",
    "file_time_or_nickname = '25_base' # VALUE TO CHANGE TO THE IMPORTED FILES\n",
    "\n",
    "# Import training logs\n",
    "with open('saved_logs/' + file_time_or_nickname + '_train_logs.json', \"r\") as f:\n",
    "    train_base = json.load(f)\n",
    "\n",
    "# Import cis valid logs\n",
    "with open('saved_logs/' + file_time_or_nickname + '_cis_valid_logs.json', \"r\") as f:\n",
    "    cis_base = json.load(f)\n",
    "\n",
    "# Import trans valid logsw\n",
    "with open('saved_logs/' + file_time_or_nickname + '_trans_valid_logs.json', \"r\") as f:\n",
    "    trans_base = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66adc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imported logs - format: name = \"NAME_OR_TIME\"      Exemple file format: \"NAME_OR_TIME_train_logs\"\n",
    "\n",
    "file_time_or_nickname = '25_roi_4_vision_version_diff' # VALUE TO CHANGE TO THE IMPORTED FILES\n",
    "\n",
    "# Import training logs\n",
    "with open('saved_logs/' + file_time_or_nickname + '_train_logs.json', \"r\") as f:\n",
    "    train_roi = json.load(f)\n",
    "\n",
    "# Import cis valid logs\n",
    "with open('saved_logs/' + file_time_or_nickname + '_cis_valid_logs.json', \"r\") as f:\n",
    "    cis_roi = json.load(f)\n",
    "\n",
    "# Import trans valid logs\n",
    "with open('saved_logs/' + file_time_or_nickname + '_trans_valid_logs.json', \"r\") as f:\n",
    "    trans_roi = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d4ce57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imported logs - format: name = \"NAME_OR_TIME\"      Exemple file format: \"NAME_OR_TIME_train_logs\"\n",
    "\n",
    "file_time_or_nickname = '25_rpn_roi_1' # VALUE TO CHANGE TO THE IMPORTED FILES\n",
    "\n",
    "# Import training logs\n",
    "with open('saved_logs/' + file_time_or_nickname + '_train_logs.json', \"r\") as f:\n",
    "    train_rpn_roi = json.load(f)\n",
    "\n",
    "# Import cis valid logs\n",
    "with open('saved_logs/' + file_time_or_nickname + '_cis_valid_logs.json', \"r\") as f:\n",
    "    cis_rpn_roi = json.load(f)\n",
    "\n",
    "# Import trans valid logs\n",
    "with open('saved_logs/' + file_time_or_nickname + '_trans_valid_logs.json', \"r\") as f:\n",
    "    trans_rpn_roi = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a60d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base\n",
    "results_train_loss_base = []\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    results_train_loss_base.append(train_base[i]['loss_box_reg']['global_avg'])\n",
    "    \n",
    "# Cis valid loss to print\n",
    "results_cis_valid_loss_base = [] # cis\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    loss_interm = 0\n",
    "    for j in range(167):\n",
    "        loss_interm += cis_base[(167 * i) + j]['loss_box_reg']\n",
    "    results_cis_valid_loss_base.append(loss_interm)\n",
    "\n",
    "# Trans valid loss to print\n",
    "results_trans_valid_loss_base = [] # trans\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    loss_interm = 0\n",
    "    for j in range(154):\n",
    "        loss_interm += trans_base[(154 * i) + j]['loss_box_reg']\n",
    "    results_trans_valid_loss_base.append(loss_interm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef93ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roi\n",
    "results_train_loss_roi = []\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    results_train_loss_roi.append(train_roi[i]['loss_box_reg']['global_avg'])\n",
    "    \n",
    "# Cis valid loss to print\n",
    "results_cis_valid_loss_roi = [] # cis\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    loss_interm = 0\n",
    "    for j in range(167):\n",
    "        loss_interm += cis_roi[(167 * i) + j]['loss_box_reg']\n",
    "    results_cis_valid_loss_roi.append(loss_interm)\n",
    "\n",
    "# Trans valid loss to print\n",
    "results_trans_valid_loss_roi = [] # trans\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    loss_interm = 0\n",
    "    for j in range(154):\n",
    "        loss_interm += trans_roi[(154 * i) + j]['loss_box_reg']\n",
    "    results_trans_valid_loss_roi.append(loss_interm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df68b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rpn+roi\n",
    "results_train_loss_rpn_roi = []\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    results_train_loss_rpn_roi.append(train_rpn_roi[i]['loss_box_reg']['global_avg'])\n",
    "    \n",
    "# Cis valid loss to print\n",
    "results_cis_valid_loss_rpn_roi = [] # cis\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    loss_interm = 0\n",
    "    for j in range(167):\n",
    "        loss_interm += cis_rpn_roi[(167 * i) + j]['loss_box_reg']\n",
    "    results_cis_valid_loss_rpn_roi.append(loss_interm)\n",
    "\n",
    "# Trans valid loss to print\n",
    "results_trans_valid_loss_rpn_roi = [] # trans\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    loss_interm = 0\n",
    "    for j in range(154):\n",
    "        loss_interm += trans_rpn_roi[(154 * i) + j]['loss_box_reg']\n",
    "    results_trans_valid_loss_rpn_roi.append(loss_interm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bd169f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Printing the different plots\n",
    "fig, ax = plt.subplots(1,2, figsize=(14,4))\n",
    "\n",
    "ax[0].plot(np.arange(1, num_epochs + 1), results_train_loss_base, label='base')\n",
    "ax[0].plot(np.arange(1, num_epochs + 1), results_train_loss_roi, label='roi')\n",
    "ax[0].plot(np.arange(1, num_epochs + 1), results_train_loss_rpn_roi, label='rpn+roi')\n",
    "ax[0].set_title('Train loss per epoch')\n",
    "ax[0].set_ylabel('loss_box_reg')\n",
    "ax[0].set_xlabel('epoch')\n",
    "ax[0].legend()\n",
    "\n",
    "plt.title('Train loss per epoch')\n",
    "ax[1].plot(np.arange(1, num_epochs + 1), results_cis_valid_loss_base, label='cis', color='tab:blue')\n",
    "ax[1].plot(np.arange(1, num_epochs + 1), results_trans_valid_loss_base, label='trans', color='tab:red')\n",
    "ax[1].plot(np.arange(1, num_epochs + 1), results_cis_valid_loss_roi, color='tab:blue')\n",
    "ax[1].plot(np.arange(1, num_epochs + 1), results_trans_valid_loss_roi, color='tab:red')\n",
    "ax[1].plot(np.arange(1, num_epochs + 1), results_cis_valid_loss_rpn_roi, color='tab:blue')\n",
    "ax[1].plot(np.arange(1, num_epochs + 1), results_trans_valid_loss_rpn_roi, color='tab:red')\n",
    "ax[1].set_title('Valid loss per epoch')\n",
    "ax[1].set_ylabel('loss_box_reg')\n",
    "ax[1].set_xlabel('epoch')\n",
    "ax[1].legend()\n",
    "\n",
    "ax[0].spines['top'].set_visible(False)\n",
    "ax[0].spines['right'].set_visible(False)\n",
    "ax[1].spines['top'].set_visible(False)\n",
    "ax[1].spines['right'].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb995807",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"figures/baseline_vs_roi_vs_rpn_roi_training.png\", transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709c2541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cis valid loss to print\n",
    "results_cis_valid_loss_base = [] # cis\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    loss_interm = 0\n",
    "    for j in range(167):\n",
    "        loss_interm += cis_base[(167 * i) + j]['loss_rpn_box_reg']\n",
    "    results_cis_valid_loss_base.append(loss_interm)\n",
    "\n",
    "# Trans valid loss to print\n",
    "results_trans_valid_loss_base = [] # trans\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    loss_interm = 0\n",
    "    for j in range(154):\n",
    "        loss_interm += trans_base[(154 * i) + j]['loss_rpn_box_reg']\n",
    "    results_trans_valid_loss_base.append(loss_interm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dfa177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cis valid loss to print\n",
    "results_cis_valid_loss_roi = [] # cis\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    loss_interm = 0\n",
    "    for j in range(167):\n",
    "        loss_interm += cis_roi[(167 * i) + j]['loss_rpn_box_reg']\n",
    "    results_cis_valid_loss_roi.append(loss_interm)\n",
    "\n",
    "# Trans valid loss to print\n",
    "results_trans_valid_loss_roi = [] # trans\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    loss_interm = 0\n",
    "    for j in range(154):\n",
    "        loss_interm += trans_roi[(154 * i) + j]['loss_rpn_box_reg']\n",
    "    results_trans_valid_loss_roi.append(loss_interm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ba42ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cis valid loss to print\n",
    "results_cis_valid_loss_rpn_roi = [] # cis\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    loss_interm = 0\n",
    "    for j in range(167):\n",
    "        loss_interm += cis_rpn_roi[(167 * i) + j]['loss_rpn_box_reg']\n",
    "    results_cis_valid_loss_rpn_roi.append(loss_interm)\n",
    "\n",
    "# Trans valid loss to print\n",
    "results_trans_valid_loss_rpn_roi = [] # trans\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    loss_interm = 0\n",
    "    for j in range(154):\n",
    "        loss_interm += trans_rpn_roi[(154 * i) + j]['loss_rpn_box_reg']\n",
    "    results_trans_valid_loss_rpn_roi.append(loss_interm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3531f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(7,4))\n",
    "\n",
    "plt.title('Train loss per epoch')\n",
    "ax.plot(np.arange(1, num_epochs + 1), results_cis_valid_loss_base, label='cis', color='tab:blue')\n",
    "ax.plot(np.arange(1, num_epochs + 1), results_trans_valid_loss_base, label='trans', color='tab:red')\n",
    "ax.plot(np.arange(1, num_epochs + 1), results_cis_valid_loss_roi, color='tab:blue')\n",
    "ax.plot(np.arange(1, num_epochs + 1), results_trans_valid_loss_roi, color='tab:red')\n",
    "ax.plot(np.arange(1, num_epochs + 1), results_cis_valid_loss_rpn_roi, color='tab:blue')\n",
    "ax.plot(np.arange(1, num_epochs + 1), results_trans_valid_loss_rpn_roi, color='tab:red')\n",
    "ax.set_title('Valid loss per epoch')\n",
    "ax.set_ylabel('loss_rpn_box_reg')\n",
    "ax.set_xlabel('epoch')\n",
    "ax.legend()\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0ab632",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"figures/baseline_vs_roi_vs_rpn_roi_training_rpn.png\", transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ee113c",
   "metadata": {},
   "source": [
    "# Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ecc2ae",
   "metadata": {},
   "source": [
    "### Different depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647275aa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(10,4))\n",
    "\n",
    "# Create bars\n",
    "barWidth = 0.55\n",
    "bars1 = [73.0, 65.3]\n",
    "bars2 = [52.4, 50.6]\n",
    "\n",
    "bars3 = [83.6, 76.3]\n",
    "bars4 = [56.9, 55.6]\n",
    "\n",
    "bars5 = [86.3, 78.1]\n",
    "bars6 = [59.1, 57.5]\n",
    "\n",
    "bars = bars1+bars3+bars5\n",
    "bars_recall = bars2+bars4+bars6\n",
    "\n",
    "# The X position of bars\n",
    "r1 = [1, 1]\n",
    "r2 = [2, 2]\n",
    "r3 = [3, 3]\n",
    "r4 = r1+r2+r3\n",
    "\n",
    "# Text below each barplot with a rotation at 90Â°\n",
    "ax[0].set_xticks([1, 2, 3], ['Baseline', 'ROI', 'RPN+ROI'])\n",
    "ax[1].set_xticks([1, 2, 3], ['Baseline', 'ROI', 'RPN+ROI'])\n",
    "\n",
    "# Create barplot 1\n",
    "ax[0].bar(r1, bars1, width = barWidth, color = ('tab:blue','tab:red'))\n",
    "ax[0].bar(r2, bars3, width = barWidth, color = ('tab:blue','tab:red'))\n",
    "ax[0].bar(r3, bars5, width = barWidth, color = ('tab:blue','tab:red'))\n",
    "ax[0].axis(ymin=40, ymax=100)\n",
    "ax[0].set_title('Precision at IoU = 0.50', fontsize=13)\n",
    "for i, v in enumerate(r4):\n",
    "    if i%2 ==0:\n",
    "        ax[0].text(v-0.13, bars[i] + 1, str(bars[i]), color='black')\n",
    "    else:\n",
    "        ax[0].text(v-0.13, bars[i] - 3, str(bars[i]), color='black')\n",
    "\n",
    "\n",
    "# Create barplot 2\n",
    "ax[1].bar(r1, bars2, width = barWidth, color = ('tab:blue','tab:red'))\n",
    "ax[1].bar(r2, bars4, width = barWidth, color = ('tab:blue','tab:red'))\n",
    "ax[1].bar(r3, bars6, width = barWidth, color = ('tab:blue','tab:red'))\n",
    "ax[1].axhline(100, color='white')\n",
    "ax[1].axis(ymin=40, ymax=70)\n",
    "ax[1].set_title('Recall (Max det = 100)', fontsize=13)\n",
    "for i, v in enumerate(r4):\n",
    "    if i%2 ==0:\n",
    "        ax[1].text(v-0.13, bars_recall[i] + 0.75, str(bars_recall[i]), color='black')\n",
    "    else:\n",
    "        ax[1].text(v-0.13, bars_recall[i] - 1.5, str(bars_recall[i]), color='black')\n",
    "\n",
    "ax[0].spines['top'].set_visible(False)\n",
    "ax[0].spines['right'].set_visible(False)\n",
    "ax[1].spines['top'].set_visible(False)\n",
    "ax[1].spines['right'].set_visible(False)\n",
    "\n",
    "fig.savefig(\"figures/baseline_vs_roi_vs_rpn_roi_precision_recall.png\", transparent=True)\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34b98f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(10,4))\n",
    "\n",
    "# Create bars\n",
    "barWidth = 0.55\n",
    "diff_bars1 = [round(bars1[0]-bars1[1], 3)]\n",
    "diff_bars2 = [round(bars2[0]-bars2[1], 3)]\n",
    "\n",
    "diff_bars3 = [round(bars3[0]-bars3[1], 3)]\n",
    "diff_bars4 = [round(bars4[0]-bars4[1], 3)]\n",
    "\n",
    "diff_bars5 = [round(bars5[0]-bars5[1], 3)]\n",
    "diff_bars6 = [round(bars6[0]-bars6[1], 3)]\n",
    "\n",
    "diff_bars = diff_bars1+diff_bars3+diff_bars5\n",
    "diff_bars_recall = diff_bars2+diff_bars4+diff_bars6\n",
    "\n",
    "# The X position of bars\n",
    "r1 = [1]\n",
    "r2 = [2]\n",
    "r3 = [3]\n",
    "r4 = r1+r2+r3\n",
    "\n",
    "# Text below each barplot with a rotation at 90Â°\n",
    "ax[0].set_xticks([1, 2, 3], ['Baseline', 'ROI', 'RPN+ROI'])\n",
    "ax[1].set_xticks([1, 2, 3], ['Baseline', 'ROI', 'RPN+ROI'])\n",
    "\n",
    "# Create barplot 1\n",
    "ax[0].bar(r1, diff_bars1, width = barWidth, color = ('tab:orange'))\n",
    "ax[0].bar(r2, diff_bars3, width = barWidth, color = ('tab:orange'))\n",
    "ax[0].bar(r3, diff_bars5, width = barWidth, color = ('tab:orange'))\n",
    "ax[0].axis(ymin=0, ymax=10)\n",
    "ax[0].set_title('Diff. between Cis and Trans - Precision', fontsize=13)\n",
    "for i, v in enumerate(r4):\n",
    "    ax[0].text(v-0.13, diff_bars[i] + 0.25, str(diff_bars[i]), color='black')\n",
    "\n",
    "\n",
    "# Create barplot 2\n",
    "ax[1].bar(r1, diff_bars2, width = barWidth, color = ('tab:orange'))\n",
    "ax[1].bar(r2, diff_bars4, width = barWidth, color = ('tab:orange'))\n",
    "ax[1].bar(r3, diff_bars6, width = barWidth, color = ('tab:orange'))\n",
    "ax[1].axhline(100, color='white')\n",
    "ax[1].axis(ymin=0, ymax=5)\n",
    "ax[1].set_title('Diff. between Cis and Trans - Recall', fontsize=13)\n",
    "for i, v in enumerate(r4):\n",
    "    ax[1].text(v-0.13, diff_bars_recall[i] + 0.15, str(diff_bars_recall[i]), color='black')\n",
    "\n",
    "ax[0].spines['top'].set_visible(False)\n",
    "ax[0].spines['right'].set_visible(False)\n",
    "ax[1].spines['top'].set_visible(False)\n",
    "ax[1].spines['right'].set_visible(False)\n",
    "\n",
    "fig.savefig(\"figures/baseline_vs_roi_vs_rpn_roi_diff.png\", transparent=True)\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec06ec6f",
   "metadata": {},
   "source": [
    "### Number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea502547",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(10,4))\n",
    "\n",
    "# Create bars\n",
    "barWidth = 0.55\n",
    "\n",
    "bars00 = [85.4, 77.3]\n",
    "bars0 = [58.4, 57.1]\n",
    "\n",
    "bars1 = [86.3, 78.1]\n",
    "bars2 = [59.1, 57.5]\n",
    "\n",
    "bars3 = [89.5, 79.4]\n",
    "bars4 = [60.3, 57.7]\n",
    "\n",
    "bars5 = [89.7, 78.5]\n",
    "bars6 = [59.4, 56.2]\n",
    "\n",
    "bars = bars00+bars1+bars3+bars5\n",
    "bars_recall = bars0+bars2+bars4+bars6\n",
    "\n",
    "# The X position of bars\n",
    "r0 = [1, 1]\n",
    "r1 = [2, 2]\n",
    "r2 = [3, 3]\n",
    "r3 = [4, 4]\n",
    "r4 = r0+r1+r2+r3\n",
    "\n",
    "# Text below each barplot\n",
    "ax[0].set_xticks([1, 2, 3, 4], ['10', '25', '50', '75'])\n",
    "ax[1].set_xticks([1, 2, 3, 4], ['10', '25', '50', '75'])\n",
    "\n",
    "# Create barplot 1\n",
    "ax[0].bar(r0, bars00, width = barWidth, color = ('tab:blue','tab:red'))\n",
    "ax[0].bar(r1, bars1, width = barWidth, color = ('tab:blue','tab:red'))\n",
    "ax[0].bar(r2, bars3, width = barWidth, color = ('tab:blue','tab:red'))\n",
    "ax[0].bar(r3, bars5, width = barWidth, color = ('tab:blue','tab:red'))\n",
    "ax[0].axis(ymin=40, ymax=100)\n",
    "ax[0].set_title('Precision over epochs', fontsize=13)\n",
    "for i, v in enumerate(r4):\n",
    "    if i%2 ==0:\n",
    "        ax[0].text(v-0.13, bars[i] + 1, str(bars[i]), color='black')\n",
    "    else:\n",
    "        ax[0].text(v-0.13, bars[i] - 3, str(bars[i]), color='black')\n",
    "\n",
    "\n",
    "# Create barplot 2\n",
    "ax[1].bar(r0, bars0, width = barWidth, color = ('tab:blue','tab:red'))\n",
    "ax[1].bar(r1, bars2, width = barWidth, color = ('tab:blue','tab:red'))\n",
    "ax[1].bar(r2, bars4, width = barWidth, color = ('tab:blue','tab:red'))\n",
    "ax[1].bar(r3, bars6, width = barWidth, color = ('tab:blue','tab:red'))\n",
    "ax[1].axhline(100, color='white')\n",
    "ax[1].axis(ymin=40, ymax=70)\n",
    "ax[1].set_title('Recall over epochs', fontsize=13)\n",
    "for i, v in enumerate(r4):\n",
    "    if i%2 ==0:\n",
    "        ax[1].text(v-0.13, bars_recall[i] + 1, str(bars_recall[i]), color='black')\n",
    "    else:\n",
    "        ax[1].text(v-0.13, bars_recall[i] - 2, str(bars_recall[i]), color='black')\n",
    "\n",
    "ax[0].spines['top'].set_visible(False)\n",
    "ax[0].spines['right'].set_visible(False)\n",
    "ax[1].spines['top'].set_visible(False)\n",
    "ax[1].spines['right'].set_visible(False)\n",
    "\n",
    "fig.savefig(\"figures/rpn_roi_epochs_precision_recall.png\", transparent=True)\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d095a337",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(10,4))\n",
    "\n",
    "# Create bars\n",
    "barWidth = 0.55\n",
    "\n",
    "diff_bars00 = [round(bars00[0]-bars00[1], 3)]\n",
    "diff_bars0 = [round(bars0[0]-bars0[1], 3)]\n",
    "\n",
    "diff_bars1 = [round(bars1[0]-bars1[1], 3)]\n",
    "diff_bars2 = [round(bars2[0]-bars2[1], 3)]\n",
    "\n",
    "diff_bars3 = [round(bars3[0]-bars3[1], 3)]\n",
    "diff_bars4 = [round(bars4[0]-bars4[1], 3)]\n",
    "\n",
    "diff_bars5 = [round(bars5[0]-bars5[1], 3)]\n",
    "diff_bars6 = [round(bars6[0]-bars6[1], 3)]\n",
    "\n",
    "diff_bars = diff_bars00+diff_bars1+diff_bars3+diff_bars5\n",
    "diff_bars_recall = diff_bars0+diff_bars2+diff_bars4+diff_bars6\n",
    "\n",
    "# The X position of bars\n",
    "r0 = [1]\n",
    "r1 = [2]\n",
    "r2 = [3]\n",
    "r3 = [4]\n",
    "r4 = r0+r1+r2+r3\n",
    "\n",
    "# Text below each barplot with a rotation at 90Â°\n",
    "ax[0].set_xticks([1, 2, 3, 4], ['10', '25', '50', '75'])\n",
    "ax[1].set_xticks([1, 2, 3, 4], ['10', '25', '50', '75'])\n",
    "\n",
    "# Create barplot 1\n",
    "ax[0].bar(r0, diff_bars00, width = barWidth, color = ('tab:orange'))\n",
    "ax[0].bar(r1, diff_bars1, width = barWidth, color = ('tab:orange'))\n",
    "ax[0].bar(r2, diff_bars3, width = barWidth, color = ('tab:orange'))\n",
    "ax[0].bar(r3, diff_bars5, width = barWidth, color = ('tab:orange'))\n",
    "ax[0].axis(ymin=0, ymax=14)\n",
    "ax[0].set_title('Diff. between Cis and Trans - Precision', fontsize=13)\n",
    "for i, v in enumerate(r4):\n",
    "    ax[0].text(v-0.13, diff_bars[i] + 0.25, str(diff_bars[i]), color='black')\n",
    "\n",
    "\n",
    "# Create barplot 2\n",
    "ax[1].bar(r0, diff_bars0, width = barWidth, color = ('tab:orange'))\n",
    "ax[1].bar(r1, diff_bars2, width = barWidth, color = ('tab:orange'))\n",
    "ax[1].bar(r2, diff_bars4, width = barWidth, color = ('tab:orange'))\n",
    "ax[1].bar(r3, diff_bars6, width = barWidth, color = ('tab:orange'))\n",
    "ax[1].axis(ymin=0, ymax=5)\n",
    "ax[1].set_title('Diff. between Cis and Trans - Recall', fontsize=13)\n",
    "for i, v in enumerate(r4):\n",
    "    ax[1].text(v-0.13, diff_bars_recall[i] + 0.15, str(diff_bars_recall[i]), color='black')\n",
    "\n",
    "ax[0].spines['top'].set_visible(False)\n",
    "ax[0].spines['right'].set_visible(False)\n",
    "ax[1].spines['top'].set_visible(False)\n",
    "ax[1].spines['right'].set_visible(False)\n",
    "\n",
    "fig.savefig(\"figures/rpn_roi_epochs_precision_diff.png\", transparent=True)\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa431cee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d471f87c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
