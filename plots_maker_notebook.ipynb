{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "215c5c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842c2fe6",
   "metadata": {},
   "source": [
    "## Logs utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a15c8a",
   "metadata": {},
   "source": [
    "#### Train logs utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2da998c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the smoothed values to a dictionnary of each values\n",
    "def smoothed_value_to_str(smoothed_value):\n",
    "    d_values = {}\n",
    "    d_values['median'] = smoothed_value.median\n",
    "    d_values['avg'] = smoothed_value.avg\n",
    "    d_values['global_avg'] = smoothed_value.global_avg\n",
    "    d_values['max'] = smoothed_value.max\n",
    "    d_values['value'] = smoothed_value.value\n",
    "    return d_values\n",
    "\n",
    "\n",
    "# Converts the train logs from MetricLogger to list\n",
    "def train_logs_to_lst(logs):\n",
    "    lst = []\n",
    "    for i in range(len(logs)):\n",
    "        d = {}\n",
    "        for key in logs[i].meters.keys():\n",
    "            d[key] = smoothed_value_to_str(logs[i].meters[key])\n",
    "        lst.append(d)\n",
    "    return lst\n",
    "\n",
    "\n",
    "# Puts the training logs into a json file with time dependent file name\n",
    "def train_logs_to_json(logs, ftime=time.strftime(\"%Y%m%d_%H%M%S\")):\n",
    "    train_metric_logs = train_logs_to_lst(logs)\n",
    "    filename = ftime + \"_train_logs.json\"\n",
    "    \n",
    "    with open('saved_logs/' + filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(train_metric_logs, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "# Converts the train logs from MetricLogger to list\n",
    "def train_logs_to_lst(logs):\n",
    "    lst = []\n",
    "    for i in range(len(logs)):\n",
    "        d = {}\n",
    "        for key in logs[i].meters.keys():\n",
    "            d[key] = smoothed_value_to_str(logs[i].meters[key])\n",
    "        lst.append(d)\n",
    "    return lst\n",
    "\n",
    "\n",
    "# Puts the training logs into a json file with time dependent file name\n",
    "def train_logs_to_json(logs, ftime=time.strftime(\"%Y%m%d_%H%M%S\")):\n",
    "    train_metric_logs = train_logs_to_lst(logs)\n",
    "    filename = ftime + \"_train_logs.json\"\n",
    "    \n",
    "    with open('saved_logs/' + filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(train_metric_logs, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec7ac49",
   "metadata": {},
   "source": [
    "#### Valid logs utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6d66ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dicts of a list \n",
    "def merge_dict(logs):\n",
    "    logs_better = []\n",
    "    try:\n",
    "        for i in range(len(logs)):\n",
    "            logs_better.append({**logs[i][0], **logs[i][1], **logs[i][2], **logs[i][3]})\n",
    "        return logs_better\n",
    "    except:\n",
    "        print(logs[0])\n",
    "        logs_better = logs\n",
    "        return logs_better\n",
    "\n",
    "    \n",
    "# Converts the valid logs from list of dictionnaries to string\n",
    "def valid_logs_to_lst(valid_logs):\n",
    "    if type(valid_logs) == list:\n",
    "        return valid_logs\n",
    "    logs = merge_dict(valid_logs)\n",
    "    lst = []\n",
    "    for i in range(len(logs)):\n",
    "        d = {}\n",
    "        for key in logs[i].keys():\n",
    "            d[key] = logs[i][key].cpu().numpy().tolist()\n",
    "        lst.append(d)\n",
    "    return lst\n",
    "\n",
    "\n",
    "# Puts the cis validation logs into a json file with time dependent file name\n",
    "def cis_valid_logs_to_json(logs, ftime=time.strftime(\"%Y%m%d_%H%M%S\")):\n",
    "    valid_metric_logs = valid_logs_to_lst(logs)\n",
    "    filename = ftime + \"_cis_valid_logs.json\"\n",
    "    \n",
    "    with open('saved_logs/' + filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(valid_metric_logs, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "# Puts the trans validation logs into a json file with time dependent file name\n",
    "def trans_valid_logs_to_json(logs, ftime=time.strftime(\"%Y%m%d_%H%M%S\")):\n",
    "    valid_metric_logs = valid_logs_to_lst(logs)\n",
    "    filename = ftime + \"_trans_valid_logs.json\"\n",
    "    \n",
    "    with open('saved_logs/' + filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(valid_metric_logs, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1a4fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Logs utils\n",
    "\n",
    "#### Train logs utils\n",
    "\n",
    "# Converts the smoothed values to a dictionnary of each values\n",
    "def smoothed_value_to_str(smoothed_value):\n",
    "    d_values = {}\n",
    "    d_values['median'] = smoothed_value.median\n",
    "    d_values['avg'] = smoothed_value.avg\n",
    "    d_values['global_avg'] = smoothed_value.global_avg\n",
    "    d_values['max'] = smoothed_value.max\n",
    "    d_values['value'] = smoothed_value.value\n",
    "    return d_values\n",
    "\n",
    "\n",
    "# Converts the train logs from MetricLogger to list\n",
    "def train_logs_to_lst(logs):\n",
    "    lst = []\n",
    "    for i in range(len(logs)):\n",
    "        d = {}\n",
    "        for key in logs[i].meters.keys():\n",
    "            d[key] = smoothed_value_to_str(logs[i].meters[key])\n",
    "        lst.append(d)\n",
    "    return lst\n",
    "\n",
    "\n",
    "# Puts the training logs into a json file with time dependent file name\n",
    "def train_logs_to_json(logs, ftime=time.strftime(\"%Y%m%d_%H%M%S\")):\n",
    "    train_metric_logs = train_logs_to_lst(logs)\n",
    "    filename = ftime + \"_train_logs.json\"\n",
    "    \n",
    "    with open('saved_logs/' + filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(train_metric_logs, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "# Converts the train logs from MetricLogger to list\n",
    "def train_logs_to_lst(logs):\n",
    "    lst = []\n",
    "    for i in range(len(logs)):\n",
    "        d = {}\n",
    "        for key in logs[i].meters.keys():\n",
    "            d[key] = smoothed_value_to_str(logs[i].meters[key])\n",
    "        lst.append(d)\n",
    "    return lst\n",
    "\n",
    "\n",
    "# Puts the training logs into a json file with time dependent file name\n",
    "def train_logs_to_json(logs, ftime=time.strftime(\"%Y%m%d_%H%M%S\")):\n",
    "    train_metric_logs = train_logs_to_lst(logs)\n",
    "    filename = ftime + \"_train_logs.json\"\n",
    "    \n",
    "    with open('saved_logs/' + filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(train_metric_logs, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "#### Valid logs utils\n",
    "\n",
    "# Merge the dicts of a list \n",
    "def merge_dict(logs):\n",
    "    logs_better = []\n",
    "    try:\n",
    "        for i in range(len(logs)):\n",
    "            logs_better.append({**logs[i][0], **logs[i][1], **logs[i][2], **logs[i][3]})\n",
    "        return logs_better\n",
    "    except:\n",
    "        print(logs[0])\n",
    "        logs_better = logs\n",
    "        return logs_better\n",
    "\n",
    "    \n",
    "# Converts the valid logs from list of dictionnaries to string\n",
    "def valid_logs_to_lst(valid_logs):\n",
    "    if type(valid_logs) == list:\n",
    "        return valid_logs\n",
    "    logs = merge_dict(valid_logs)\n",
    "    lst = []\n",
    "    for i in range(len(logs)):\n",
    "        d = {}\n",
    "        for key in logs[i].keys():\n",
    "            d[key] = logs[i][key].cpu().numpy().tolist()\n",
    "        lst.append(d)\n",
    "    return lst\n",
    "\n",
    "\n",
    "# Puts the cis validation logs into a json file with time dependent file name\n",
    "def cis_valid_logs_to_json(logs, ftime=time.strftime(\"%Y%m%d_%H%M%S\")):\n",
    "    valid_metric_logs = valid_logs_to_lst(logs)\n",
    "    filename = ftime + \"_cis_valid_logs.json\"\n",
    "    \n",
    "    with open('saved_logs/' + filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(valid_metric_logs, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n",
    "# Puts the trans validation logs into a json file with time dependent file name\n",
    "def trans_valid_logs_to_json(logs, ftime=time.strftime(\"%Y%m%d_%H%M%S\")):\n",
    "    valid_metric_logs = valid_logs_to_lst(logs)\n",
    "    filename = ftime + \"_trans_valid_logs.json\"\n",
    "    \n",
    "    with open('saved_logs/' + filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(valid_metric_logs, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7777021",
   "metadata": {},
   "source": [
    "## Looking at/Loading the logs in convenient ways\n",
    "Here we define the variables \"train_logs\", \"cis_valid_logs\" and \"trans_valid_logs\" that will be used in the methods for the results and the visualisations.\n",
    "\n",
    "We can import logs or use the ones from training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15decee1",
   "metadata": {},
   "source": [
    "### Load logs right here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb72e3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imported logs - format: name = \"NAME_OR_TIME\"      Exemple file format: \"NAME_OR_TIME_train_logs\"\n",
    "\n",
    "file_time_or_nickname = '50_rpn_roi_2' # VALUE TO CHANGE TO THE IMPORTED FILES\n",
    "\n",
    "# Import training logs\n",
    "with open('saved_logs/' + file_time_or_nickname + '_train_logs.json', \"r\") as f:\n",
    "    train_logs = json.load(f)\n",
    "\n",
    "# Import cis valid logs\n",
    "with open('saved_logs/' + file_time_or_nickname + '_cis_valid_logs.json', \"r\") as f:\n",
    "    cis_valid_logs = json.load(f)\n",
    "\n",
    "# Import trans valid logs\n",
    "with open('saved_logs/' + file_time_or_nickname + '_trans_valid_logs.json', \"r\") as f:\n",
    "    trans_valid_logs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d701d19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imported logs - format: name = \"NAME_OR_TIME\"      Exemple file format: \"NAME_OR_TIME_train_logs\"\n",
    "\n",
    "file_time_or_nickname = '75_rpn_roi_1' # VALUE TO CHANGE TO THE IMPORTED FILES\n",
    "\n",
    "# Import training logs\n",
    "with open('saved_logs/' + file_time_or_nickname + '_train_logs.json', \"r\") as f:\n",
    "    train_logs = train_logs + json.load(f)\n",
    "\n",
    "# Import cis valid logs\n",
    "with open('saved_logs/' + file_time_or_nickname + '_cis_valid_logs.json', \"r\") as f:\n",
    "    cis_valid_logs = cis_valid_logs + json.load(f)\n",
    "\n",
    "# Import trans valid logs\n",
    "with open('saved_logs/' + file_time_or_nickname + '_trans_valid_logs.json', \"r\") as f:\n",
    "    trans_valid_logs = trans_valid_logs + json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e85e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To confirm that the data is loaded properly\n",
    "len(train_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2700fe49",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = len(train_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789cd180",
   "metadata": {},
   "outputs": [],
   "source": [
    "cis_valid_logs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5128b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train loss to print (here we use global_avg but we can use: value, median, avg, max or global_avg)\n",
    "results_train_loss = []\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    results_train_loss.append(train_logs[i]['loss_box_reg']['global_avg'])\n",
    "    \n",
    "# Cis valid loss to print\n",
    "results_cis_valid_loss = [] # cis\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    loss_interm = 0\n",
    "    for j in range(167):\n",
    "        loss_interm += cis_valid_logs[(167 * i) + j]['loss_rpn_box_reg']\n",
    "    results_cis_valid_loss.append(loss_interm)\n",
    "\n",
    "# Trans valid loss to print\n",
    "results_trans_valid_loss = [] # cis\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    loss_interm = 0\n",
    "    for j in range(154):\n",
    "        loss_interm += trans_valid_logs[(154 * i) + j]['loss_rpn_box_reg']\n",
    "    results_trans_valid_loss.append(loss_interm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b6e3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the different plots\n",
    "fig, ax = plt.subplots(1,2, figsize=(20,6))\n",
    "\n",
    "ax[0].plot(np.arange(1, num_epochs + 1), results_train_loss, label='train')\n",
    "ax[0].set_title('Train loss per epoch')\n",
    "ax[0].set_ylabel('loss_box_reg')\n",
    "ax[0].set_xlabel('epoch')\n",
    "\n",
    "plt.title('Train loss per epoch')\n",
    "ax[1].plot(np.arange(1, num_epochs + 1), results_cis_valid_loss, label='cis')\n",
    "ax[1].plot(np.arange(1, num_epochs + 1), results_trans_valid_loss, label='trans')\n",
    "ax[1].set_title('Valid loss per epoch')\n",
    "ax[1].set_ylabel('loss_rpn_box_reg')\n",
    "ax[1].set_xlabel('epoch')\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519a1950",
   "metadata": {},
   "source": [
    "#### Save the figure to pdf format in the figures folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce24f5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"figures/\" + time.strftime(\"%Y%m%d_%H%M%S\") + \"_figure.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60560b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"figures/full_75_rpn_roi_1_figure.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599a3310",
   "metadata": {},
   "source": [
    "## Table to show results (manually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515f1909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RPN + ROI\n",
    "cis_results = [0.863, 0.895, 0.897]\n",
    "trans_results = [0.781, 0.794, 0.785]\n",
    "delta_results = [cis_results[i]-trans_results[i] for i in range(len(cis_results))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301ce1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RPN + ROI: Printing the different plots\n",
    "fig, ax = plt.subplots(1,2, figsize=(20,6))\n",
    "\n",
    "ax[0].plot(np.arange(1, len(cis_results) + 1), cis_results, label='cis')\n",
    "ax[0].plot(np.arange(1, len(trans_results) + 1), trans_results, label='trans')\n",
    "ax[0].axhline(y=0.7, c=\"white\")\n",
    "ax[0].set_title('Average precision over number of epochs')\n",
    "ax[0].set_ylabel('Average precision @IoU=0.50')\n",
    "ax[0].set_xlabel('epoch')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(np.arange(1, len(cis_results) + 1), delta_results,'r', label='train')\n",
    "ax[1].axhline(y=0.05, c=\"white\")\n",
    "ax[1].set_title('Difference in average precision over number of epochs')\n",
    "ax[1].set_ylabel('Difference in average precision')\n",
    "ax[1].set_xlabel('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345d038e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2996d024",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddb863b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(1, 3 + 1), cis_results, label='xd')\n",
    "plt.bar(np.arange(1, 3 + 1), trans_results)\n",
    "plt.title('Precision over number of epochs')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba0aebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base vs roi vs roi+rpn\n",
    "cis_results = [0.863, 0.895, 0.897]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c23c3d",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db89b6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imported logs - format: name = \"NAME_OR_TIME\"      Exemple file format: \"NAME_OR_TIME_train_logs\"\n",
    "\n",
    "file_time_or_nickname = '25_base' # VALUE TO CHANGE TO THE IMPORTED FILES\n",
    "\n",
    "# Import training logs\n",
    "with open('saved_logs/' + file_time_or_nickname + '_train_logs.json', \"r\") as f:\n",
    "    train_base = json.load(f)\n",
    "\n",
    "# Import cis valid logs\n",
    "with open('saved_logs/' + file_time_or_nickname + '_cis_valid_logs.json', \"r\") as f:\n",
    "    cis_base = json.load(f)\n",
    "\n",
    "# Import trans valid logsw\n",
    "with open('saved_logs/' + file_time_or_nickname + '_trans_valid_logs.json', \"r\") as f:\n",
    "    trans_base = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66adc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imported logs - format: name = \"NAME_OR_TIME\"      Exemple file format: \"NAME_OR_TIME_train_logs\"\n",
    "\n",
    "file_time_or_nickname = '25_roi_4_vision_version_diff' # VALUE TO CHANGE TO THE IMPORTED FILES\n",
    "\n",
    "# Import training logs\n",
    "with open('saved_logs/' + file_time_or_nickname + '_train_logs.json', \"r\") as f:\n",
    "    train_roi = json.load(f)\n",
    "\n",
    "# Import cis valid logs\n",
    "with open('saved_logs/' + file_time_or_nickname + '_cis_valid_logs.json', \"r\") as f:\n",
    "    cis_roi = json.load(f)\n",
    "\n",
    "# Import trans valid logs\n",
    "with open('saved_logs/' + file_time_or_nickname + '_trans_valid_logs.json', \"r\") as f:\n",
    "    trans_roi = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d4ce57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imported logs - format: name = \"NAME_OR_TIME\"      Exemple file format: \"NAME_OR_TIME_train_logs\"\n",
    "\n",
    "file_time_or_nickname = '25_rpn_roi_1' # VALUE TO CHANGE TO THE IMPORTED FILES\n",
    "\n",
    "# Import training logs\n",
    "with open('saved_logs/' + file_time_or_nickname + '_train_logs.json', \"r\") as f:\n",
    "    train_rpn_roi = json.load(f)\n",
    "\n",
    "# Import cis valid logs\n",
    "with open('saved_logs/' + file_time_or_nickname + '_cis_valid_logs.json', \"r\") as f:\n",
    "    cis_rpn_roi = json.load(f)\n",
    "\n",
    "# Import trans valid logs\n",
    "with open('saved_logs/' + file_time_or_nickname + '_trans_valid_logs.json', \"r\") as f:\n",
    "    trans_rpn_roi = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a60d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base\n",
    "results_train_loss_base = []\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    results_train_loss_base.append(train_base[i]['loss_box_reg']['global_avg'])\n",
    "    \n",
    "# Cis valid loss to print\n",
    "results_cis_valid_loss_base = [] # cis\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    loss_interm = 0\n",
    "    for j in range(167):\n",
    "        loss_interm += cis_base[(167 * i) + j]['loss_box_reg']\n",
    "    results_cis_valid_loss_base.append(loss_interm)\n",
    "\n",
    "# Trans valid loss to print\n",
    "results_trans_valid_loss_base = [] # trans\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    loss_interm = 0\n",
    "    for j in range(154):\n",
    "        loss_interm += trans_base[(154 * i) + j]['loss_box_reg']\n",
    "    results_trans_valid_loss_base.append(loss_interm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef93ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roi\n",
    "results_train_loss_roi = []\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    results_train_loss_roi.append(train_roi[i]['loss_box_reg']['global_avg'])\n",
    "    \n",
    "# Cis valid loss to print\n",
    "results_cis_valid_loss_roi = [] # cis\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    loss_interm = 0\n",
    "    for j in range(167):\n",
    "        loss_interm += cis_roi[(167 * i) + j]['loss_box_reg']\n",
    "    results_cis_valid_loss_roi.append(loss_interm)\n",
    "\n",
    "# Trans valid loss to print\n",
    "results_trans_valid_loss_roi = [] # trans\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    loss_interm = 0\n",
    "    for j in range(154):\n",
    "        loss_interm += trans_roi[(154 * i) + j]['loss_box_reg']\n",
    "    results_trans_valid_loss_roi.append(loss_interm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df68b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rpn+roi\n",
    "results_train_loss_rpn_roi = []\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    results_train_loss_rpn_roi.append(train_rpn_roi[i]['loss_box_reg']['global_avg'])\n",
    "    \n",
    "# Cis valid loss to print\n",
    "results_cis_valid_loss_rpn_roi = [] # cis\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    loss_interm = 0\n",
    "    for j in range(167):\n",
    "        loss_interm += cis_rpn_roi[(167 * i) + j]['loss_box_reg']\n",
    "    results_cis_valid_loss_rpn_roi.append(loss_interm)\n",
    "\n",
    "# Trans valid loss to print\n",
    "results_trans_valid_loss_rpn_roi = [] # trans\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    loss_interm = 0\n",
    "    for j in range(154):\n",
    "        loss_interm += trans_rpn_roi[(154 * i) + j]['loss_box_reg']\n",
    "    results_trans_valid_loss_rpn_roi.append(loss_interm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bd169f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Printing the different plots\n",
    "fig, ax = plt.subplots(1,2, figsize=(14,4))\n",
    "\n",
    "ax[0].plot(np.arange(1, num_epochs + 1), results_train_loss_base, label='base')\n",
    "ax[0].plot(np.arange(1, num_epochs + 1), results_train_loss_roi, label='roi')\n",
    "ax[0].plot(np.arange(1, num_epochs + 1), results_train_loss_rpn_roi, label='rpn+roi')\n",
    "ax[0].set_title('Train loss per epoch')\n",
    "ax[0].set_ylabel('loss_box_reg')\n",
    "ax[0].set_xlabel('epoch')\n",
    "ax[0].legend()\n",
    "\n",
    "plt.title('Train loss per epoch')\n",
    "ax[1].plot(np.arange(1, num_epochs + 1), results_cis_valid_loss_base, label='cis', color='tab:blue')\n",
    "ax[1].plot(np.arange(1, num_epochs + 1), results_trans_valid_loss_base, label='trans', color='tab:red')\n",
    "ax[1].plot(np.arange(1, num_epochs + 1), results_cis_valid_loss_roi, color='tab:blue')\n",
    "ax[1].plot(np.arange(1, num_epochs + 1), results_trans_valid_loss_roi, color='tab:red')\n",
    "ax[1].plot(np.arange(1, num_epochs + 1), results_cis_valid_loss_rpn_roi, color='tab:blue')\n",
    "ax[1].plot(np.arange(1, num_epochs + 1), results_trans_valid_loss_rpn_roi, color='tab:red')\n",
    "ax[1].set_title('Valid loss per epoch')\n",
    "ax[1].set_ylabel('loss_box_reg')\n",
    "ax[1].set_xlabel('epoch')\n",
    "ax[1].legend()\n",
    "\n",
    "ax[0].spines['top'].set_visible(False)\n",
    "ax[0].spines['right'].set_visible(False)\n",
    "ax[1].spines['top'].set_visible(False)\n",
    "ax[1].spines['right'].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb995807",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"figures/baseline_vs_roi_vs_rpn_roi_training.png\", transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709c2541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cis valid loss to print\n",
    "results_cis_valid_loss_base = [] # cis\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    loss_interm = 0\n",
    "    for j in range(167):\n",
    "        loss_interm += cis_base[(167 * i) + j]['loss_rpn_box_reg']\n",
    "    results_cis_valid_loss_base.append(loss_interm)\n",
    "\n",
    "# Trans valid loss to print\n",
    "results_trans_valid_loss_base = [] # trans\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    loss_interm = 0\n",
    "    for j in range(154):\n",
    "        loss_interm += trans_base[(154 * i) + j]['loss_rpn_box_reg']\n",
    "    results_trans_valid_loss_base.append(loss_interm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dfa177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cis valid loss to print\n",
    "results_cis_valid_loss_roi = [] # cis\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    loss_interm = 0\n",
    "    for j in range(167):\n",
    "        loss_interm += cis_roi[(167 * i) + j]['loss_rpn_box_reg']\n",
    "    results_cis_valid_loss_roi.append(loss_interm)\n",
    "\n",
    "# Trans valid loss to print\n",
    "results_trans_valid_loss_roi = [] # trans\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    loss_interm = 0\n",
    "    for j in range(154):\n",
    "        loss_interm += trans_roi[(154 * i) + j]['loss_rpn_box_reg']\n",
    "    results_trans_valid_loss_roi.append(loss_interm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ba42ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cis valid loss to print\n",
    "results_cis_valid_loss_rpn_roi = [] # cis\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    loss_interm = 0\n",
    "    for j in range(167):\n",
    "        loss_interm += cis_rpn_roi[(167 * i) + j]['loss_rpn_box_reg']\n",
    "    results_cis_valid_loss_rpn_roi.append(loss_interm)\n",
    "\n",
    "# Trans valid loss to print\n",
    "results_trans_valid_loss_rpn_roi = [] # trans\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    loss_interm = 0\n",
    "    for j in range(154):\n",
    "        loss_interm += trans_rpn_roi[(154 * i) + j]['loss_rpn_box_reg']\n",
    "    results_trans_valid_loss_rpn_roi.append(loss_interm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3531f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(7,4))\n",
    "\n",
    "plt.title('Train loss per epoch')\n",
    "ax.plot(np.arange(1, num_epochs + 1), results_cis_valid_loss_base, label='cis', color='tab:blue')\n",
    "ax.plot(np.arange(1, num_epochs + 1), results_trans_valid_loss_base, label='trans', color='tab:red')\n",
    "ax.plot(np.arange(1, num_epochs + 1), results_cis_valid_loss_roi, color='tab:blue')\n",
    "ax.plot(np.arange(1, num_epochs + 1), results_trans_valid_loss_roi, color='tab:red')\n",
    "ax.plot(np.arange(1, num_epochs + 1), results_cis_valid_loss_rpn_roi, color='tab:blue')\n",
    "ax.plot(np.arange(1, num_epochs + 1), results_trans_valid_loss_rpn_roi, color='tab:red')\n",
    "ax.set_title('Valid loss per epoch')\n",
    "ax.set_ylabel('loss_rpn_box_reg')\n",
    "ax.set_xlabel('epoch')\n",
    "ax.legend()\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0ab632",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"figures/baseline_vs_roi_vs_rpn_roi_training_rpn.png\", transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ee113c",
   "metadata": {},
   "source": [
    "# Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ecc2ae",
   "metadata": {},
   "source": [
    "### Different depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647275aa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(10,4))\n",
    "\n",
    "# Create bars\n",
    "barWidth = 0.55\n",
    "bars1 = [73.0, 65.3]\n",
    "bars2 = [52.4, 50.6]\n",
    "\n",
    "bars3 = [83.6, 76.3]\n",
    "bars4 = [56.9, 55.6]\n",
    "\n",
    "bars5 = [86.3, 78.1]\n",
    "bars6 = [59.1, 57.5]\n",
    "\n",
    "bars = bars1+bars3+bars5\n",
    "bars_recall = bars2+bars4+bars6\n",
    "\n",
    "# The X position of bars\n",
    "r1 = [1, 1]\n",
    "r2 = [2, 2]\n",
    "r3 = [3, 3]\n",
    "r4 = r1+r2+r3\n",
    "\n",
    "# Text below each barplot with a rotation at 90°\n",
    "ax[0].set_xticks([1, 2, 3], ['Baseline', 'ROI', 'RPN+ROI'])\n",
    "ax[1].set_xticks([1, 2, 3], ['Baseline', 'ROI', 'RPN+ROI'])\n",
    "\n",
    "# Create barplot 1\n",
    "ax[0].bar(r1, bars1, width = barWidth, color = ('tab:blue','tab:red'))\n",
    "ax[0].bar(r2, bars3, width = barWidth, color = ('tab:blue','tab:red'))\n",
    "ax[0].bar(r3, bars5, width = barWidth, color = ('tab:blue','tab:red'))\n",
    "ax[0].axis(ymin=40, ymax=100)\n",
    "ax[0].set_title('Precision at IoU = 0.50', fontsize=13)\n",
    "for i, v in enumerate(r4):\n",
    "    if i%2 ==0:\n",
    "        ax[0].text(v-0.13, bars[i] + 1, str(bars[i]), color='black')\n",
    "    else:\n",
    "        ax[0].text(v-0.13, bars[i] - 3, str(bars[i]), color='black')\n",
    "\n",
    "\n",
    "# Create barplot 2\n",
    "ax[1].bar(r1, bars2, width = barWidth, color = ('tab:blue','tab:red'))\n",
    "ax[1].bar(r2, bars4, width = barWidth, color = ('tab:blue','tab:red'))\n",
    "ax[1].bar(r3, bars6, width = barWidth, color = ('tab:blue','tab:red'))\n",
    "ax[1].axhline(100, color='white')\n",
    "ax[1].axis(ymin=40, ymax=70)\n",
    "ax[1].set_title('Recall (Max det = 100)', fontsize=13)\n",
    "for i, v in enumerate(r4):\n",
    "    if i%2 ==0:\n",
    "        ax[1].text(v-0.13, bars_recall[i] + 0.75, str(bars_recall[i]), color='black')\n",
    "    else:\n",
    "        ax[1].text(v-0.13, bars_recall[i] - 1.5, str(bars_recall[i]), color='black')\n",
    "\n",
    "ax[0].spines['top'].set_visible(False)\n",
    "ax[0].spines['right'].set_visible(False)\n",
    "ax[1].spines['top'].set_visible(False)\n",
    "ax[1].spines['right'].set_visible(False)\n",
    "\n",
    "fig.savefig(\"figures/baseline_vs_roi_vs_rpn_roi_precision_recall.png\", transparent=True)\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34b98f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(10,4))\n",
    "\n",
    "# Create bars\n",
    "barWidth = 0.55\n",
    "diff_bars1 = [round(bars1[0]-bars1[1], 3)]\n",
    "diff_bars2 = [round(bars2[0]-bars2[1], 3)]\n",
    "\n",
    "diff_bars3 = [round(bars3[0]-bars3[1], 3)]\n",
    "diff_bars4 = [round(bars4[0]-bars4[1], 3)]\n",
    "\n",
    "diff_bars5 = [round(bars5[0]-bars5[1], 3)]\n",
    "diff_bars6 = [round(bars6[0]-bars6[1], 3)]\n",
    "\n",
    "diff_bars = diff_bars1+diff_bars3+diff_bars5\n",
    "diff_bars_recall = diff_bars2+diff_bars4+diff_bars6\n",
    "\n",
    "# The X position of bars\n",
    "r1 = [1]\n",
    "r2 = [2]\n",
    "r3 = [3]\n",
    "r4 = r1+r2+r3\n",
    "\n",
    "# Text below each barplot with a rotation at 90°\n",
    "ax[0].set_xticks([1, 2, 3], ['Baseline', 'ROI', 'RPN+ROI'])\n",
    "ax[1].set_xticks([1, 2, 3], ['Baseline', 'ROI', 'RPN+ROI'])\n",
    "\n",
    "# Create barplot 1\n",
    "ax[0].bar(r1, diff_bars1, width = barWidth, color = ('tab:orange'))\n",
    "ax[0].bar(r2, diff_bars3, width = barWidth, color = ('tab:orange'))\n",
    "ax[0].bar(r3, diff_bars5, width = barWidth, color = ('tab:orange'))\n",
    "ax[0].axis(ymin=0, ymax=10)\n",
    "ax[0].set_title('Diff. between Cis and Trans - Precision', fontsize=13)\n",
    "for i, v in enumerate(r4):\n",
    "    ax[0].text(v-0.13, diff_bars[i] + 0.25, str(diff_bars[i]), color='black')\n",
    "\n",
    "\n",
    "# Create barplot 2\n",
    "ax[1].bar(r1, diff_bars2, width = barWidth, color = ('tab:orange'))\n",
    "ax[1].bar(r2, diff_bars4, width = barWidth, color = ('tab:orange'))\n",
    "ax[1].bar(r3, diff_bars6, width = barWidth, color = ('tab:orange'))\n",
    "ax[1].axhline(100, color='white')\n",
    "ax[1].axis(ymin=0, ymax=5)\n",
    "ax[1].set_title('Diff. between Cis and Trans - Recall', fontsize=13)\n",
    "for i, v in enumerate(r4):\n",
    "    ax[1].text(v-0.13, diff_bars_recall[i] + 0.15, str(diff_bars_recall[i]), color='black')\n",
    "\n",
    "ax[0].spines['top'].set_visible(False)\n",
    "ax[0].spines['right'].set_visible(False)\n",
    "ax[1].spines['top'].set_visible(False)\n",
    "ax[1].spines['right'].set_visible(False)\n",
    "\n",
    "fig.savefig(\"figures/baseline_vs_roi_vs_rpn_roi_diff.png\", transparent=True)\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec06ec6f",
   "metadata": {},
   "source": [
    "### Number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea502547",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(10,4))\n",
    "\n",
    "# Create bars\n",
    "barWidth = 0.55\n",
    "\n",
    "bars00 = [85.4, 77.3]\n",
    "bars0 = [58.4, 57.1]\n",
    "\n",
    "bars1 = [86.3, 78.1]\n",
    "bars2 = [59.1, 57.5]\n",
    "\n",
    "bars3 = [89.5, 79.4]\n",
    "bars4 = [60.3, 57.7]\n",
    "\n",
    "bars5 = [89.7, 78.5]\n",
    "bars6 = [59.4, 56.2]\n",
    "\n",
    "bars = bars00+bars1+bars3+bars5\n",
    "bars_recall = bars0+bars2+bars4+bars6\n",
    "\n",
    "# The X position of bars\n",
    "r0 = [1, 1]\n",
    "r1 = [2, 2]\n",
    "r2 = [3, 3]\n",
    "r3 = [4, 4]\n",
    "r4 = r0+r1+r2+r3\n",
    "\n",
    "# Text below each barplot\n",
    "ax[0].set_xticks([1, 2, 3, 4], ['10', '25', '50', '75'])\n",
    "ax[1].set_xticks([1, 2, 3, 4], ['10', '25', '50', '75'])\n",
    "\n",
    "# Create barplot 1\n",
    "ax[0].bar(r0, bars00, width = barWidth, color = ('tab:blue','tab:red'))\n",
    "ax[0].bar(r1, bars1, width = barWidth, color = ('tab:blue','tab:red'))\n",
    "ax[0].bar(r2, bars3, width = barWidth, color = ('tab:blue','tab:red'))\n",
    "ax[0].bar(r3, bars5, width = barWidth, color = ('tab:blue','tab:red'))\n",
    "ax[0].axis(ymin=40, ymax=100)\n",
    "ax[0].set_title('Precision over epochs', fontsize=13)\n",
    "for i, v in enumerate(r4):\n",
    "    if i%2 ==0:\n",
    "        ax[0].text(v-0.13, bars[i] + 1, str(bars[i]), color='black')\n",
    "    else:\n",
    "        ax[0].text(v-0.13, bars[i] - 3, str(bars[i]), color='black')\n",
    "\n",
    "\n",
    "# Create barplot 2\n",
    "ax[1].bar(r0, bars0, width = barWidth, color = ('tab:blue','tab:red'))\n",
    "ax[1].bar(r1, bars2, width = barWidth, color = ('tab:blue','tab:red'))\n",
    "ax[1].bar(r2, bars4, width = barWidth, color = ('tab:blue','tab:red'))\n",
    "ax[1].bar(r3, bars6, width = barWidth, color = ('tab:blue','tab:red'))\n",
    "ax[1].axhline(100, color='white')\n",
    "ax[1].axis(ymin=40, ymax=70)\n",
    "ax[1].set_title('Recall over epochs', fontsize=13)\n",
    "for i, v in enumerate(r4):\n",
    "    if i%2 ==0:\n",
    "        ax[1].text(v-0.13, bars_recall[i] + 1, str(bars_recall[i]), color='black')\n",
    "    else:\n",
    "        ax[1].text(v-0.13, bars_recall[i] - 2, str(bars_recall[i]), color='black')\n",
    "\n",
    "ax[0].spines['top'].set_visible(False)\n",
    "ax[0].spines['right'].set_visible(False)\n",
    "ax[1].spines['top'].set_visible(False)\n",
    "ax[1].spines['right'].set_visible(False)\n",
    "\n",
    "fig.savefig(\"figures/rpn_roi_epochs_precision_recall.png\", transparent=True)\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d095a337",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(10,4))\n",
    "\n",
    "# Create bars\n",
    "barWidth = 0.55\n",
    "\n",
    "diff_bars00 = [round(bars00[0]-bars00[1], 3)]\n",
    "diff_bars0 = [round(bars0[0]-bars0[1], 3)]\n",
    "\n",
    "diff_bars1 = [round(bars1[0]-bars1[1], 3)]\n",
    "diff_bars2 = [round(bars2[0]-bars2[1], 3)]\n",
    "\n",
    "diff_bars3 = [round(bars3[0]-bars3[1], 3)]\n",
    "diff_bars4 = [round(bars4[0]-bars4[1], 3)]\n",
    "\n",
    "diff_bars5 = [round(bars5[0]-bars5[1], 3)]\n",
    "diff_bars6 = [round(bars6[0]-bars6[1], 3)]\n",
    "\n",
    "diff_bars = diff_bars00+diff_bars1+diff_bars3+diff_bars5\n",
    "diff_bars_recall = diff_bars0+diff_bars2+diff_bars4+diff_bars6\n",
    "\n",
    "# The X position of bars\n",
    "r0 = [1]\n",
    "r1 = [2]\n",
    "r2 = [3]\n",
    "r3 = [4]\n",
    "r4 = r0+r1+r2+r3\n",
    "\n",
    "# Text below each barplot with a rotation at 90°\n",
    "ax[0].set_xticks([1, 2, 3, 4], ['10', '25', '50', '75'])\n",
    "ax[1].set_xticks([1, 2, 3, 4], ['10', '25', '50', '75'])\n",
    "\n",
    "# Create barplot 1\n",
    "ax[0].bar(r0, diff_bars00, width = barWidth, color = ('tab:orange'))\n",
    "ax[0].bar(r1, diff_bars1, width = barWidth, color = ('tab:orange'))\n",
    "ax[0].bar(r2, diff_bars3, width = barWidth, color = ('tab:orange'))\n",
    "ax[0].bar(r3, diff_bars5, width = barWidth, color = ('tab:orange'))\n",
    "ax[0].axis(ymin=0, ymax=14)\n",
    "ax[0].set_title('Diff. between Cis and Trans - Precision', fontsize=13)\n",
    "for i, v in enumerate(r4):\n",
    "    ax[0].text(v-0.13, diff_bars[i] + 0.25, str(diff_bars[i]), color='black')\n",
    "\n",
    "\n",
    "# Create barplot 2\n",
    "ax[1].bar(r0, diff_bars0, width = barWidth, color = ('tab:orange'))\n",
    "ax[1].bar(r1, diff_bars2, width = barWidth, color = ('tab:orange'))\n",
    "ax[1].bar(r2, diff_bars4, width = barWidth, color = ('tab:orange'))\n",
    "ax[1].bar(r3, diff_bars6, width = barWidth, color = ('tab:orange'))\n",
    "ax[1].axis(ymin=0, ymax=5)\n",
    "ax[1].set_title('Diff. between Cis and Trans - Recall', fontsize=13)\n",
    "for i, v in enumerate(r4):\n",
    "    ax[1].text(v-0.13, diff_bars_recall[i] + 0.15, str(diff_bars_recall[i]), color='black')\n",
    "\n",
    "ax[0].spines['top'].set_visible(False)\n",
    "ax[0].spines['right'].set_visible(False)\n",
    "ax[1].spines['top'].set_visible(False)\n",
    "ax[1].spines['right'].set_visible(False)\n",
    "\n",
    "fig.savefig(\"figures/rpn_roi_epochs_precision_diff.png\", transparent=True)\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa431cee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d471f87c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8448df7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Animals",
   "language": "python",
   "name": "animals"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
