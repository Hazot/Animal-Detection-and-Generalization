{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3RUQCnETVJhK"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "import os\n",
    "from torchvision.io import read_image\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.patches as patches\n",
    "from torchvision import transforms\n",
    "\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "from torchmetrics.detection.map import MeanAveragePrecision\n",
    "\n",
    "import pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports from local lib files\n",
    "import utils\n",
    "import transforms\n",
    "import coco_eval\n",
    "from engine import train_one_epoch, evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CFo8FhOT4-Yf"
   },
   "source": [
    "## File paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IlU99PhcSNDv"
   },
   "outputs": [],
   "source": [
    "output_path = 'output'\n",
    "img_folder = 'eccv_18_all_images_sm'\n",
    "\n",
    "cis_test_ann_path = 'eccv_18_annotation_files/cis_test_annotations.json'\n",
    "cis_val_ann_path = 'eccv_18_annotation_files/cis_val_annotations.json'\n",
    "train_ann_path = 'eccv_18_annotation_files/train_annotations.json'\n",
    "trans_test_ann_path = 'eccv_18_annotation_files/trans_test_annotations.json'\n",
    "trans_val_ann_path = 'eccv_18_annotation_files/trans_val_annotations.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "08r4QhagWuKZ"
   },
   "source": [
    "## Basic data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "5tYL7gDDW09R"
   },
   "outputs": [],
   "source": [
    "cis_test_ann = json.load(open(cis_test_ann_path))\n",
    "cis_val_ann = json.load(open(cis_val_ann_path))\n",
    "train_ann = json.load(open(train_ann_path))\n",
    "trans_test_ann = json.load(open(trans_test_ann_path))\n",
    "trans_val_ann = json.load(open(trans_val_ann_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qbuy1jLsWuew",
    "outputId": "7ba79560-5443-4fea-f46c-c0e3acaa1588"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cis test set length: 15827\n",
      "cis val set length: 3484\n",
      "train set length: 13553\n",
      "trans test set length: 23275\n",
      "trans val set length: 1725\n"
     ]
    }
   ],
   "source": [
    "print('cis test set length:', len(cis_test_ann['images']))\n",
    "print('cis val set length:', len(cis_val_ann['images']))\n",
    "print('train set length:', len(train_ann['images']))\n",
    "print('trans test set length:', len(trans_test_ann['images']))\n",
    "print('trans val set length:', len(trans_val_ann['images']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "iOwBQIVEYWkN",
    "outputId": "c91a5292-95b4-4e30-9e96-a5cbbc6cdf66"
   },
   "outputs": [],
   "source": [
    "# i = 0\n",
    "\n",
    "# boxes = [trans_val_ann['annotations'][j]['bbox'] for j in range(len(trans_val_ann['annotations'])) \n",
    "#          if trans_val_ann['annotations'][j]['image_id']==trans_val_ann['images'][i]['id'] \n",
    "#          and 'bbox' in trans_val_ann['annotations'][j].keys()]\n",
    "\n",
    "# img_path = os.path.join('eccv_18_all_images_sm', trans_val_ann['images'][i]['file_name']) # to change\n",
    "\n",
    "# image = read_image(img_path)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.imshow(image[0].squeeze(),cmap=\"gray\")\n",
    "\n",
    "# scale_x = image.shape[2] / trans_val_ann['images'][i]['width'] \n",
    "# scale_y = image.shape[1] / trans_val_ann['images'][i]['height']\n",
    "\n",
    "# boxes = torch.as_tensor(boxes)\n",
    "\n",
    "# for i in range(boxes.shape[0]):\n",
    "#     boxes[i][0] = torch.round(boxes[i][0] * scale_x)\n",
    "#     boxes[i][1] = torch.round(boxes[i][1] * scale_y)\n",
    "#     boxes[i][2] = torch.round(boxes[i][2] * scale_x)\n",
    "#     boxes[i][3] = torch.round(boxes[i][3] * scale_y)\n",
    "\n",
    "#     boxes[i][2] = boxes[i][0] + boxes[i][2]\n",
    "#     boxes[i][3] = boxes[i][1] + boxes[i][3]\n",
    "\n",
    "# target = {}\n",
    "# target[\"boxes\"] = boxes\n",
    "\n",
    "# rect = patches.Rectangle((boxes[0][0], boxes[0][1]), boxes[0][2]-boxes[0][0], \n",
    "#                          boxes[0][3]-boxes[0][1], linewidth=2, edgecolor='r', facecolor='none')\n",
    "# ax.add_patch(rect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OMhB4CM354Px"
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3mHaZNrt7D98"
   },
   "outputs": [],
   "source": [
    "# In paper :  ' ... and employ horizontal flipping for data augmentation. ( for detection)\n",
    "\n",
    "import transforms as T   # from git hub repo\n",
    "\n",
    "data_transform = {'train': T.RandomHorizontalFlip(0.5)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a list with the idx of images with at least one bounding box (img_wbbox) and a \n",
    "# list with the number of bbox for each valid image (num_bbox)\n",
    "def get_img_with_bbox(file_path):\n",
    "  \n",
    "    file = json.load(open(file_path))\n",
    "    img_wbbox = []\n",
    "    num_bbox = []\n",
    "\n",
    "    for i in range(len(file['images'])):\n",
    "        bboxes = [file['annotations'][j]['bbox'] \n",
    "                  for j in range(len(file['annotations'])) \n",
    "                  if file['annotations'][j]['image_id']==file['images'][i]['id'] \n",
    "                  and 'bbox' in file['annotations'][j].keys()]\n",
    "\n",
    "        if len(bboxes)!=0:\n",
    "            img_wbbox.append(i)\n",
    "\n",
    "            num_bbox.append(len(bboxes))\n",
    "\n",
    "    return img_wbbox, num_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "SdJaZm5aOJ6y"
   },
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, label_path, img_dir, valid_img, transform = None, target_transform=None):\n",
    "        self.label_file = json.load(open(label_path))\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.valid_img = valid_img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_img)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        idx = self.valid_img[idx] # consider only images with bbox annotations\n",
    "        img_path = os.path.join(self.img_dir, self.label_file['images'][idx]['file_name'])\n",
    "        image = read_image(img_path)\n",
    "\n",
    "        conv = torchvision.transforms.ToTensor()\n",
    "        # if image.shape[0]==1:\n",
    "        # some images have only one channel, we convert them to rgb\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        image = conv(image)\n",
    "\n",
    "        boxes = [self.label_file['annotations'][j]['bbox'] \n",
    "                 for j in range(len(self.label_file['annotations'])) \n",
    "                 if self.label_file['annotations'][j]['image_id']==self.label_file['images'][idx]['id']]\n",
    "        \n",
    "        label = [self.label_file['annotations'][j]['category_id'] \n",
    "                 for j in range(len(self.label_file['annotations'])) \n",
    "                 if self.label_file['annotations'][j]['image_id']==self.label_file['images'][idx]['id']]\n",
    "\n",
    "        # transform bbox coords to adjust for resizing\n",
    "        scale_x = image.shape[2] / self.label_file['images'][idx]['width'] \n",
    "        scale_y = image.shape[1] / self.label_file['images'][idx]['height']\n",
    "\n",
    "        boxes = torch.as_tensor(boxes)\n",
    "        for i in range(boxes.shape[0]):\n",
    "            boxes[i][0] = torch.round(boxes[i][0] * scale_x)\n",
    "            boxes[i][1] = torch.round(boxes[i][1] * scale_y)\n",
    "            boxes[i][2] = torch.round(boxes[i][2] * scale_x)\n",
    "            boxes[i][3] = torch.round(boxes[i][3] * scale_y)\n",
    "\n",
    "            boxes[i][2] = boxes[i][0] + boxes[i][2] # to transform to pytorch bbox format\n",
    "            boxes[i][3] = boxes[i][1] + boxes[i][3]\n",
    "\n",
    "            #boxes[i][0]*=scale_x\n",
    "            #boxes[i][1]*=scale_y\n",
    "            #boxes[i][2]*=scale_x\n",
    "            #boxes[i][3]*=scale_y\n",
    "\n",
    "        label = torch.as_tensor(label)\n",
    "        label = torch.where(label==30,0,1)  # 0 if empty (categ id = 30), 1 if animal\n",
    "        image_id = torch.tensor([idx])\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        iscrowd = torch.zeros((boxes.shape[0],), dtype=torch.int64)\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = label\n",
    "        target[\"image_id\"] = image_id\n",
    "        target['area']=area\n",
    "        target['iscrowd']=iscrowd\n",
    "\n",
    "        # TO DO : resize all to same size\n",
    "\n",
    "        if self.transform:\n",
    "            # transform image AND target\n",
    "            image, target = self.transform(image, target)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iuPqrCPG8wsr"
   },
   "source": [
    "## Pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6UGQCk7Gcoy7"
   },
   "outputs": [],
   "source": [
    "# Inspired from https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/torchvision_finetuning_instance_segmentation.ipynb#scrollTo=YjNHjVMOyYlH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with only the last layer to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vuz8DJUgccUx"
   },
   "outputs": [],
   "source": [
    "def get_model_from_pretrained(num_classes):\n",
    "\n",
    "    # load an instance segmentation model pre-trained on COCO\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "    for param in model.parameters(): # to freeze all existing weights\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # get the number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with deeper layers to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_from_pretrained(num_classes):\n",
    "\n",
    "    # load an instance segmentation model pre-trained on COCO\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "    for param in model.parameters(): # to freeze all existing weights\n",
    "        param.requires_grad = False\n",
    "\n",
    "    for param in model.roi_heads.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    # get the number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "hbSuc8Jwc5qT"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# our dataset has two classes only - background and person\n",
    "num_classes = 2\n",
    "\n",
    "# get the model using our helper function\n",
    "model = get_model_from_pretrained(num_classes)\n",
    "\n",
    "# move model to the right device\n",
    "model.to(device)\n",
    "\n",
    "# construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.0003, momentum=0.9)\n",
    "\n",
    "# like in the paper, construct the scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=[5,10], gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the dataloaders\n",
    "To load the data of the dataset efficiently for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "hNli84Y1V-Az"
   },
   "outputs": [],
   "source": [
    "train_valid_img,_ = get_img_with_bbox(train_ann_path)\n",
    "train_data = CustomImageDataset(train_ann_path, img_folder, train_valid_img)\n",
    "train_dataloader = DataLoader(train_data, batch_size=1, shuffle=True, collate_fn=utils.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "NdZtIwI_iy9l"
   },
   "outputs": [],
   "source": [
    "trans_val_valid_img,_ = get_img_with_bbox(trans_val_ann_path)\n",
    "trans_valid_data = CustomImageDataset(trans_val_ann_path, img_folder, trans_val_valid_img)\n",
    "trans_valid_dataloader = DataLoader(trans_valid_data, batch_size=10, shuffle=True, collate_fn=utils.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "VdGh66kZ_8av"
   },
   "outputs": [],
   "source": [
    "cis_val_valid_img,_ = get_img_with_bbox(cis_val_ann_path)\n",
    "cis_valid_data = CustomImageDataset(cis_val_ann_path, img_folder, cis_val_valid_img)\n",
    "cis_valid_dataloader = DataLoader(cis_valid_data, batch_size=10, shuffle=True, collate_fn=utils.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cis_test_img,_ = get_img_with_bbox(cis_test_ann_path)\n",
    "cis_test_data = CustomImageDataset(cis_test_ann_path,img_folder, cis_test_img)\n",
    "cis_test_dataloader = DataLoader(cis_test_data, batch_size=10, shuffle=True, collate_fn=utils.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_test_img,_ = get_img_with_bbox(trans_test_ann_path)\n",
    "trans_test_data = CustomImageDataset(trans_test_ann_path,img_folder, trans_test_img)\n",
    "trans_test_dataloader = DataLoader(trans_test_data, batch_size=10, shuffle=True, collate_fn=utils.collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading/Importing a model\n",
    "#### Need to initiate the model, the optimizer and de scheduler before loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NEED TO INITIATE THE MODEL, THE OPTIMIZER AND THE SCHEDULER BEFOREHAND (if )\n",
    "# load the model, the optimizer and the scheduler\n",
    "model.load_state_dict(torch.load('saved_models/25_roi_model.pt'))\n",
    "optimizer.load_state_dict(torch.load('saved_models/25_roi_optimizer.pt'))\n",
    "lr_scheduler.load_state_dict(torch.load('saved_models/25_roi_scheduler.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logs utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train logs utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the smoothed values to a dictionnary of each values\n",
    "def smoothed_value_to_str(smoothed_value):\n",
    "    d_values = {}\n",
    "    d_values['median'] = smoothed_value.median\n",
    "    d_values['avg'] = smoothed_value.avg\n",
    "    d_values['global_avg'] = smoothed_value.global_avg\n",
    "    d_values['max'] = smoothed_value.max\n",
    "    d_values['value'] = smoothed_value.value\n",
    "    return d_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the train logs from MetricLogger to list\n",
    "def train_logs_to_lst(logs):\n",
    "    lst = []\n",
    "    for i in range(len(logs)):\n",
    "        d = {}\n",
    "        for key in logs[i].meters.keys():\n",
    "            d[key] = smoothed_value_to_str(logs[i].meters[key])\n",
    "        lst.append(d)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puts the training logs into a json file with time dependent file name\n",
    "def train_logs_to_json(logs, ftime=time.strftime(\"%Y%m%d_%H%M%S\")):\n",
    "    train_metric_logs = train_logs_to_lst(logs)\n",
    "    filename = ftime + \"_train_logs.json\"\n",
    "    \n",
    "    with open('saved_logs/' + filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(train_metric_logs, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Valid logs utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dicts of a list \n",
    "def merge_dict(logs):\n",
    "    logs_better = []\n",
    "    try:\n",
    "        for i in range(len(logs)):\n",
    "            logs_better.append({**logs[i][0], **logs[i][1], **logs[i][2], **logs[i][3]})\n",
    "        return logs_better\n",
    "    except:\n",
    "        print(logs[0])\n",
    "        logs_better = logs\n",
    "        return logs_better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the valid logs from list of dictionnaries to string\n",
    "def valid_logs_to_lst(valid_logs):\n",
    "    logs = merge_dict(valid_logs)\n",
    "    lst = []\n",
    "    for i in range(len(logs)):\n",
    "        d = {}\n",
    "        for key in logs[i].keys():\n",
    "            d[key] = logs[i][key].cpu().numpy().tolist()\n",
    "        lst.append(d)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puts the cis validation logs into a json file with time dependent file name\n",
    "def cis_valid_logs_to_json(logs, ftime=time.strftime(\"%Y%m%d_%H%M%S\")):\n",
    "    valid_metric_logs = valid_logs_to_lst(logs)\n",
    "    filename = ftime + \"_cis_valid_logs.json\"\n",
    "    \n",
    "    with open('saved_logs/' + filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(valid_metric_logs, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puts the trans validation logs into a json file with time dependent file name\n",
    "def trans_valid_logs_to_json(logs, ftime=time.strftime(\"%Y%m%d_%H%M%S\")):\n",
    "    valid_metric_logs = valid_logs_to_lst(logs)\n",
    "    filename = ftime + \"_trans_valid_logs.json\"\n",
    "    \n",
    "    with open('saved_logs/' + filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(valid_metric_logs, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS TO TUNE BEFORE TRAINING\n",
    "num_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1080 Ti'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CHECK DEVICE BEFORE TRAINING\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the train function\n",
    "def train(dataloader, num_epochs, save_logs=True, save_model=True, print_freq=100):\n",
    "    \n",
    "    all_train_logs = []\n",
    "    all_cis_valid_logs = []\n",
    "    all_trans_valid_logs = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        # train for one epoch, printing every 100 images\n",
    "        train_logs = train_one_epoch(model, optimizer, dataloader, device, epoch, print_freq)\n",
    "        all_train_logs.append(train_logs)\n",
    "        \n",
    "        # update the learning rate\n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        # evaluate on the validation dataset after training one epoch\n",
    "        for images, targets in trans_valid_dataloader: # can do batch of 10 prob.\n",
    "            images = [image.to(device) for image in images]\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                trans_loss_dict = model(images, targets)\n",
    "                trans_loss_dict = [{k: loss.to('cpu')} for k, loss in trans_loss_dict.items()]\n",
    "                all_trans_valid_logs.append(trans_loss_dict)\n",
    "\n",
    "\n",
    "        for images, targets in cis_valid_dataloader: # can do batch of 10 prob.\n",
    "            images = [image.to(device) for image in images]\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                cis_loss_dict = model(images, targets)\n",
    "                cis_loss_dict = [{k: loss.to('cpu')} for k, loss in cis_loss_dict.items()]\n",
    "                all_cis_valid_logs.append(cis_loss_dict)\n",
    "    \n",
    "    filetime = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    if save_logs:\n",
    "        \n",
    "        # save the train, cis valid and trans valid logs\n",
    "        train_logs_to_json(all_train_logs, filetime)\n",
    "        cis_valid_logs_to_json(all_cis_valid_logs, filetime)\n",
    "        trans_valid_logs_to_json(all_trans_valid_logs, filetime)\n",
    "        \n",
    "    if save_model:\n",
    "        \n",
    "        # save the model, the optimizer and the scheduler\n",
    "        torch.save(model.state_dict(), 'saved_models/' + filetime + 'model.pt')\n",
    "        torch.save(optimizer.state_dict(), 'saved_models/' + filetime + 'optimizer.pt')\n",
    "        torch.save(lr_scheduler.state_dict(), 'saved_models/' + filetime + 'scheduler.pt')\n",
    "    \n",
    "    return all_train_logs, all_trans_valid_logs, all_cis_valid_logs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This next cell starts the training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "all_train_logs, all_trans_valid_logs, all_cis_valid_logs = train(dataloader=train_dataloader, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the last training logs to variables\n",
    "##### Ensures that if you hit the training cell, you don't lose the variables containing the logs from the last run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_train_logs = all_train_logs\n",
    "last_trans_valid_logs = all_trans_valid_logs\n",
    "last_cis_valid_logs = all_cis_valid_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving manually every logs from training to json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves the log with the same time\n",
    "train_logs_to_json(last_train_logs)\n",
    "trans_valid_logs_to_json(last_trans_valid_logs)\n",
    "cis_valid_logs_to_json(last_cis_valid_logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model, the optimizer and the scheduler\n",
    "filetime = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "torch.save(model.state_dict(), 'saved_models/' + filetime + '_model.pt')\n",
    "torch.save(optimizer.state_dict(), 'saved_models/' + filetime + '_optimizer.pt')\n",
    "torch.save(lr_scheduler.state_dict(), 'saved_models/' + filetime + '_scheduler.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration of the raw logs\n",
    "##### Only look at the MetricLogger if you just trained the model. You cannot import the model and then check the MetricLogger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_logs[0].meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_logs[0].meters['loss_box_reg'].global_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we check the amount of logs per epoch for each categories and the type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_cis_valid_logs[0])\n",
    "print(\"total length:\", len(all_cis_valid_logs))\n",
    "print(\"-\"*8)\n",
    "print(\"per epoch length:\", len(all_cis_valid_logs)/num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_trans_valid_logs[0])\n",
    "print(\"total length:\", len(all_trans_valid_logs))\n",
    "print(\"-\"*8)\n",
    "print(\"per epoch length:\", len(all_trans_valid_logs)/num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at/Loading the logs in convenient ways\n",
    "Here we define the variables \"train_logs\", \"cis_valid_logs\" and \"trans_valid_logs\" that will be used in the methods for the results and the visualisations.\n",
    "\n",
    "We can import logs or use the ones from training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPTIONAL - Can load some logs right here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imported logs - format: name = \"NAME_OR_TIME\"      Exemple file format: \"NAME_OR_TIME_train_logs\"\n",
    "\n",
    "file_time_or_nickname = '25_roi' # VALUE TO CHANGE TO THE IMPORTED FILES\n",
    "\n",
    "# Import training logs\n",
    "with open('saved_logs/' + file_time_or_nickname + '_train_logs.json', \"r\") as f:\n",
    "    train_logs = train_logs + json.load(f)\n",
    "\n",
    "# Import cis valid logs\n",
    "with open('saved_logs/' + file_time_or_nickname + '_cis_valid_logs.json', \"r\") as f:\n",
    "    cis_valid_logs = cis_valid_logs + json.load(f)\n",
    "\n",
    "# Import trans valid logs\n",
    "with open('saved_logs/' + file_time_or_nickname + '_trans_valid_logs.json', \"r\") as f:\n",
    "    trans_valid_logs = trans_valid_logs + json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPTIONAL - Combine 2 loaded logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imported logs - format: name = \"NAME_OR_TIME\"      Exemple file format: \"NAME_OR_TIME_train_logs\"\n",
    "\n",
    "file_time_or_nickname = '10_roi' # VALUE TO CHANGE TO THE IMPORTED FILES\n",
    "\n",
    "# Import training logs\n",
    "with open('saved_logs/' + file_time_or_nickname + '_train_logs.json', \"r\") as f:\n",
    "    train_logs = json.load(f)\n",
    "\n",
    "# Import cis valid logs\n",
    "with open('saved_logs/' + file_time_or_nickname + '_cis_valid_logs.json', \"r\") as f:\n",
    "    cis_valid_logs = json.load(f)\n",
    "\n",
    "# Import trans valid logs\n",
    "with open('saved_logs/' + file_time_or_nickname + '_trans_valid_logs.json', \"r\") as f:\n",
    "    trans_valid_logs = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put the last trained logs into convenient list variables\n",
    "##### Converts the logs to lists and the tensors to numpy - ONLY IF MODEL HAVE BEEN TRAINED IN THIS KERNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_logs = train_logs_to_lst(last_train_logs)\n",
    "cis_valid_logs = valid_logs_to_lst(last_cis_valid_logs)\n",
    "trans_valid_logs = valid_logs_to_lst(last_trans_valid_logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To confirm that the data is loaded properly\n",
    "len(train_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train loss to print (here we use global_avg but we can use: value, median, avg, max or global_avg)\n",
    "results_train_loss = []\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    results_train_loss.append(train_logs[i]['loss_box_reg']['global_avg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cis valid loss to print\n",
    "results_cis_valid_loss = [] # cis\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    loss_interm = 0\n",
    "    for j in range(167):\n",
    "        loss_interm += cis_valid_logs[(167 * i) + j]['loss_box_reg']\n",
    "    results_cis_valid_loss.append(loss_interm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trans valid loss to print\n",
    "results_trans_valid_loss = [] # cis\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    loss_interm = 0\n",
    "    for j in range(154):\n",
    "        loss_interm += trans_valid_logs[(154 * i) + j]['loss_box_reg']\n",
    "    results_trans_valid_loss.append(loss_interm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the different plots\n",
    "fig, ax = plt.subplots(1,2, figsize=(20,6))\n",
    "\n",
    "ax[0].plot(np.arange(1, num_epochs + 1), results_train_loss, label='train')\n",
    "ax[0].set_title('Train loss per epoch')\n",
    "ax[0].set_ylabel('loss_box_reg')\n",
    "ax[0].set_xlabel('epoch')\n",
    "\n",
    "plt.title('Train loss per epoch')\n",
    "ax[1].plot(np.arange(1, num_epochs + 1), results_cis_valid_loss, label='cis')\n",
    "ax[1].plot(np.arange(1, num_epochs + 1), results_trans_valid_loss, label='trans')\n",
    "ax[1].set_title('Valid loss per epoch')\n",
    "ax[1].set_ylabel('loss_box_reg')\n",
    "ax[1].set_xlabel('epoch')\n",
    "ax[1].legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the figure to pdf format in the figures folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"figures/25_epochs_normal_baseline.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPV4Pxyajekr"
   },
   "source": [
    "## Make Predictions with a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPTIONAL - Can load a model right here to test the predictions quickly\n",
    "#### Need to initiate the model, the optimizer and de scheduler before loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEED TO INITIATE THE MODEL, THE OPTIMIZER AND THE SCHEDULER BEFOREHAND (if )\n",
    "# load the model, the optimizer and the scheduler\n",
    "model.load_state_dict(torch.load('saved_models/25_roi_model.pt'))\n",
    "optimizer.load_state_dict(torch.load('saved_models/25_roi_optimizer.pt'))\n",
    "lr_scheduler.load_state_dict(torch.load('saved_models/25_roi_scheduler.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1dTlEPVhRVHE"
   },
   "outputs": [],
   "source": [
    "train_features, train_labels = next(iter(trans_valid_dataloader))\n",
    "image = list(image.to(device) for image in train_features)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "      pred = model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints 10 images with the predictions before and after NMS\n",
    "for image_i in range(len(image)):\n",
    "    fig, ax = plt.subplots(1,3,figsize=(24,16))\n",
    "\n",
    "    ax[0].imshow(train_features[image_i][0].squeeze(),cmap=\"gray\")\n",
    "    rect = patches.Rectangle((train_labels[image_i]['boxes'][0][0], \n",
    "                              train_labels[image_i]['boxes'][0][1]), \n",
    "                             train_labels[image_i]['boxes'][0][2]-train_labels[image_i]['boxes'][0][0], \n",
    "                             train_labels[image_i]['boxes'][0][3]-train_labels[image_i]['boxes'][0][1], \n",
    "                             linewidth=2, edgecolor='r', facecolor='none')\n",
    "    ax[0].add_patch(rect)\n",
    "    ax[0].set_title('Ground truth')\n",
    "\n",
    "    # Predictions\n",
    "    ax[1].imshow(train_features[image_i][0].squeeze(),cmap=\"gray\")\n",
    "    for i in range(len(pred[image_i]['boxes'])):\n",
    "        rect = patches.Rectangle((pred[image_i]['boxes'][i][0].cpu(), \n",
    "                                  pred[image_i]['boxes'][i][1].cpu()), \n",
    "                                 (pred[image_i]['boxes'][i][2]-pred[image_i]['boxes'][i][0]).cpu(), \n",
    "                                 (pred[image_i]['boxes'][i][3]-pred[image_i]['boxes'][i][1]).cpu(), \n",
    "                                 linewidth=2, edgecolor='r', facecolor='none')\n",
    "        ax[1].add_patch(rect)\n",
    "    ax[1].set_title('Pred')\n",
    "\n",
    "    # Predictions after NMS\n",
    "    iou_threshold = 0.01 # param to tune\n",
    "    boxes_to_keep = torchvision.ops.nms(pred[image_i]['boxes'], pred[image_i]['scores'], iou_threshold = iou_threshold).cpu()\n",
    "    ax[2].imshow(train_features[image_i][0].squeeze(),cmap=\"gray\")\n",
    "    for i in boxes_to_keep:\n",
    "        rect = patches.Rectangle((pred[image_i]['boxes'][i][0].cpu(), \n",
    "                                  pred[image_i]['boxes'][i][1].cpu()), \n",
    "                                 (pred[image_i]['boxes'][i][2]-pred[image_i]['boxes'][i][0]).cpu(), \n",
    "                                 (pred[image_i]['boxes'][i][3]-pred[image_i]['boxes'][i][1]).cpu(), \n",
    "                                 linewidth=2, edgecolor='r', facecolor='none')\n",
    "        ax[2].add_patch(rect)\n",
    "\n",
    "    ax[2].set_title('After NMS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368
    },
    "id": "tkwIJ6cCeRq3",
    "outputId": "33012e5f-2664-46ef-fa1e-b54bf5e2faf5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print a single image chosen by index from the last batch of 10 predictions\n",
    "image_i = 0 # from 0 to 9 included\n",
    "\n",
    "fig, ax = plt.subplots(1,3,figsize=(24,16))\n",
    "\n",
    "ax[0].imshow(train_features[image_i][0].squeeze(),cmap=\"gray\")\n",
    "rect = patches.Rectangle((train_labels[image_i]['boxes'][0][0], \n",
    "                          train_labels[image_i]['boxes'][0][1]), \n",
    "                         train_labels[image_i]['boxes'][0][2]-train_labels[image_i]['boxes'][0][0], \n",
    "                         train_labels[image_i]['boxes'][0][3]-train_labels[image_i]['boxes'][0][1], \n",
    "                         linewidth=2, edgecolor='r', facecolor='none')\n",
    "ax[0].add_patch(rect)\n",
    "ax[0].set_title('Ground truth')\n",
    "\n",
    "# Predictions\n",
    "ax[1].imshow(train_features[image_i][0].squeeze(),cmap=\"gray\")\n",
    "for i in range(len(pred[image_i]['boxes'])):\n",
    "    rect = patches.Rectangle((pred[image_i]['boxes'][i][0].cpu(), \n",
    "                              pred[image_i]['boxes'][i][1].cpu()), \n",
    "                             (pred[image_i]['boxes'][i][2]-pred[image_i]['boxes'][i][0]).cpu(), \n",
    "                             (pred[image_i]['boxes'][i][3]-pred[image_i]['boxes'][i][1]).cpu(), \n",
    "                             linewidth=2, edgecolor='r', facecolor='none')\n",
    "    ax[1].add_patch(rect)\n",
    "ax[1].set_title('Pred')\n",
    "\n",
    "# Predictions after NMS\n",
    "iou_threshold = 0.01 # param to tune\n",
    "boxes_to_keep = torchvision.ops.nms(pred[image_i]['boxes'], pred[image_i]['scores'], iou_threshold = iou_threshold).cpu()\n",
    "ax[2].imshow(train_features[image_i][0].squeeze(),cmap=\"gray\")\n",
    "for i in boxes_to_keep:\n",
    "    rect = patches.Rectangle((pred[image_i]['boxes'][i][0].cpu(), \n",
    "                              pred[image_i]['boxes'][i][1].cpu()), \n",
    "                             (pred[image_i]['boxes'][i][2]-pred[image_i]['boxes'][i][0]).cpu(), \n",
    "                             (pred[image_i]['boxes'][i][3]-pred[image_i]['boxes'][i][1]).cpu(), \n",
    "                             linewidth=2, edgecolor='r', facecolor='none')\n",
    "    ax[2].add_patch(rect)\n",
    "\n",
    "ax[2].set_title('After NMS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[image_i]['boxes'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels[image_i]['boxes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evalutate on COCO detection metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cis Test on COCO metrics\n",
    "##### 'For evaluation, we consider a detected box to be correct if its IoU  0.5 with a ground truth box.'\n",
    "\n",
    "We need to look at the precison score with IoU=0.5, area=all and maxDets=100.\n",
    "For the recall score, by default it's IoU=0.5:IoU=0.95."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluate perfo on COCO detection metrics\n",
    "\n",
    "# takes +- 25min to run on cis_test\n",
    "\n",
    "from coco_utils import get_coco_api_from_dataset\n",
    "from coco_eval import CocoEvaluator\n",
    "from engine import _get_iou_types \n",
    "\n",
    "apply_nms = True\n",
    "iou_threshold = 0.35 # param to potentially tune\n",
    "the_data_loader = cis_test_dataloader # change to test set\n",
    "\n",
    "coco = get_coco_api_from_dataset(the_data_loader.dataset)\n",
    "iou_types = _get_iou_types(model)\n",
    "coco_evaluator = CocoEvaluator(coco, iou_types)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for images, targets in the_data_loader:\n",
    "    images = [image.to(device) for image in images]\n",
    "    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        pred=model(images)\n",
    "\n",
    "        if apply_nms:\n",
    "            boxes_to_keep = torchvision.ops.nms(pred[0]['boxes'], pred[0]['scores'], iou_threshold=iou_threshold).cpu()\n",
    "            pred[0]['boxes'] = pred[0]['boxes'][boxes_to_keep]\n",
    "            pred[0]['labels'] = pred[0]['labels'][boxes_to_keep]\n",
    "            pred[0]['scores'] = pred[0]['scores'][boxes_to_keep]\n",
    "\n",
    "        outputs = [{k: v.cpu() for k, v in t.items()} for t in pred]\n",
    "        res = {target[\"image_id\"].item(): output for target, output in zip(targets, outputs)}\n",
    "        coco_evaluator.update(res)\n",
    "\n",
    "coco_evaluator.synchronize_between_processes()\n",
    "coco_evaluator.accumulate()\n",
    "print('_'*20)\n",
    "print('Cis Test Data - Summary')\n",
    "print(\" \")\n",
    "coco_evaluator.summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trans Test on COCO metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate perfo on COCO detection metrics\n",
    "\n",
    "# takes +- 25min to run on trans_test\n",
    "\n",
    "from coco_utils import get_coco_api_from_dataset\n",
    "from coco_eval import CocoEvaluator\n",
    "from engine import _get_iou_types \n",
    "\n",
    "apply_nms = True\n",
    "iou_threshold = 0.35 # param to potentially tune\n",
    "the_data_loader = trans_test_dataloader # change to test set\n",
    "\n",
    "coco = get_coco_api_from_dataset(the_data_loader.dataset)\n",
    "iou_types = _get_iou_types(model)\n",
    "coco_evaluator = CocoEvaluator(coco, iou_types)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for images, targets in the_data_loader:\n",
    "    images = [image.to(device) for image in images]\n",
    "    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        pred=model(images)\n",
    "\n",
    "        if apply_nms:\n",
    "            boxes_to_keep = torchvision.ops.nms(pred[0]['boxes'], pred[0]['scores'], iou_threshold=iou_threshold).cpu()\n",
    "            pred[0]['boxes'] = pred[0]['boxes'][boxes_to_keep]\n",
    "            pred[0]['labels'] = pred[0]['labels'][boxes_to_keep]\n",
    "            pred[0]['scores'] = pred[0]['scores'][boxes_to_keep]\n",
    "\n",
    "        outputs = [{k: v.cpu() for k, v in t.items()} for t in pred]\n",
    "        res = {target[\"image_id\"].item(): output for target, output in zip(targets, outputs)}\n",
    "        coco_evaluator.update(res)\n",
    "\n",
    "coco_evaluator.synchronize_between_processes()\n",
    "coco_evaluator.accumulate()\n",
    "print('_'*20)\n",
    "print('Trans Test Data - Summary')\n",
    "print(\" \")\n",
    "coco_evaluator.summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3 (Subspace alignment based Domain adaptation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.ops.boxes as bops\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Papers \n",
    "\n",
    " 1. https://arxiv.org/pdf/1507.05578.pdf\n",
    "\n",
    " 2.  https://openaccess.thecvf.com/content_iccv_2013/papers/Fernando_Unsupervised_Visual_Domain_2013_ICCV_paper.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Construct source matrix:** \n",
    "\n",
    "We keep output of model.roi_heads.box_head (vector of size 1024) as feature representations of bounding boxes extracted by the RPN (region proposal network). For us to stack a box representation to the source matrix, it has to have a IoU > thres_IoU with the ground truth of the given image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 minutes\n",
    "thres_IoU= 0.50\n",
    "count=0\n",
    "\n",
    "X_source=torch.tensor([])\n",
    "bbox_idx=torch.arange(1000)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for images, targets in train_dataloader: \n",
    "    images = [image.to(device) for image in images]\n",
    "    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "    count+=1\n",
    "\n",
    "    if count%100==0:\n",
    "        print(count)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = []\n",
    "        hook = model.rpn.register_forward_hook(\n",
    "        lambda self, input, output: outputs.append(output))\n",
    "\n",
    "        outputs1 = []\n",
    "        hook1 = model.roi_heads.box_head.register_forward_hook(\n",
    "        lambda self, input, output: outputs1.append(output))\n",
    "\n",
    "        res = model(images)\n",
    "        hook.remove()\n",
    "        hook1.remove()\n",
    "\n",
    "    coords = outputs[0][0][0].cpu() # [1000,4]\n",
    "    feat=outputs1[0].cpu() # [1000, 1024]\n",
    "\n",
    "    gt = targets[0]['boxes'].cpu()\n",
    "\n",
    "    bbox_idx_to_keep=torch.tensor([])\n",
    "    for i in range(gt.shape[0]):\n",
    "\n",
    "        IoUs=bops.box_iou(gt[i].reshape(1,4), coords)\n",
    "        IoUs = IoUs.reshape(1000)\n",
    "        bbox_idx_to_keep = torch.cat((bbox_idx_to_keep, bbox_idx[IoUs >= thres_IoU]),dim=0)\n",
    "\n",
    "    X_source = torch.cat((X_source,feat[torch.unique(bbox_idx_to_keep).long()]), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_source.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(X_source, 'saved_data/X_source_05_roi.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# center data\n",
    "scaler = StandardScaler()\n",
    "X_source_scaled = scaler.fit_transform(X_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA, keep only the first 100 components which gives the Projected source matrix\n",
    "\n",
    "pca = PCA(n_components=100)\n",
    "pca.fit(X_source_scaled)\n",
    "\n",
    "X_source_proj = pca.components_\n",
    "X_source_proj = torch.from_numpy(X_source_proj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_source_proj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pca.explained_variance_ratio_) \n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(X_source_proj, 'saved_data/X_source_proj_05_roi.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target data with batch size 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target data/distribution = trans test set - Batch Size 1\n",
    "trans_test_batch1_img,_ = get_img_with_bbox(trans_test_ann_path)\n",
    "trans_test_batch1_data = CustomImageDataset(trans_test_ann_path, img_folder, trans_test_batch1_img)\n",
    "trans_test_batch1_dataloader = DataLoader(trans_test_batch1_data, batch_size=1, shuffle=True, collate_fn=utils.collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Construct target matrix:** \n",
    " \n",
    "We keep output of model.roi_heads.box_head (vector of size 1024) as feature representations of bounding boxes\n",
    " extracted by the RPN (region proposal network). For us to stack a box representation to the source matrix, the predicted bbox associated with the feature has to have a confidence score > thres_conf_score (since we don't use target labels we can't use the IoU here).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 minutes\n",
    "thres_conf_score= 0.50 \n",
    "count=0\n",
    "\n",
    "X_target=torch.tensor([])\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for images, targets in trans_test_batch1_dataloader: # trans location valid AND test ?\n",
    "    images = [image.to(device) for image in images]\n",
    "    targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "    count+=1\n",
    "\n",
    "    if count%100==0:\n",
    "        print(count)\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        outputs = []\n",
    "        hook = model.backbone.register_forward_hook(\n",
    "        lambda self, input, output: outputs.append(output))\n",
    "        res = model(images)\n",
    "        hook.remove()\n",
    "\n",
    "        box_features = model.roi_heads.box_roi_pool(outputs[0], [r['boxes'] for r in res], [i.shape[-2:] for i in images])\n",
    "        box_features = model.roi_heads.box_head(box_features)\n",
    "\n",
    "    X_target = torch.cat((X_target,box_features[res[0]['scores']>=thres_conf_score].cpu()), dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(X_target, 'saved_data/X_target_05_roi.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# center data\n",
    "scaler = StandardScaler()\n",
    "X_target_scaled = scaler.fit_transform(X_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA, keep only the first 100 components which gives the Projected source matrix\n",
    "\n",
    "pca_proj = PCA(n_components=100)\n",
    "pca_proj.fit(X_target_scaled)\n",
    "\n",
    "X_target_proj = pca_proj.components_\n",
    "X_target_proj = torch.from_numpy(X_target_proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(pca_proj.explained_variance_ratio_) # we keep 100 dimensions\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_target_proj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(X_target_proj, 'saved_data/X_target_proj_05_roi.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation matrix M\n",
    "\n",
    " is obtained by minimizing the following Bregman matrix divergence (following closed-form solution given in the paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = torch.matmul(X_source_proj, X_target_proj.T) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project source data into target aligned source subspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xa= torch.matmul(X_source_proj.T,M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To project a given feature\n",
    "\n",
    "# feat(1,1024) x Xa (1024,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projet target data in target subspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To project a given feature\n",
    "\n",
    "# feat(1,1024) x X_target_proj.T (1024,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train adapted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loda because it takes time to generate the following matrices so they are saved\n",
    "X_source_proj = torch.load('saved_data/X_source_proj_05_roi.pt')\n",
    "X_target_proj = torch.load('saved_data/X_target_proj_05_roi.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_source_proj.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 100])\n",
      "torch.Size([1024, 100])\n"
     ]
    }
   ],
   "source": [
    "M = torch.matmul(X_source_proj, X_target_proj.T) # transformation matrix\n",
    "print(M.shape)\n",
    "\n",
    "Xa = torch.matmul(X_source_proj.T,M) # target aligned source subspace\n",
    "print(Xa.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-8.3206e-02,  8.6303e-01,  1.4386e-01,  ...,  1.8172e-02,\n",
       "          8.6311e-03,  2.3675e-03],\n",
       "        [ 7.7480e-01,  1.3245e-01, -7.4946e-03,  ...,  4.0069e-03,\n",
       "          4.4142e-03, -1.6273e-02],\n",
       "        [-1.7604e-01,  1.6074e-01,  3.3943e-01,  ..., -5.0102e-02,\n",
       "         -4.0499e-02,  6.5427e-04],\n",
       "        ...,\n",
       "        [ 2.1474e-03,  1.2598e-03, -1.7591e-03,  ...,  3.9705e-02,\n",
       "         -4.7052e-02, -4.1430e-02],\n",
       "        [-1.1055e-02,  5.6693e-04,  1.3001e-02,  ..., -1.9011e-02,\n",
       "         -7.1657e-02, -5.2998e-02],\n",
       "        [ 1.4891e-02, -2.4838e-03,  3.5215e-03,  ..., -8.3762e-02,\n",
       "         -6.9656e-02, -2.7392e-02]], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0357,  0.0360, -0.0238,  ...,  0.0073, -0.0138,  0.0083],\n",
       "        [-0.0327,  0.0501,  0.0064,  ...,  0.0173,  0.0304,  0.0372],\n",
       "        [-0.0044, -0.0373, -0.0271,  ..., -0.0026,  0.0218, -0.0077],\n",
       "        ...,\n",
       "        [ 0.0277,  0.0458, -0.0143,  ..., -0.0438, -0.0245,  0.0184],\n",
       "        [-0.0575,  0.0260, -0.0327,  ...,  0.0186, -0.0134, -0.0029],\n",
       "        [ 0.0359,  0.0597, -0.0025,  ...,  0.0019, -0.0027,  0.0059]],\n",
       "       device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xa.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastRCNNPredictor_custom(nn.Module):\n",
    "    \"\"\"\n",
    "    Standard classification + bounding box regression layers\n",
    "    for Fast R-CNN.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): number of input channels\n",
    "        num_classes (int): number of output classes (including background)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, num_classes, m_transfo):\n",
    "        super(FastRCNNPredictor_custom, self).__init__()\n",
    "        self.cls_score = nn.Sequential(nn.Linear(in_features = 1024, out_features = 100, bias=False), nn.Linear(in_channels, num_classes))\n",
    "        self.bbox_pred = nn.Sequential(nn.Linear(in_features = 1024, out_features = 100, bias=False), nn.Linear(in_channels, num_classes * 4))\n",
    "        self.cls_score[0].weight= nn.Parameter(m_transfo, requires_grad = False)\n",
    "        self.bbox_pred[0].weight= nn.Parameter(m_transfo, requires_grad = False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.dim() == 4:\n",
    "            assert list(x.shape[2:]) == [1, 1]\n",
    "        x = x.flatten(start_dim=1)\n",
    "        scores = self.cls_score(x)\n",
    "        bbox_deltas = self.bbox_pred(x)\n",
    "\n",
    "        return scores, bbox_deltas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# our dataset has two classes only - background and person\n",
    "num_classes = 2\n",
    "\n",
    "# get the model using our helper function\n",
    "model = get_model_from_pretrained(num_classes)\n",
    "\n",
    "# move model to the right device\n",
    "model.to(device)\n",
    "\n",
    "# load fine-tuned weights\n",
    "model.load_state_dict(torch.load('saved_models/25_roi_model.pt'))\n",
    "\n",
    "\n",
    "for param in model.parameters(): # to freeze all existing weights\n",
    "\n",
    "    param.requires_grad = False\n",
    "\n",
    "# vector are of size 100 after the transformation\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor_custom(in_channels=100, num_classes=2, m_transfo=Xa.T.float()) \n",
    "\n",
    "# move model to the right device\n",
    "model.to(device)\n",
    "\n",
    "# construct an optimizer\n",
    "# We will only retrain model.roi_heads.box_predictor (2 last layers)\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.0003, momentum=0.9)\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=[5,10], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 100])\n",
      "torch.Size([2])\n",
      "torch.Size([8, 100])\n",
      "torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "# weights to learn\n",
    "for i in range(4):\n",
    "\n",
    "    print(params[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\miniconda3\\envs\\animals\\lib\\site-packages\\torch\\functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [    0/12099]  eta: 3:46:16  lr: 0.000001  loss: 0.6835 (0.6835)  loss_classifier: 0.4782 (0.4782)  loss_box_reg: 0.2016 (0.2016)  loss_objectness: 0.0026 (0.0026)  loss_rpn_box_reg: 0.0010 (0.0010)  time: 1.1221  data: 0.0355  max mem: 1064\n",
      "Epoch: [0]  [  100/12099]  eta: 0:27:05  lr: 0.000031  loss: 0.4748 (0.5495)  loss_classifier: 0.2551 (0.3614)  loss_box_reg: 0.1492 (0.1482)  loss_objectness: 0.0066 (0.0327)  loss_rpn_box_reg: 0.0023 (0.0073)  time: 0.1245  data: 0.0352  max mem: 1064\n",
      "Epoch: [0]  [  200/12099]  eta: 0:25:38  lr: 0.000061  loss: 0.2541 (0.4354)  loss_classifier: 0.1074 (0.2555)  loss_box_reg: 0.1258 (0.1414)  loss_objectness: 0.0053 (0.0321)  loss_rpn_box_reg: 0.0018 (0.0064)  time: 0.1199  data: 0.0329  max mem: 1064\n",
      "Epoch: [0]  [  300/12099]  eta: 0:25:44  lr: 0.000091  loss: 0.2734 (0.3846)  loss_classifier: 0.0997 (0.2051)  loss_box_reg: 0.1204 (0.1381)  loss_objectness: 0.0099 (0.0343)  loss_rpn_box_reg: 0.0035 (0.0072)  time: 0.1307  data: 0.0357  max mem: 1064\n",
      "Epoch: [0]  [  400/12099]  eta: 0:25:30  lr: 0.000120  loss: 0.2448 (0.3562)  loss_classifier: 0.0786 (0.1766)  loss_box_reg: 0.0898 (0.1381)  loss_objectness: 0.0165 (0.0340)  loss_rpn_box_reg: 0.0049 (0.0075)  time: 0.1291  data: 0.0360  max mem: 1064\n",
      "Epoch: [0]  [  500/12099]  eta: 0:25:33  lr: 0.000150  loss: 0.2326 (0.3366)  loss_classifier: 0.0754 (0.1575)  loss_box_reg: 0.1304 (0.1380)  loss_objectness: 0.0065 (0.0339)  loss_rpn_box_reg: 0.0023 (0.0073)  time: 0.1315  data: 0.0381  max mem: 1064\n",
      "Epoch: [0]  [  600/12099]  eta: 0:25:07  lr: 0.000180  loss: 0.2389 (0.3250)  loss_classifier: 0.0734 (0.1446)  loss_box_reg: 0.1354 (0.1388)  loss_objectness: 0.0039 (0.0342)  loss_rpn_box_reg: 0.0016 (0.0075)  time: 0.1339  data: 0.0373  max mem: 1064\n",
      "Epoch: [0]  [  700/12099]  eta: 0:24:58  lr: 0.000210  loss: 0.2336 (0.3136)  loss_classifier: 0.0764 (0.1344)  loss_box_reg: 0.1392 (0.1380)  loss_objectness: 0.0044 (0.0338)  loss_rpn_box_reg: 0.0030 (0.0074)  time: 0.1298  data: 0.0352  max mem: 1064\n",
      "Epoch: [0]  [  800/12099]  eta: 0:24:41  lr: 0.000240  loss: 0.2319 (0.3057)  loss_classifier: 0.0617 (0.1263)  loss_box_reg: 0.0972 (0.1372)  loss_objectness: 0.0161 (0.0344)  loss_rpn_box_reg: 0.0044 (0.0077)  time: 0.1207  data: 0.0331  max mem: 1064\n",
      "Epoch: [0]  [  900/12099]  eta: 0:24:17  lr: 0.000270  loss: 0.2041 (0.2971)  loss_classifier: 0.0440 (0.1187)  loss_box_reg: 0.1206 (0.1353)  loss_objectness: 0.0033 (0.0353)  loss_rpn_box_reg: 0.0025 (0.0078)  time: 0.1277  data: 0.0362  max mem: 1064\n",
      "Epoch: [0]  [ 1000/12099]  eta: 0:24:00  lr: 0.000300  loss: 0.2169 (0.2891)  loss_classifier: 0.0490 (0.1125)  loss_box_reg: 0.1541 (0.1330)  loss_objectness: 0.0011 (0.0357)  loss_rpn_box_reg: 0.0031 (0.0079)  time: 0.1191  data: 0.0320  max mem: 1064\n",
      "Epoch: [0]  [ 1100/12099]  eta: 0:23:40  lr: 0.000300  loss: 0.1852 (0.2819)  loss_classifier: 0.0464 (0.1069)  loss_box_reg: 0.1249 (0.1319)  loss_objectness: 0.0012 (0.0354)  loss_rpn_box_reg: 0.0020 (0.0077)  time: 0.1227  data: 0.0332  max mem: 1064\n",
      "Epoch: [0]  [ 1200/12099]  eta: 0:23:20  lr: 0.000300  loss: 0.2075 (0.2746)  loss_classifier: 0.0468 (0.1020)  loss_box_reg: 0.1286 (0.1297)  loss_objectness: 0.0061 (0.0352)  loss_rpn_box_reg: 0.0021 (0.0078)  time: 0.1198  data: 0.0324  max mem: 1064\n",
      "Epoch: [0]  [ 1300/12099]  eta: 0:23:02  lr: 0.000300  loss: 0.1727 (0.2689)  loss_classifier: 0.0366 (0.0977)  loss_box_reg: 0.0823 (0.1279)  loss_objectness: 0.0056 (0.0351)  loss_rpn_box_reg: 0.0022 (0.0081)  time: 0.1280  data: 0.0370  max mem: 1064\n",
      "Epoch: [0]  [ 1400/12099]  eta: 0:22:44  lr: 0.000300  loss: 0.1722 (0.2639)  loss_classifier: 0.0366 (0.0942)  loss_box_reg: 0.1041 (0.1275)  loss_objectness: 0.0024 (0.0343)  loss_rpn_box_reg: 0.0019 (0.0079)  time: 0.1198  data: 0.0318  max mem: 1064\n",
      "Epoch: [0]  [ 1500/12099]  eta: 0:22:35  lr: 0.000300  loss: 0.1512 (0.2596)  loss_classifier: 0.0371 (0.0908)  loss_box_reg: 0.0863 (0.1254)  loss_objectness: 0.0147 (0.0353)  loss_rpn_box_reg: 0.0035 (0.0081)  time: 0.1295  data: 0.0359  max mem: 1064\n",
      "Epoch: [0]  [ 1600/12099]  eta: 0:22:28  lr: 0.000300  loss: 0.1669 (0.2543)  loss_classifier: 0.0404 (0.0878)  loss_box_reg: 0.0847 (0.1236)  loss_objectness: 0.0191 (0.0350)  loss_rpn_box_reg: 0.0042 (0.0080)  time: 0.1439  data: 0.0425  max mem: 1064\n",
      "Epoch: [0]  [ 1700/12099]  eta: 0:22:28  lr: 0.000300  loss: 0.1571 (0.2496)  loss_classifier: 0.0303 (0.0849)  loss_box_reg: 0.0725 (0.1213)  loss_objectness: 0.0075 (0.0353)  loss_rpn_box_reg: 0.0033 (0.0080)  time: 0.1383  data: 0.0373  max mem: 1064\n",
      "Epoch: [0]  [ 1800/12099]  eta: 0:22:24  lr: 0.000300  loss: 0.1556 (0.2451)  loss_classifier: 0.0313 (0.0824)  loss_box_reg: 0.1006 (0.1195)  loss_objectness: 0.0095 (0.0351)  loss_rpn_box_reg: 0.0040 (0.0081)  time: 0.1486  data: 0.0428  max mem: 1064\n",
      "Epoch: [0]  [ 1900/12099]  eta: 0:22:20  lr: 0.000300  loss: 0.1495 (0.2416)  loss_classifier: 0.0317 (0.0803)  loss_box_reg: 0.1040 (0.1183)  loss_objectness: 0.0036 (0.0349)  loss_rpn_box_reg: 0.0033 (0.0081)  time: 0.1390  data: 0.0370  max mem: 1064\n",
      "Epoch: [0]  [ 2000/12099]  eta: 0:22:12  lr: 0.000300  loss: 0.1400 (0.2377)  loss_classifier: 0.0348 (0.0782)  loss_box_reg: 0.0705 (0.1164)  loss_objectness: 0.0029 (0.0350)  loss_rpn_box_reg: 0.0018 (0.0081)  time: 0.1427  data: 0.0394  max mem: 1064\n",
      "Epoch: [0]  [ 2100/12099]  eta: 0:22:04  lr: 0.000300  loss: 0.1402 (0.2349)  loss_classifier: 0.0372 (0.0765)  loss_box_reg: 0.0731 (0.1148)  loss_objectness: 0.0040 (0.0353)  loss_rpn_box_reg: 0.0062 (0.0083)  time: 0.1454  data: 0.0398  max mem: 1064\n",
      "Epoch: [0]  [ 2200/12099]  eta: 0:21:52  lr: 0.000300  loss: 0.1313 (0.2313)  loss_classifier: 0.0273 (0.0747)  loss_box_reg: 0.0783 (0.1135)  loss_objectness: 0.0044 (0.0349)  loss_rpn_box_reg: 0.0040 (0.0082)  time: 0.1377  data: 0.0395  max mem: 1064\n",
      "Epoch: [0]  [ 2300/12099]  eta: 0:21:44  lr: 0.000300  loss: 0.1080 (0.2278)  loss_classifier: 0.0272 (0.0730)  loss_box_reg: 0.0716 (0.1119)  loss_objectness: 0.0035 (0.0348)  loss_rpn_box_reg: 0.0021 (0.0081)  time: 0.1306  data: 0.0347  max mem: 1064\n",
      "Epoch: [0]  [ 2400/12099]  eta: 0:21:32  lr: 0.000300  loss: 0.1397 (0.2254)  loss_classifier: 0.0372 (0.0717)  loss_box_reg: 0.0859 (0.1107)  loss_objectness: 0.0096 (0.0349)  loss_rpn_box_reg: 0.0034 (0.0081)  time: 0.1344  data: 0.0365  max mem: 1064\n",
      "Epoch: [0]  [ 2500/12099]  eta: 0:21:19  lr: 0.000300  loss: 0.1237 (0.2224)  loss_classifier: 0.0321 (0.0703)  loss_box_reg: 0.0623 (0.1090)  loss_objectness: 0.0162 (0.0351)  loss_rpn_box_reg: 0.0039 (0.0081)  time: 0.1294  data: 0.0349  max mem: 1064\n",
      "Epoch: [0]  [ 2600/12099]  eta: 0:21:05  lr: 0.000300  loss: 0.1182 (0.2196)  loss_classifier: 0.0248 (0.0689)  loss_box_reg: 0.0675 (0.1076)  loss_objectness: 0.0048 (0.0350)  loss_rpn_box_reg: 0.0029 (0.0080)  time: 0.1338  data: 0.0358  max mem: 1064\n",
      "Epoch: [0]  [ 2700/12099]  eta: 0:20:54  lr: 0.000300  loss: 0.1252 (0.2165)  loss_classifier: 0.0282 (0.0677)  loss_box_reg: 0.0707 (0.1060)  loss_objectness: 0.0029 (0.0349)  loss_rpn_box_reg: 0.0019 (0.0080)  time: 0.1397  data: 0.0390  max mem: 1064\n",
      "Epoch: [0]  [ 2800/12099]  eta: 0:20:40  lr: 0.000300  loss: 0.1281 (0.2139)  loss_classifier: 0.0292 (0.0665)  loss_box_reg: 0.0483 (0.1047)  loss_objectness: 0.0054 (0.0347)  loss_rpn_box_reg: 0.0043 (0.0079)  time: 0.1296  data: 0.0344  max mem: 1064\n",
      "Epoch: [0]  [ 2900/12099]  eta: 0:20:27  lr: 0.000300  loss: 0.1106 (0.2118)  loss_classifier: 0.0301 (0.0655)  loss_box_reg: 0.0654 (0.1035)  loss_objectness: 0.0088 (0.0349)  loss_rpn_box_reg: 0.0045 (0.0080)  time: 0.1412  data: 0.0388  max mem: 1064\n",
      "Epoch: [0]  [ 3000/12099]  eta: 0:20:15  lr: 0.000300  loss: 0.1075 (0.2097)  loss_classifier: 0.0246 (0.0644)  loss_box_reg: 0.0395 (0.1022)  loss_objectness: 0.0253 (0.0350)  loss_rpn_box_reg: 0.0040 (0.0080)  time: 0.1414  data: 0.0403  max mem: 1064\n",
      "Epoch: [0]  [ 3100/12099]  eta: 0:20:02  lr: 0.000300  loss: 0.1232 (0.2075)  loss_classifier: 0.0332 (0.0634)  loss_box_reg: 0.0587 (0.1009)  loss_objectness: 0.0054 (0.0351)  loss_rpn_box_reg: 0.0032 (0.0081)  time: 0.1314  data: 0.0353  max mem: 1064\n",
      "Epoch: [0]  [ 3200/12099]  eta: 0:19:50  lr: 0.000300  loss: 0.1132 (0.2050)  loss_classifier: 0.0316 (0.0625)  loss_box_reg: 0.0506 (0.0997)  loss_objectness: 0.0031 (0.0348)  loss_rpn_box_reg: 0.0046 (0.0080)  time: 0.1418  data: 0.0409  max mem: 1064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [ 3300/12099]  eta: 0:19:37  lr: 0.000300  loss: 0.1041 (0.2035)  loss_classifier: 0.0288 (0.0618)  loss_box_reg: 0.0642 (0.0987)  loss_objectness: 0.0052 (0.0350)  loss_rpn_box_reg: 0.0030 (0.0080)  time: 0.1277  data: 0.0344  max mem: 1064\n",
      "Epoch: [0]  [ 3400/12099]  eta: 0:19:24  lr: 0.000300  loss: 0.1323 (0.2014)  loss_classifier: 0.0341 (0.0610)  loss_box_reg: 0.0525 (0.0975)  loss_objectness: 0.0113 (0.0349)  loss_rpn_box_reg: 0.0030 (0.0081)  time: 0.1418  data: 0.0413  max mem: 1064\n",
      "Epoch: [0]  [ 3500/12099]  eta: 0:19:12  lr: 0.000300  loss: 0.1107 (0.1994)  loss_classifier: 0.0280 (0.0602)  loss_box_reg: 0.0593 (0.0965)  loss_objectness: 0.0085 (0.0347)  loss_rpn_box_reg: 0.0018 (0.0080)  time: 0.1405  data: 0.0394  max mem: 1064\n",
      "Epoch: [0]  [ 3600/12099]  eta: 0:18:59  lr: 0.000300  loss: 0.1078 (0.1973)  loss_classifier: 0.0228 (0.0593)  loss_box_reg: 0.0548 (0.0955)  loss_objectness: 0.0062 (0.0346)  loss_rpn_box_reg: 0.0037 (0.0080)  time: 0.1423  data: 0.0408  max mem: 1064\n",
      "Epoch: [0]  [ 3700/12099]  eta: 0:18:45  lr: 0.000300  loss: 0.1357 (0.1956)  loss_classifier: 0.0280 (0.0586)  loss_box_reg: 0.0401 (0.0942)  loss_objectness: 0.0147 (0.0348)  loss_rpn_box_reg: 0.0032 (0.0079)  time: 0.1317  data: 0.0369  max mem: 1064\n",
      "Epoch: [0]  [ 3800/12099]  eta: 0:18:31  lr: 0.000300  loss: 0.1107 (0.1940)  loss_classifier: 0.0276 (0.0580)  loss_box_reg: 0.0582 (0.0934)  loss_objectness: 0.0040 (0.0348)  loss_rpn_box_reg: 0.0014 (0.0079)  time: 0.1349  data: 0.0364  max mem: 1064\n",
      "Epoch: [0]  [ 3900/12099]  eta: 0:18:19  lr: 0.000300  loss: 0.1088 (0.1921)  loss_classifier: 0.0218 (0.0573)  loss_box_reg: 0.0397 (0.0923)  loss_objectness: 0.0100 (0.0346)  loss_rpn_box_reg: 0.0047 (0.0079)  time: 0.1477  data: 0.0413  max mem: 1064\n",
      "Epoch: [0]  [ 4000/12099]  eta: 0:18:08  lr: 0.000300  loss: 0.1124 (0.1903)  loss_classifier: 0.0274 (0.0566)  loss_box_reg: 0.0593 (0.0914)  loss_objectness: 0.0124 (0.0344)  loss_rpn_box_reg: 0.0042 (0.0080)  time: 0.1458  data: 0.0391  max mem: 1064\n",
      "Epoch: [0]  [ 4100/12099]  eta: 0:17:56  lr: 0.000300  loss: 0.1053 (0.1888)  loss_classifier: 0.0345 (0.0560)  loss_box_reg: 0.0359 (0.0905)  loss_objectness: 0.0087 (0.0344)  loss_rpn_box_reg: 0.0043 (0.0080)  time: 0.1416  data: 0.0394  max mem: 1064\n",
      "Epoch: [0]  [ 4200/12099]  eta: 0:17:45  lr: 0.000300  loss: 0.1206 (0.1872)  loss_classifier: 0.0282 (0.0554)  loss_box_reg: 0.0480 (0.0896)  loss_objectness: 0.0324 (0.0342)  loss_rpn_box_reg: 0.0029 (0.0079)  time: 0.1470  data: 0.0404  max mem: 1064\n",
      "Epoch: [0]  [ 4300/12099]  eta: 0:17:34  lr: 0.000300  loss: 0.0921 (0.1858)  loss_classifier: 0.0256 (0.0549)  loss_box_reg: 0.0476 (0.0887)  loss_objectness: 0.0053 (0.0343)  loss_rpn_box_reg: 0.0020 (0.0079)  time: 0.1558  data: 0.0471  max mem: 1064\n",
      "Epoch: [0]  [ 4400/12099]  eta: 0:17:21  lr: 0.000300  loss: 0.1183 (0.1849)  loss_classifier: 0.0315 (0.0544)  loss_box_reg: 0.0464 (0.0880)  loss_objectness: 0.0115 (0.0345)  loss_rpn_box_reg: 0.0057 (0.0080)  time: 0.1426  data: 0.0370  max mem: 1064\n",
      "Epoch: [0]  [ 4500/12099]  eta: 0:17:09  lr: 0.000300  loss: 0.1127 (0.1840)  loss_classifier: 0.0270 (0.0540)  loss_box_reg: 0.0471 (0.0873)  loss_objectness: 0.0128 (0.0347)  loss_rpn_box_reg: 0.0032 (0.0080)  time: 0.1383  data: 0.0373  max mem: 1064\n",
      "Epoch: [0]  [ 4600/12099]  eta: 0:16:58  lr: 0.000300  loss: 0.1374 (0.1831)  loss_classifier: 0.0244 (0.0536)  loss_box_reg: 0.0618 (0.0868)  loss_objectness: 0.0099 (0.0348)  loss_rpn_box_reg: 0.0035 (0.0080)  time: 0.1427  data: 0.0408  max mem: 1064\n",
      "Epoch: [0]  [ 4700/12099]  eta: 0:16:45  lr: 0.000300  loss: 0.1029 (0.1817)  loss_classifier: 0.0244 (0.0531)  loss_box_reg: 0.0469 (0.0861)  loss_objectness: 0.0082 (0.0346)  loss_rpn_box_reg: 0.0033 (0.0080)  time: 0.1537  data: 0.0410  max mem: 1064\n",
      "Epoch: [0]  [ 4800/12099]  eta: 0:16:34  lr: 0.000300  loss: 0.0952 (0.1807)  loss_classifier: 0.0273 (0.0527)  loss_box_reg: 0.0446 (0.0854)  loss_objectness: 0.0095 (0.0345)  loss_rpn_box_reg: 0.0021 (0.0080)  time: 0.1503  data: 0.0431  max mem: 1064\n",
      "Epoch: [0]  [ 4900/12099]  eta: 0:16:21  lr: 0.000300  loss: 0.1029 (0.1796)  loss_classifier: 0.0289 (0.0523)  loss_box_reg: 0.0503 (0.0848)  loss_objectness: 0.0040 (0.0345)  loss_rpn_box_reg: 0.0015 (0.0080)  time: 0.1334  data: 0.0357  max mem: 1064\n",
      "Epoch: [0]  [ 5000/12099]  eta: 0:16:10  lr: 0.000300  loss: 0.0769 (0.1782)  loss_classifier: 0.0226 (0.0519)  loss_box_reg: 0.0477 (0.0842)  loss_objectness: 0.0025 (0.0341)  loss_rpn_box_reg: 0.0021 (0.0080)  time: 0.1688  data: 0.0522  max mem: 1064\n",
      "Epoch: [0]  [ 5100/12099]  eta: 0:16:00  lr: 0.000300  loss: 0.1263 (0.1773)  loss_classifier: 0.0221 (0.0515)  loss_box_reg: 0.0458 (0.0836)  loss_objectness: 0.0237 (0.0342)  loss_rpn_box_reg: 0.0043 (0.0080)  time: 0.1461  data: 0.0404  max mem: 1064\n",
      "Epoch: [0]  [ 5200/12099]  eta: 0:15:49  lr: 0.000300  loss: 0.1194 (0.1764)  loss_classifier: 0.0258 (0.0512)  loss_box_reg: 0.0415 (0.0832)  loss_objectness: 0.0193 (0.0341)  loss_rpn_box_reg: 0.0045 (0.0079)  time: 0.1560  data: 0.0468  max mem: 1064\n",
      "Epoch: [0]  [ 5300/12099]  eta: 0:15:37  lr: 0.000300  loss: 0.0936 (0.1754)  loss_classifier: 0.0218 (0.0509)  loss_box_reg: 0.0556 (0.0826)  loss_objectness: 0.0064 (0.0340)  loss_rpn_box_reg: 0.0037 (0.0080)  time: 0.1523  data: 0.0439  max mem: 1064\n",
      "Epoch: [0]  [ 5400/12099]  eta: 0:15:25  lr: 0.000300  loss: 0.1168 (0.1748)  loss_classifier: 0.0329 (0.0506)  loss_box_reg: 0.0512 (0.0821)  loss_objectness: 0.0281 (0.0341)  loss_rpn_box_reg: 0.0038 (0.0080)  time: 0.1609  data: 0.0479  max mem: 1064\n",
      "Epoch: [0]  [ 5500/12099]  eta: 0:15:13  lr: 0.000300  loss: 0.1177 (0.1739)  loss_classifier: 0.0255 (0.0502)  loss_box_reg: 0.0621 (0.0816)  loss_objectness: 0.0066 (0.0341)  loss_rpn_box_reg: 0.0030 (0.0080)  time: 0.1441  data: 0.0393  max mem: 1064\n",
      "Epoch: [0]  [ 5600/12099]  eta: 0:15:01  lr: 0.000300  loss: 0.1064 (0.1732)  loss_classifier: 0.0252 (0.0499)  loss_box_reg: 0.0499 (0.0811)  loss_objectness: 0.0114 (0.0342)  loss_rpn_box_reg: 0.0027 (0.0079)  time: 0.1579  data: 0.0474  max mem: 1064\n",
      "Epoch: [0]  [ 5700/12099]  eta: 0:14:49  lr: 0.000300  loss: 0.1053 (0.1725)  loss_classifier: 0.0273 (0.0496)  loss_box_reg: 0.0400 (0.0806)  loss_objectness: 0.0128 (0.0343)  loss_rpn_box_reg: 0.0022 (0.0080)  time: 0.1448  data: 0.0383  max mem: 1064\n",
      "Epoch: [0]  [ 5800/12099]  eta: 0:14:36  lr: 0.000300  loss: 0.1128 (0.1717)  loss_classifier: 0.0293 (0.0493)  loss_box_reg: 0.0598 (0.0802)  loss_objectness: 0.0100 (0.0343)  loss_rpn_box_reg: 0.0030 (0.0079)  time: 0.1569  data: 0.0467  max mem: 1064\n",
      "Epoch: [0]  [ 5900/12099]  eta: 0:14:23  lr: 0.000300  loss: 0.1010 (0.1709)  loss_classifier: 0.0239 (0.0490)  loss_box_reg: 0.0451 (0.0797)  loss_objectness: 0.0033 (0.0342)  loss_rpn_box_reg: 0.0027 (0.0079)  time: 0.1490  data: 0.0414  max mem: 1064\n",
      "Epoch: [0]  [ 6000/12099]  eta: 0:14:11  lr: 0.000300  loss: 0.1214 (0.1701)  loss_classifier: 0.0304 (0.0487)  loss_box_reg: 0.0619 (0.0792)  loss_objectness: 0.0114 (0.0342)  loss_rpn_box_reg: 0.0044 (0.0079)  time: 0.1605  data: 0.0433  max mem: 1064\n",
      "Epoch: [0]  [ 6100/12099]  eta: 0:13:58  lr: 0.000300  loss: 0.0972 (0.1692)  loss_classifier: 0.0252 (0.0484)  loss_box_reg: 0.0495 (0.0787)  loss_objectness: 0.0060 (0.0341)  loss_rpn_box_reg: 0.0020 (0.0080)  time: 0.1686  data: 0.0496  max mem: 1064\n",
      "Epoch: [0]  [ 6200/12099]  eta: 0:13:46  lr: 0.000300  loss: 0.0924 (0.1685)  loss_classifier: 0.0237 (0.0481)  loss_box_reg: 0.0466 (0.0783)  loss_objectness: 0.0041 (0.0341)  loss_rpn_box_reg: 0.0014 (0.0080)  time: 0.1561  data: 0.0473  max mem: 1064\n",
      "Epoch: [0]  [ 6300/12099]  eta: 0:13:33  lr: 0.000300  loss: 0.0958 (0.1679)  loss_classifier: 0.0222 (0.0478)  loss_box_reg: 0.0366 (0.0779)  loss_objectness: 0.0169 (0.0342)  loss_rpn_box_reg: 0.0038 (0.0080)  time: 0.1477  data: 0.0412  max mem: 1064\n",
      "Epoch: [0]  [ 6400/12099]  eta: 0:13:20  lr: 0.000300  loss: 0.0911 (0.1671)  loss_classifier: 0.0209 (0.0475)  loss_box_reg: 0.0411 (0.0774)  loss_objectness: 0.0124 (0.0342)  loss_rpn_box_reg: 0.0030 (0.0080)  time: 0.1685  data: 0.0500  max mem: 1064\n",
      "Epoch: [0]  [ 6500/12099]  eta: 0:13:07  lr: 0.000300  loss: 0.1048 (0.1663)  loss_classifier: 0.0287 (0.0472)  loss_box_reg: 0.0485 (0.0770)  loss_objectness: 0.0069 (0.0341)  loss_rpn_box_reg: 0.0024 (0.0080)  time: 0.1415  data: 0.0396  max mem: 1064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [ 6600/12099]  eta: 0:12:54  lr: 0.000300  loss: 0.1110 (0.1656)  loss_classifier: 0.0248 (0.0470)  loss_box_reg: 0.0475 (0.0766)  loss_objectness: 0.0126 (0.0341)  loss_rpn_box_reg: 0.0033 (0.0081)  time: 0.1532  data: 0.0429  max mem: 1064\n",
      "Epoch: [0]  [ 6700/12099]  eta: 0:12:41  lr: 0.000300  loss: 0.1095 (0.1650)  loss_classifier: 0.0225 (0.0467)  loss_box_reg: 0.0432 (0.0762)  loss_objectness: 0.0117 (0.0340)  loss_rpn_box_reg: 0.0046 (0.0081)  time: 0.1415  data: 0.0405  max mem: 1064\n",
      "Epoch: [0]  [ 6800/12099]  eta: 0:12:28  lr: 0.000300  loss: 0.0944 (0.1645)  loss_classifier: 0.0257 (0.0465)  loss_box_reg: 0.0583 (0.0759)  loss_objectness: 0.0073 (0.0339)  loss_rpn_box_reg: 0.0031 (0.0080)  time: 0.1592  data: 0.0491  max mem: 1064\n",
      "Epoch: [0]  [ 6900/12099]  eta: 0:12:14  lr: 0.000300  loss: 0.1342 (0.1641)  loss_classifier: 0.0341 (0.0463)  loss_box_reg: 0.0539 (0.0755)  loss_objectness: 0.0042 (0.0341)  loss_rpn_box_reg: 0.0036 (0.0081)  time: 0.1659  data: 0.0521  max mem: 1064\n",
      "Epoch: [0]  [ 7000/12099]  eta: 0:12:00  lr: 0.000300  loss: 0.1319 (0.1635)  loss_classifier: 0.0243 (0.0461)  loss_box_reg: 0.0422 (0.0752)  loss_objectness: 0.0203 (0.0341)  loss_rpn_box_reg: 0.0026 (0.0081)  time: 0.1392  data: 0.0384  max mem: 1064\n",
      "Epoch: [0]  [ 7100/12099]  eta: 0:11:46  lr: 0.000300  loss: 0.0783 (0.1628)  loss_classifier: 0.0278 (0.0459)  loss_box_reg: 0.0433 (0.0748)  loss_objectness: 0.0034 (0.0340)  loss_rpn_box_reg: 0.0027 (0.0081)  time: 0.1565  data: 0.0460  max mem: 1064\n",
      "Epoch: [0]  [ 7200/12099]  eta: 0:11:33  lr: 0.000300  loss: 0.1138 (0.1622)  loss_classifier: 0.0255 (0.0457)  loss_box_reg: 0.0421 (0.0745)  loss_objectness: 0.0165 (0.0340)  loss_rpn_box_reg: 0.0040 (0.0080)  time: 0.1650  data: 0.0474  max mem: 1064\n",
      "Epoch: [0]  [ 7300/12099]  eta: 0:11:19  lr: 0.000300  loss: 0.1616 (0.1617)  loss_classifier: 0.0315 (0.0455)  loss_box_reg: 0.0486 (0.0742)  loss_objectness: 0.0139 (0.0340)  loss_rpn_box_reg: 0.0048 (0.0080)  time: 0.1438  data: 0.0402  max mem: 1064\n",
      "Epoch: [0]  [ 7400/12099]  eta: 0:11:06  lr: 0.000300  loss: 0.1061 (0.1611)  loss_classifier: 0.0294 (0.0453)  loss_box_reg: 0.0467 (0.0738)  loss_objectness: 0.0048 (0.0340)  loss_rpn_box_reg: 0.0036 (0.0081)  time: 0.1648  data: 0.0490  max mem: 1064\n",
      "Epoch: [0]  [ 7500/12099]  eta: 0:10:53  lr: 0.000300  loss: 0.1092 (0.1605)  loss_classifier: 0.0260 (0.0451)  loss_box_reg: 0.0507 (0.0735)  loss_objectness: 0.0149 (0.0339)  loss_rpn_box_reg: 0.0020 (0.0081)  time: 0.1702  data: 0.0540  max mem: 1064\n",
      "Epoch: [0]  [ 7600/12099]  eta: 0:10:39  lr: 0.000300  loss: 0.1133 (0.1600)  loss_classifier: 0.0247 (0.0449)  loss_box_reg: 0.0556 (0.0733)  loss_objectness: 0.0091 (0.0338)  loss_rpn_box_reg: 0.0024 (0.0081)  time: 0.1443  data: 0.0399  max mem: 1064\n",
      "Epoch: [0]  [ 7700/12099]  eta: 0:10:25  lr: 0.000300  loss: 0.1176 (0.1598)  loss_classifier: 0.0312 (0.0447)  loss_box_reg: 0.0422 (0.0730)  loss_objectness: 0.0182 (0.0340)  loss_rpn_box_reg: 0.0041 (0.0081)  time: 0.1385  data: 0.0370  max mem: 1064\n",
      "Epoch: [0]  [ 7800/12099]  eta: 0:10:11  lr: 0.000300  loss: 0.1158 (0.1592)  loss_classifier: 0.0290 (0.0445)  loss_box_reg: 0.0401 (0.0727)  loss_objectness: 0.0139 (0.0340)  loss_rpn_box_reg: 0.0013 (0.0081)  time: 0.1524  data: 0.0424  max mem: 1064\n",
      "Epoch: [0]  [ 7900/12099]  eta: 0:09:57  lr: 0.000300  loss: 0.1114 (0.1588)  loss_classifier: 0.0244 (0.0443)  loss_box_reg: 0.0414 (0.0724)  loss_objectness: 0.0026 (0.0340)  loss_rpn_box_reg: 0.0017 (0.0080)  time: 0.1291  data: 0.0363  max mem: 1064\n",
      "Epoch: [0]  [ 8000/12099]  eta: 0:09:43  lr: 0.000300  loss: 0.1051 (0.1584)  loss_classifier: 0.0294 (0.0442)  loss_box_reg: 0.0505 (0.0723)  loss_objectness: 0.0041 (0.0339)  loss_rpn_box_reg: 0.0022 (0.0080)  time: 0.1496  data: 0.0401  max mem: 1064\n",
      "Epoch: [0]  [ 8100/12099]  eta: 0:09:29  lr: 0.000300  loss: 0.0945 (0.1579)  loss_classifier: 0.0219 (0.0440)  loss_box_reg: 0.0353 (0.0720)  loss_objectness: 0.0133 (0.0338)  loss_rpn_box_reg: 0.0019 (0.0080)  time: 0.1817  data: 0.0640  max mem: 1064\n",
      "Epoch: [0]  [ 8200/12099]  eta: 0:09:16  lr: 0.000300  loss: 0.1017 (0.1574)  loss_classifier: 0.0207 (0.0439)  loss_box_reg: 0.0347 (0.0718)  loss_objectness: 0.0049 (0.0338)  loss_rpn_box_reg: 0.0035 (0.0080)  time: 0.1590  data: 0.0475  max mem: 1064\n",
      "Epoch: [0]  [ 8300/12099]  eta: 0:09:01  lr: 0.000300  loss: 0.0978 (0.1571)  loss_classifier: 0.0240 (0.0437)  loss_box_reg: 0.0338 (0.0715)  loss_objectness: 0.0038 (0.0338)  loss_rpn_box_reg: 0.0028 (0.0080)  time: 0.1393  data: 0.0390  max mem: 1064\n",
      "Epoch: [0]  [ 8400/12099]  eta: 0:08:47  lr: 0.000300  loss: 0.0964 (0.1566)  loss_classifier: 0.0246 (0.0435)  loss_box_reg: 0.0441 (0.0712)  loss_objectness: 0.0027 (0.0338)  loss_rpn_box_reg: 0.0025 (0.0080)  time: 0.1526  data: 0.0435  max mem: 1064\n",
      "Epoch: [0]  [ 8500/12099]  eta: 0:08:33  lr: 0.000300  loss: 0.1049 (0.1562)  loss_classifier: 0.0259 (0.0434)  loss_box_reg: 0.0606 (0.0710)  loss_objectness: 0.0053 (0.0338)  loss_rpn_box_reg: 0.0027 (0.0080)  time: 0.1546  data: 0.0475  max mem: 1064\n",
      "Epoch: [0]  [ 8600/12099]  eta: 0:08:20  lr: 0.000300  loss: 0.0989 (0.1558)  loss_classifier: 0.0214 (0.0432)  loss_box_reg: 0.0620 (0.0708)  loss_objectness: 0.0041 (0.0338)  loss_rpn_box_reg: 0.0022 (0.0080)  time: 0.1503  data: 0.0421  max mem: 1064\n",
      "Epoch: [0]  [ 8700/12099]  eta: 0:08:06  lr: 0.000300  loss: 0.1176 (0.1554)  loss_classifier: 0.0264 (0.0430)  loss_box_reg: 0.0479 (0.0706)  loss_objectness: 0.0102 (0.0338)  loss_rpn_box_reg: 0.0045 (0.0080)  time: 0.1631  data: 0.0502  max mem: 1064\n",
      "Epoch: [0]  [ 8800/12099]  eta: 0:07:52  lr: 0.000300  loss: 0.1095 (0.1551)  loss_classifier: 0.0280 (0.0429)  loss_box_reg: 0.0569 (0.0704)  loss_objectness: 0.0134 (0.0338)  loss_rpn_box_reg: 0.0030 (0.0080)  time: 0.1755  data: 0.0529  max mem: 1064\n",
      "Epoch: [0]  [ 8900/12099]  eta: 0:07:38  lr: 0.000300  loss: 0.0834 (0.1545)  loss_classifier: 0.0176 (0.0427)  loss_box_reg: 0.0320 (0.0702)  loss_objectness: 0.0072 (0.0336)  loss_rpn_box_reg: 0.0029 (0.0080)  time: 0.1371  data: 0.0378  max mem: 1064\n",
      "Epoch: [0]  [ 9000/12099]  eta: 0:07:24  lr: 0.000300  loss: 0.1018 (0.1542)  loss_classifier: 0.0206 (0.0426)  loss_box_reg: 0.0418 (0.0700)  loss_objectness: 0.0047 (0.0337)  loss_rpn_box_reg: 0.0019 (0.0080)  time: 0.1544  data: 0.0435  max mem: 1064\n",
      "Epoch: [0]  [ 9100/12099]  eta: 0:07:10  lr: 0.000300  loss: 0.1029 (0.1538)  loss_classifier: 0.0202 (0.0424)  loss_box_reg: 0.0323 (0.0697)  loss_objectness: 0.0156 (0.0336)  loss_rpn_box_reg: 0.0030 (0.0080)  time: 0.1464  data: 0.0396  max mem: 1064\n",
      "Epoch: [0]  [ 9200/12099]  eta: 0:06:56  lr: 0.000300  loss: 0.1121 (0.1535)  loss_classifier: 0.0231 (0.0423)  loss_box_reg: 0.0494 (0.0696)  loss_objectness: 0.0139 (0.0336)  loss_rpn_box_reg: 0.0028 (0.0080)  time: 0.1475  data: 0.0417  max mem: 1064\n",
      "Epoch: [0]  [ 9300/12099]  eta: 0:06:42  lr: 0.000300  loss: 0.0876 (0.1530)  loss_classifier: 0.0300 (0.0422)  loss_box_reg: 0.0461 (0.0693)  loss_objectness: 0.0079 (0.0336)  loss_rpn_box_reg: 0.0019 (0.0080)  time: 0.1581  data: 0.0485  max mem: 1064\n",
      "Epoch: [0]  [ 9400/12099]  eta: 0:06:28  lr: 0.000300  loss: 0.1062 (0.1527)  loss_classifier: 0.0236 (0.0420)  loss_box_reg: 0.0516 (0.0691)  loss_objectness: 0.0076 (0.0336)  loss_rpn_box_reg: 0.0057 (0.0080)  time: 0.1566  data: 0.0454  max mem: 1064\n",
      "Epoch: [0]  [ 9500/12099]  eta: 0:06:14  lr: 0.000300  loss: 0.0962 (0.1523)  loss_classifier: 0.0225 (0.0419)  loss_box_reg: 0.0477 (0.0689)  loss_objectness: 0.0029 (0.0336)  loss_rpn_box_reg: 0.0020 (0.0080)  time: 0.1592  data: 0.0452  max mem: 1064\n",
      "Epoch: [0]  [ 9600/12099]  eta: 0:06:01  lr: 0.000300  loss: 0.1178 (0.1522)  loss_classifier: 0.0247 (0.0418)  loss_box_reg: 0.0389 (0.0687)  loss_objectness: 0.0120 (0.0337)  loss_rpn_box_reg: 0.0021 (0.0080)  time: 0.1825  data: 0.0617  max mem: 1064\n",
      "Epoch: [0]  [ 9700/12099]  eta: 0:05:46  lr: 0.000300  loss: 0.0946 (0.1520)  loss_classifier: 0.0224 (0.0417)  loss_box_reg: 0.0544 (0.0686)  loss_objectness: 0.0043 (0.0338)  loss_rpn_box_reg: 0.0029 (0.0080)  time: 0.1630  data: 0.0524  max mem: 1064\n",
      "Epoch: [0]  [ 9800/12099]  eta: 0:05:32  lr: 0.000300  loss: 0.0983 (0.1518)  loss_classifier: 0.0211 (0.0416)  loss_box_reg: 0.0441 (0.0684)  loss_objectness: 0.0133 (0.0338)  loss_rpn_box_reg: 0.0033 (0.0080)  time: 0.1687  data: 0.0529  max mem: 1064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [ 9900/12099]  eta: 0:05:18  lr: 0.000300  loss: 0.1121 (0.1516)  loss_classifier: 0.0302 (0.0415)  loss_box_reg: 0.0404 (0.0683)  loss_objectness: 0.0070 (0.0338)  loss_rpn_box_reg: 0.0044 (0.0080)  time: 0.1446  data: 0.0409  max mem: 1064\n",
      "Epoch: [0]  [10000/12099]  eta: 0:05:04  lr: 0.000300  loss: 0.1088 (0.1512)  loss_classifier: 0.0248 (0.0413)  loss_box_reg: 0.0567 (0.0681)  loss_objectness: 0.0034 (0.0338)  loss_rpn_box_reg: 0.0031 (0.0080)  time: 0.1503  data: 0.0439  max mem: 1064\n",
      "Epoch: [0]  [10100/12099]  eta: 0:04:49  lr: 0.000300  loss: 0.1015 (0.1508)  loss_classifier: 0.0256 (0.0413)  loss_box_reg: 0.0427 (0.0679)  loss_objectness: 0.0083 (0.0337)  loss_rpn_box_reg: 0.0035 (0.0080)  time: 0.1380  data: 0.0382  max mem: 1064\n",
      "Epoch: [0]  [10200/12099]  eta: 0:04:35  lr: 0.000300  loss: 0.1114 (0.1504)  loss_classifier: 0.0229 (0.0411)  loss_box_reg: 0.0362 (0.0677)  loss_objectness: 0.0208 (0.0337)  loss_rpn_box_reg: 0.0018 (0.0080)  time: 0.1421  data: 0.0393  max mem: 1064\n",
      "Epoch: [0]  [10300/12099]  eta: 0:04:21  lr: 0.000300  loss: 0.1007 (0.1501)  loss_classifier: 0.0254 (0.0410)  loss_box_reg: 0.0564 (0.0675)  loss_objectness: 0.0126 (0.0336)  loss_rpn_box_reg: 0.0038 (0.0080)  time: 0.1372  data: 0.0386  max mem: 1064\n",
      "Epoch: [0]  [10400/12099]  eta: 0:04:06  lr: 0.000300  loss: 0.0994 (0.1498)  loss_classifier: 0.0170 (0.0409)  loss_box_reg: 0.0348 (0.0674)  loss_objectness: 0.0161 (0.0335)  loss_rpn_box_reg: 0.0044 (0.0080)  time: 0.1304  data: 0.0366  max mem: 1064\n",
      "Epoch: [0]  [10500/12099]  eta: 0:03:51  lr: 0.000300  loss: 0.1096 (0.1494)  loss_classifier: 0.0235 (0.0408)  loss_box_reg: 0.0491 (0.0672)  loss_objectness: 0.0062 (0.0335)  loss_rpn_box_reg: 0.0026 (0.0079)  time: 0.1361  data: 0.0385  max mem: 1064\n",
      "Epoch: [0]  [10600/12099]  eta: 0:03:37  lr: 0.000300  loss: 0.0907 (0.1491)  loss_classifier: 0.0261 (0.0407)  loss_box_reg: 0.0465 (0.0670)  loss_objectness: 0.0060 (0.0334)  loss_rpn_box_reg: 0.0027 (0.0079)  time: 0.1411  data: 0.0402  max mem: 1064\n",
      "Epoch: [0]  [10700/12099]  eta: 0:03:22  lr: 0.000300  loss: 0.0929 (0.1488)  loss_classifier: 0.0225 (0.0406)  loss_box_reg: 0.0391 (0.0669)  loss_objectness: 0.0069 (0.0335)  loss_rpn_box_reg: 0.0034 (0.0079)  time: 0.1551  data: 0.0499  max mem: 1064\n",
      "Epoch: [0]  [10800/12099]  eta: 0:03:08  lr: 0.000300  loss: 0.1206 (0.1487)  loss_classifier: 0.0239 (0.0405)  loss_box_reg: 0.0438 (0.0667)  loss_objectness: 0.0123 (0.0336)  loss_rpn_box_reg: 0.0033 (0.0079)  time: 0.1541  data: 0.0453  max mem: 1064\n",
      "Epoch: [0]  [10900/12099]  eta: 0:02:54  lr: 0.000300  loss: 0.0903 (0.1482)  loss_classifier: 0.0208 (0.0403)  loss_box_reg: 0.0425 (0.0665)  loss_objectness: 0.0026 (0.0335)  loss_rpn_box_reg: 0.0019 (0.0079)  time: 0.1706  data: 0.0535  max mem: 1064\n",
      "Epoch: [0]  [11000/12099]  eta: 0:02:39  lr: 0.000300  loss: 0.1003 (0.1480)  loss_classifier: 0.0242 (0.0402)  loss_box_reg: 0.0578 (0.0664)  loss_objectness: 0.0110 (0.0335)  loss_rpn_box_reg: 0.0024 (0.0079)  time: 0.1546  data: 0.0457  max mem: 1064\n",
      "Epoch: [0]  [11100/12099]  eta: 0:02:25  lr: 0.000300  loss: 0.1138 (0.1478)  loss_classifier: 0.0250 (0.0402)  loss_box_reg: 0.0403 (0.0662)  loss_objectness: 0.0273 (0.0335)  loss_rpn_box_reg: 0.0021 (0.0079)  time: 0.1393  data: 0.0388  max mem: 1064\n",
      "Epoch: [0]  [11200/12099]  eta: 0:02:10  lr: 0.000300  loss: 0.1044 (0.1475)  loss_classifier: 0.0208 (0.0401)  loss_box_reg: 0.0430 (0.0661)  loss_objectness: 0.0099 (0.0335)  loss_rpn_box_reg: 0.0037 (0.0079)  time: 0.1580  data: 0.0463  max mem: 1064\n",
      "Epoch: [0]  [11300/12099]  eta: 0:01:56  lr: 0.000300  loss: 0.0902 (0.1473)  loss_classifier: 0.0214 (0.0400)  loss_box_reg: 0.0376 (0.0659)  loss_objectness: 0.0121 (0.0335)  loss_rpn_box_reg: 0.0037 (0.0079)  time: 0.1514  data: 0.0448  max mem: 1064\n",
      "Epoch: [0]  [11400/12099]  eta: 0:01:41  lr: 0.000300  loss: 0.0976 (0.1471)  loss_classifier: 0.0178 (0.0398)  loss_box_reg: 0.0406 (0.0658)  loss_objectness: 0.0167 (0.0335)  loss_rpn_box_reg: 0.0036 (0.0079)  time: 0.1455  data: 0.0412  max mem: 1064\n",
      "Epoch: [0]  [11500/12099]  eta: 0:01:27  lr: 0.000300  loss: 0.0742 (0.1467)  loss_classifier: 0.0204 (0.0397)  loss_box_reg: 0.0388 (0.0656)  loss_objectness: 0.0033 (0.0335)  loss_rpn_box_reg: 0.0015 (0.0079)  time: 0.1459  data: 0.0410  max mem: 1064\n",
      "Epoch: [0]  [11600/12099]  eta: 0:01:12  lr: 0.000300  loss: 0.1020 (0.1465)  loss_classifier: 0.0250 (0.0397)  loss_box_reg: 0.0451 (0.0655)  loss_objectness: 0.0111 (0.0335)  loss_rpn_box_reg: 0.0031 (0.0079)  time: 0.1680  data: 0.0501  max mem: 1064\n",
      "Epoch: [0]  [11700/12099]  eta: 0:00:58  lr: 0.000300  loss: 0.0715 (0.1462)  loss_classifier: 0.0216 (0.0396)  loss_box_reg: 0.0372 (0.0653)  loss_objectness: 0.0034 (0.0334)  loss_rpn_box_reg: 0.0015 (0.0079)  time: 0.1588  data: 0.0481  max mem: 1064\n",
      "Epoch: [0]  [11800/12099]  eta: 0:00:43  lr: 0.000300  loss: 0.1059 (0.1461)  loss_classifier: 0.0281 (0.0395)  loss_box_reg: 0.0492 (0.0652)  loss_objectness: 0.0087 (0.0334)  loss_rpn_box_reg: 0.0041 (0.0079)  time: 0.1379  data: 0.0380  max mem: 1064\n",
      "Epoch: [0]  [11900/12099]  eta: 0:00:29  lr: 0.000300  loss: 0.0890 (0.1458)  loss_classifier: 0.0266 (0.0394)  loss_box_reg: 0.0361 (0.0651)  loss_objectness: 0.0101 (0.0334)  loss_rpn_box_reg: 0.0023 (0.0079)  time: 0.1441  data: 0.0405  max mem: 1064\n",
      "Epoch: [0]  [12000/12099]  eta: 0:00:14  lr: 0.000300  loss: 0.1060 (0.1457)  loss_classifier: 0.0216 (0.0394)  loss_box_reg: 0.0396 (0.0650)  loss_objectness: 0.0206 (0.0335)  loss_rpn_box_reg: 0.0016 (0.0079)  time: 0.1741  data: 0.0581  max mem: 1064\n",
      "Epoch: [0]  [12098/12099]  eta: 0:00:00  lr: 0.000300  loss: 0.0903 (0.1454)  loss_classifier: 0.0231 (0.0393)  loss_box_reg: 0.0410 (0.0648)  loss_objectness: 0.0052 (0.0334)  loss_rpn_box_reg: 0.0018 (0.0079)  time: 0.1932  data: 0.0641  max mem: 1064\n",
      "Epoch: [0] Total time: 0:29:28 (0.1462 s / it)\n",
      "Epoch: [1]  [    0/12099]  eta: 0:30:51  lr: 0.000300  loss: 0.1377 (0.1377)  loss_classifier: 0.0433 (0.0433)  loss_box_reg: 0.0930 (0.0930)  loss_objectness: 0.0002 (0.0002)  loss_rpn_box_reg: 0.0011 (0.0011)  time: 0.1530  data: 0.0450  max mem: 4294\n",
      "Epoch: [1]  [  100/12099]  eta: 0:28:56  lr: 0.000300  loss: 0.0943 (0.1047)  loss_classifier: 0.0211 (0.0251)  loss_box_reg: 0.0441 (0.0448)  loss_objectness: 0.0042 (0.0284)  loss_rpn_box_reg: 0.0018 (0.0064)  time: 0.1399  data: 0.0405  max mem: 4294\n",
      "Epoch: [1]  [  200/12099]  eta: 0:29:16  lr: 0.000300  loss: 0.1172 (0.1132)  loss_classifier: 0.0252 (0.0274)  loss_box_reg: 0.0521 (0.0465)  loss_objectness: 0.0082 (0.0316)  loss_rpn_box_reg: 0.0033 (0.0078)  time: 0.1751  data: 0.0592  max mem: 4294\n",
      "Epoch: [1]  [  300/12099]  eta: 0:28:47  lr: 0.000300  loss: 0.1101 (0.1143)  loss_classifier: 0.0200 (0.0277)  loss_box_reg: 0.0441 (0.0479)  loss_objectness: 0.0099 (0.0314)  loss_rpn_box_reg: 0.0033 (0.0073)  time: 0.1337  data: 0.0373  max mem: 4294\n",
      "Epoch: [1]  [  400/12099]  eta: 0:28:09  lr: 0.000300  loss: 0.1034 (0.1133)  loss_classifier: 0.0279 (0.0273)  loss_box_reg: 0.0563 (0.0478)  loss_objectness: 0.0036 (0.0309)  loss_rpn_box_reg: 0.0019 (0.0073)  time: 0.1327  data: 0.0378  max mem: 4294\n",
      "Epoch: [1]  [  500/12099]  eta: 0:27:33  lr: 0.000300  loss: 0.1104 (0.1157)  loss_classifier: 0.0287 (0.0287)  loss_box_reg: 0.0436 (0.0491)  loss_objectness: 0.0159 (0.0305)  loss_rpn_box_reg: 0.0028 (0.0074)  time: 0.1365  data: 0.0420  max mem: 4294\n",
      "Epoch: [1]  [  600/12099]  eta: 0:27:10  lr: 0.000300  loss: 0.1084 (0.1169)  loss_classifier: 0.0254 (0.0293)  loss_box_reg: 0.0456 (0.0501)  loss_objectness: 0.0079 (0.0303)  loss_rpn_box_reg: 0.0015 (0.0072)  time: 0.1321  data: 0.0366  max mem: 4294\n",
      "Epoch: [1]  [  700/12099]  eta: 0:26:46  lr: 0.000300  loss: 0.1052 (0.1168)  loss_classifier: 0.0304 (0.0289)  loss_box_reg: 0.0528 (0.0496)  loss_objectness: 0.0075 (0.0315)  loss_rpn_box_reg: 0.0020 (0.0068)  time: 0.1344  data: 0.0384  max mem: 4294\n",
      "Epoch: [1]  [  800/12099]  eta: 0:26:30  lr: 0.000300  loss: 0.0959 (0.1160)  loss_classifier: 0.0214 (0.0288)  loss_box_reg: 0.0402 (0.0496)  loss_objectness: 0.0015 (0.0307)  loss_rpn_box_reg: 0.0015 (0.0069)  time: 0.1398  data: 0.0393  max mem: 4294\n",
      "Epoch: [1]  [  900/12099]  eta: 0:26:19  lr: 0.000300  loss: 0.1349 (0.1159)  loss_classifier: 0.0184 (0.0287)  loss_box_reg: 0.0335 (0.0492)  loss_objectness: 0.0371 (0.0310)  loss_rpn_box_reg: 0.0040 (0.0070)  time: 0.1337  data: 0.0372  max mem: 4294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1]  [ 1000/12099]  eta: 0:25:59  lr: 0.000300  loss: 0.0949 (0.1157)  loss_classifier: 0.0253 (0.0288)  loss_box_reg: 0.0542 (0.0489)  loss_objectness: 0.0061 (0.0310)  loss_rpn_box_reg: 0.0016 (0.0069)  time: 0.1412  data: 0.0403  max mem: 4294\n",
      "Epoch: [1]  [ 1100/12099]  eta: 0:25:41  lr: 0.000300  loss: 0.1116 (0.1164)  loss_classifier: 0.0212 (0.0288)  loss_box_reg: 0.0446 (0.0489)  loss_objectness: 0.0255 (0.0314)  loss_rpn_box_reg: 0.0035 (0.0073)  time: 0.1511  data: 0.0473  max mem: 4294\n",
      "Epoch: [1]  [ 1200/12099]  eta: 0:25:24  lr: 0.000300  loss: 0.1049 (0.1172)  loss_classifier: 0.0210 (0.0287)  loss_box_reg: 0.0517 (0.0494)  loss_objectness: 0.0048 (0.0316)  loss_rpn_box_reg: 0.0036 (0.0075)  time: 0.1431  data: 0.0446  max mem: 4294\n",
      "Epoch: [1]  [ 1300/12099]  eta: 0:25:07  lr: 0.000300  loss: 0.0759 (0.1174)  loss_classifier: 0.0222 (0.0287)  loss_box_reg: 0.0357 (0.0493)  loss_objectness: 0.0086 (0.0319)  loss_rpn_box_reg: 0.0026 (0.0074)  time: 0.1338  data: 0.0365  max mem: 4294\n",
      "Epoch: [1]  [ 1400/12099]  eta: 0:24:53  lr: 0.000300  loss: 0.0989 (0.1175)  loss_classifier: 0.0234 (0.0287)  loss_box_reg: 0.0422 (0.0492)  loss_objectness: 0.0063 (0.0322)  loss_rpn_box_reg: 0.0021 (0.0073)  time: 0.1511  data: 0.0469  max mem: 4294\n",
      "Epoch: [1]  [ 1500/12099]  eta: 0:24:38  lr: 0.000300  loss: 0.1295 (0.1188)  loss_classifier: 0.0279 (0.0292)  loss_box_reg: 0.0365 (0.0498)  loss_objectness: 0.0303 (0.0322)  loss_rpn_box_reg: 0.0033 (0.0075)  time: 0.1340  data: 0.0355  max mem: 4294\n",
      "Epoch: [1]  [ 1600/12099]  eta: 0:24:21  lr: 0.000300  loss: 0.1173 (0.1194)  loss_classifier: 0.0175 (0.0292)  loss_box_reg: 0.0327 (0.0495)  loss_objectness: 0.0157 (0.0329)  loss_rpn_box_reg: 0.0059 (0.0077)  time: 0.1301  data: 0.0344  max mem: 4294\n",
      "Epoch: [1]  [ 1700/12099]  eta: 0:24:09  lr: 0.000300  loss: 0.0991 (0.1194)  loss_classifier: 0.0232 (0.0292)  loss_box_reg: 0.0316 (0.0495)  loss_objectness: 0.0058 (0.0329)  loss_rpn_box_reg: 0.0037 (0.0079)  time: 0.1320  data: 0.0354  max mem: 4294\n",
      "Epoch: [1]  [ 1800/12099]  eta: 0:23:53  lr: 0.000300  loss: 0.0963 (0.1195)  loss_classifier: 0.0229 (0.0293)  loss_box_reg: 0.0482 (0.0499)  loss_objectness: 0.0008 (0.0325)  loss_rpn_box_reg: 0.0022 (0.0079)  time: 0.1399  data: 0.0392  max mem: 4294\n",
      "Epoch: [1]  [ 1900/12099]  eta: 0:23:38  lr: 0.000300  loss: 0.1202 (0.1190)  loss_classifier: 0.0282 (0.0292)  loss_box_reg: 0.0586 (0.0498)  loss_objectness: 0.0100 (0.0322)  loss_rpn_box_reg: 0.0027 (0.0078)  time: 0.1384  data: 0.0398  max mem: 4294\n",
      "Epoch: [1]  [ 2000/12099]  eta: 0:23:24  lr: 0.000300  loss: 0.1051 (0.1188)  loss_classifier: 0.0164 (0.0291)  loss_box_reg: 0.0308 (0.0496)  loss_objectness: 0.0214 (0.0323)  loss_rpn_box_reg: 0.0034 (0.0079)  time: 0.1348  data: 0.0392  max mem: 4294\n",
      "Epoch: [1]  [ 2100/12099]  eta: 0:23:09  lr: 0.000300  loss: 0.1078 (0.1184)  loss_classifier: 0.0150 (0.0289)  loss_box_reg: 0.0365 (0.0495)  loss_objectness: 0.0255 (0.0321)  loss_rpn_box_reg: 0.0041 (0.0078)  time: 0.1422  data: 0.0406  max mem: 4294\n",
      "Epoch: [1]  [ 2200/12099]  eta: 0:22:56  lr: 0.000300  loss: 0.0946 (0.1186)  loss_classifier: 0.0253 (0.0290)  loss_box_reg: 0.0402 (0.0497)  loss_objectness: 0.0064 (0.0321)  loss_rpn_box_reg: 0.0024 (0.0079)  time: 0.1420  data: 0.0400  max mem: 4294\n",
      "Epoch: [1]  [ 2300/12099]  eta: 0:22:40  lr: 0.000300  loss: 0.1081 (0.1188)  loss_classifier: 0.0212 (0.0290)  loss_box_reg: 0.0463 (0.0497)  loss_objectness: 0.0116 (0.0323)  loss_rpn_box_reg: 0.0034 (0.0078)  time: 0.1439  data: 0.0429  max mem: 4294\n",
      "Epoch: [1]  [ 2400/12099]  eta: 0:22:24  lr: 0.000300  loss: 0.0865 (0.1184)  loss_classifier: 0.0281 (0.0290)  loss_box_reg: 0.0478 (0.0496)  loss_objectness: 0.0041 (0.0321)  loss_rpn_box_reg: 0.0022 (0.0077)  time: 0.1308  data: 0.0360  max mem: 4294\n",
      "Epoch: [1]  [ 2500/12099]  eta: 0:22:09  lr: 0.000300  loss: 0.0963 (0.1193)  loss_classifier: 0.0212 (0.0292)  loss_box_reg: 0.0426 (0.0498)  loss_objectness: 0.0152 (0.0326)  loss_rpn_box_reg: 0.0066 (0.0078)  time: 0.1317  data: 0.0360  max mem: 4294\n",
      "Epoch: [1]  [ 2600/12099]  eta: 0:21:57  lr: 0.000300  loss: 0.1045 (0.1197)  loss_classifier: 0.0210 (0.0292)  loss_box_reg: 0.0455 (0.0498)  loss_objectness: 0.0170 (0.0328)  loss_rpn_box_reg: 0.0034 (0.0079)  time: 0.1301  data: 0.0363  max mem: 4294\n",
      "Epoch: [1]  [ 2700/12099]  eta: 0:21:41  lr: 0.000300  loss: 0.1254 (0.1197)  loss_classifier: 0.0210 (0.0291)  loss_box_reg: 0.0364 (0.0498)  loss_objectness: 0.0125 (0.0329)  loss_rpn_box_reg: 0.0019 (0.0079)  time: 0.1307  data: 0.0362  max mem: 4294\n",
      "Epoch: [1]  [ 2800/12099]  eta: 0:21:25  lr: 0.000300  loss: 0.0970 (0.1193)  loss_classifier: 0.0240 (0.0291)  loss_box_reg: 0.0436 (0.0498)  loss_objectness: 0.0018 (0.0327)  loss_rpn_box_reg: 0.0017 (0.0078)  time: 0.1309  data: 0.0359  max mem: 4294\n",
      "Epoch: [1]  [ 2900/12099]  eta: 0:21:10  lr: 0.000300  loss: 0.1189 (0.1192)  loss_classifier: 0.0284 (0.0290)  loss_box_reg: 0.0465 (0.0498)  loss_objectness: 0.0109 (0.0326)  loss_rpn_box_reg: 0.0028 (0.0077)  time: 0.1352  data: 0.0397  max mem: 4294\n",
      "Epoch: [1]  [ 3000/12099]  eta: 0:20:56  lr: 0.000300  loss: 0.1139 (0.1192)  loss_classifier: 0.0259 (0.0290)  loss_box_reg: 0.0394 (0.0499)  loss_objectness: 0.0213 (0.0326)  loss_rpn_box_reg: 0.0057 (0.0077)  time: 0.1309  data: 0.0357  max mem: 4294\n",
      "Epoch: [1]  [ 3100/12099]  eta: 0:20:41  lr: 0.000300  loss: 0.0840 (0.1192)  loss_classifier: 0.0256 (0.0291)  loss_box_reg: 0.0411 (0.0499)  loss_objectness: 0.0028 (0.0326)  loss_rpn_box_reg: 0.0017 (0.0077)  time: 0.1480  data: 0.0470  max mem: 4294\n",
      "Epoch: [1]  [ 3200/12099]  eta: 0:20:26  lr: 0.000300  loss: 0.0889 (0.1188)  loss_classifier: 0.0229 (0.0290)  loss_box_reg: 0.0374 (0.0498)  loss_objectness: 0.0032 (0.0324)  loss_rpn_box_reg: 0.0022 (0.0077)  time: 0.1413  data: 0.0389  max mem: 4294\n",
      "Epoch: [1]  [ 3300/12099]  eta: 0:20:10  lr: 0.000300  loss: 0.0978 (0.1188)  loss_classifier: 0.0242 (0.0290)  loss_box_reg: 0.0457 (0.0497)  loss_objectness: 0.0107 (0.0324)  loss_rpn_box_reg: 0.0022 (0.0077)  time: 0.1286  data: 0.0342  max mem: 4294\n",
      "Epoch: [1]  [ 3400/12099]  eta: 0:19:56  lr: 0.000300  loss: 0.0829 (0.1188)  loss_classifier: 0.0238 (0.0289)  loss_box_reg: 0.0444 (0.0497)  loss_objectness: 0.0015 (0.0324)  loss_rpn_box_reg: 0.0031 (0.0077)  time: 0.1282  data: 0.0348  max mem: 4294\n",
      "Epoch: [1]  [ 3500/12099]  eta: 0:19:41  lr: 0.000300  loss: 0.1357 (0.1188)  loss_classifier: 0.0234 (0.0289)  loss_box_reg: 0.0457 (0.0497)  loss_objectness: 0.0285 (0.0325)  loss_rpn_box_reg: 0.0058 (0.0077)  time: 0.1330  data: 0.0364  max mem: 4294\n",
      "Epoch: [1]  [ 3600/12099]  eta: 0:19:26  lr: 0.000300  loss: 0.1092 (0.1188)  loss_classifier: 0.0250 (0.0289)  loss_box_reg: 0.0435 (0.0497)  loss_objectness: 0.0127 (0.0324)  loss_rpn_box_reg: 0.0025 (0.0078)  time: 0.1299  data: 0.0365  max mem: 4294\n",
      "Epoch: [1]  [ 3700/12099]  eta: 0:19:15  lr: 0.000300  loss: 0.0726 (0.1187)  loss_classifier: 0.0176 (0.0287)  loss_box_reg: 0.0417 (0.0497)  loss_objectness: 0.0028 (0.0325)  loss_rpn_box_reg: 0.0022 (0.0078)  time: 0.1591  data: 0.0547  max mem: 4294\n",
      "Epoch: [1]  [ 3800/12099]  eta: 0:19:01  lr: 0.000300  loss: 0.1058 (0.1187)  loss_classifier: 0.0214 (0.0287)  loss_box_reg: 0.0477 (0.0496)  loss_objectness: 0.0184 (0.0327)  loss_rpn_box_reg: 0.0040 (0.0079)  time: 0.1440  data: 0.0444  max mem: 4294\n",
      "Epoch: [1]  [ 3900/12099]  eta: 0:18:47  lr: 0.000300  loss: 0.1099 (0.1186)  loss_classifier: 0.0238 (0.0286)  loss_box_reg: 0.0385 (0.0495)  loss_objectness: 0.0302 (0.0326)  loss_rpn_box_reg: 0.0034 (0.0078)  time: 0.1381  data: 0.0388  max mem: 4294\n",
      "Epoch: [1]  [ 4000/12099]  eta: 0:18:32  lr: 0.000300  loss: 0.1138 (0.1187)  loss_classifier: 0.0190 (0.0286)  loss_box_reg: 0.0411 (0.0495)  loss_objectness: 0.0114 (0.0326)  loss_rpn_box_reg: 0.0024 (0.0079)  time: 0.1334  data: 0.0394  max mem: 4294\n",
      "Epoch: [1]  [ 4100/12099]  eta: 0:18:18  lr: 0.000300  loss: 0.1129 (0.1187)  loss_classifier: 0.0282 (0.0286)  loss_box_reg: 0.0452 (0.0495)  loss_objectness: 0.0150 (0.0326)  loss_rpn_box_reg: 0.0030 (0.0080)  time: 0.1330  data: 0.0367  max mem: 4294\n",
      "Epoch: [1]  [ 4200/12099]  eta: 0:18:03  lr: 0.000300  loss: 0.0892 (0.1189)  loss_classifier: 0.0180 (0.0285)  loss_box_reg: 0.0408 (0.0494)  loss_objectness: 0.0080 (0.0329)  loss_rpn_box_reg: 0.0024 (0.0080)  time: 0.1288  data: 0.0345  max mem: 4294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1]  [ 4300/12099]  eta: 0:17:49  lr: 0.000300  loss: 0.0877 (0.1188)  loss_classifier: 0.0216 (0.0286)  loss_box_reg: 0.0344 (0.0494)  loss_objectness: 0.0121 (0.0329)  loss_rpn_box_reg: 0.0029 (0.0079)  time: 0.1461  data: 0.0437  max mem: 4294\n",
      "Epoch: [1]  [ 4400/12099]  eta: 0:17:35  lr: 0.000300  loss: 0.0962 (0.1192)  loss_classifier: 0.0150 (0.0287)  loss_box_reg: 0.0375 (0.0495)  loss_objectness: 0.0194 (0.0332)  loss_rpn_box_reg: 0.0036 (0.0079)  time: 0.1325  data: 0.0359  max mem: 4294\n",
      "Epoch: [1]  [ 4500/12099]  eta: 0:17:20  lr: 0.000300  loss: 0.1093 (0.1195)  loss_classifier: 0.0248 (0.0287)  loss_box_reg: 0.0423 (0.0494)  loss_objectness: 0.0393 (0.0335)  loss_rpn_box_reg: 0.0032 (0.0079)  time: 0.1312  data: 0.0365  max mem: 4294\n",
      "Epoch: [1]  [ 4600/12099]  eta: 0:17:07  lr: 0.000300  loss: 0.0978 (0.1197)  loss_classifier: 0.0211 (0.0288)  loss_box_reg: 0.0330 (0.0495)  loss_objectness: 0.0061 (0.0336)  loss_rpn_box_reg: 0.0030 (0.0079)  time: 0.1299  data: 0.0354  max mem: 4294\n",
      "Epoch: [1]  [ 4700/12099]  eta: 0:16:52  lr: 0.000300  loss: 0.0866 (0.1196)  loss_classifier: 0.0158 (0.0288)  loss_box_reg: 0.0275 (0.0495)  loss_objectness: 0.0056 (0.0334)  loss_rpn_box_reg: 0.0022 (0.0079)  time: 0.1299  data: 0.0359  max mem: 4294\n",
      "Epoch: [1]  [ 4800/12099]  eta: 0:16:38  lr: 0.000300  loss: 0.1081 (0.1195)  loss_classifier: 0.0195 (0.0287)  loss_box_reg: 0.0471 (0.0495)  loss_objectness: 0.0279 (0.0334)  loss_rpn_box_reg: 0.0046 (0.0079)  time: 0.1286  data: 0.0345  max mem: 4294\n",
      "Epoch: [1]  [ 4900/12099]  eta: 0:16:24  lr: 0.000300  loss: 0.1018 (0.1196)  loss_classifier: 0.0196 (0.0287)  loss_box_reg: 0.0474 (0.0495)  loss_objectness: 0.0115 (0.0334)  loss_rpn_box_reg: 0.0037 (0.0079)  time: 0.1311  data: 0.0351  max mem: 4294\n",
      "Epoch: [1]  [ 5000/12099]  eta: 0:16:11  lr: 0.000300  loss: 0.0950 (0.1196)  loss_classifier: 0.0248 (0.0287)  loss_box_reg: 0.0437 (0.0495)  loss_objectness: 0.0090 (0.0335)  loss_rpn_box_reg: 0.0037 (0.0079)  time: 0.1274  data: 0.0356  max mem: 4294\n",
      "Epoch: [1]  [ 5100/12099]  eta: 0:15:57  lr: 0.000300  loss: 0.1017 (0.1195)  loss_classifier: 0.0237 (0.0287)  loss_box_reg: 0.0351 (0.0495)  loss_objectness: 0.0057 (0.0334)  loss_rpn_box_reg: 0.0024 (0.0079)  time: 0.1507  data: 0.0472  max mem: 4294\n",
      "Epoch: [1]  [ 5200/12099]  eta: 0:15:48  lr: 0.000300  loss: 0.0838 (0.1196)  loss_classifier: 0.0198 (0.0287)  loss_box_reg: 0.0446 (0.0494)  loss_objectness: 0.0040 (0.0335)  loss_rpn_box_reg: 0.0033 (0.0080)  time: 0.1508  data: 0.0430  max mem: 4294\n",
      "Epoch: [1]  [ 5300/12099]  eta: 0:15:36  lr: 0.000300  loss: 0.1025 (0.1196)  loss_classifier: 0.0236 (0.0286)  loss_box_reg: 0.0444 (0.0494)  loss_objectness: 0.0078 (0.0336)  loss_rpn_box_reg: 0.0040 (0.0080)  time: 0.1414  data: 0.0404  max mem: 4294\n",
      "Epoch: [1]  [ 5400/12099]  eta: 0:15:24  lr: 0.000300  loss: 0.1067 (0.1196)  loss_classifier: 0.0216 (0.0287)  loss_box_reg: 0.0495 (0.0494)  loss_objectness: 0.0065 (0.0335)  loss_rpn_box_reg: 0.0022 (0.0080)  time: 0.1661  data: 0.0544  max mem: 4294\n",
      "Epoch: [1]  [ 5500/12099]  eta: 0:15:11  lr: 0.000300  loss: 0.0922 (0.1195)  loss_classifier: 0.0189 (0.0286)  loss_box_reg: 0.0383 (0.0494)  loss_objectness: 0.0055 (0.0335)  loss_rpn_box_reg: 0.0022 (0.0080)  time: 0.1323  data: 0.0370  max mem: 4294\n",
      "Epoch: [1]  [ 5600/12099]  eta: 0:14:58  lr: 0.000300  loss: 0.0814 (0.1194)  loss_classifier: 0.0184 (0.0286)  loss_box_reg: 0.0440 (0.0494)  loss_objectness: 0.0027 (0.0335)  loss_rpn_box_reg: 0.0016 (0.0079)  time: 0.1388  data: 0.0409  max mem: 4294\n",
      "Epoch: [1]  [ 5700/12099]  eta: 0:14:43  lr: 0.000300  loss: 0.1076 (0.1194)  loss_classifier: 0.0230 (0.0286)  loss_box_reg: 0.0452 (0.0494)  loss_objectness: 0.0045 (0.0335)  loss_rpn_box_reg: 0.0029 (0.0080)  time: 0.1319  data: 0.0364  max mem: 4294\n",
      "Epoch: [1]  [ 5800/12099]  eta: 0:14:30  lr: 0.000300  loss: 0.1135 (0.1194)  loss_classifier: 0.0228 (0.0286)  loss_box_reg: 0.0470 (0.0494)  loss_objectness: 0.0295 (0.0334)  loss_rpn_box_reg: 0.0046 (0.0080)  time: 0.1480  data: 0.0425  max mem: 4294\n",
      "Epoch: [1]  [ 5900/12099]  eta: 0:14:18  lr: 0.000300  loss: 0.0882 (0.1196)  loss_classifier: 0.0205 (0.0287)  loss_box_reg: 0.0391 (0.0496)  loss_objectness: 0.0051 (0.0334)  loss_rpn_box_reg: 0.0015 (0.0080)  time: 0.1427  data: 0.0408  max mem: 4294\n",
      "Epoch: [1]  [ 6000/12099]  eta: 0:14:05  lr: 0.000300  loss: 0.1348 (0.1200)  loss_classifier: 0.0246 (0.0288)  loss_box_reg: 0.0534 (0.0497)  loss_objectness: 0.0146 (0.0335)  loss_rpn_box_reg: 0.0031 (0.0080)  time: 0.1621  data: 0.0519  max mem: 4294\n",
      "Epoch: [1]  [ 6100/12099]  eta: 0:13:52  lr: 0.000300  loss: 0.0997 (0.1202)  loss_classifier: 0.0217 (0.0289)  loss_box_reg: 0.0421 (0.0497)  loss_objectness: 0.0122 (0.0336)  loss_rpn_box_reg: 0.0023 (0.0080)  time: 0.1442  data: 0.0418  max mem: 4294\n",
      "Epoch: [1]  [ 6200/12099]  eta: 0:13:38  lr: 0.000300  loss: 0.1016 (0.1201)  loss_classifier: 0.0273 (0.0289)  loss_box_reg: 0.0452 (0.0497)  loss_objectness: 0.0066 (0.0335)  loss_rpn_box_reg: 0.0027 (0.0079)  time: 0.1646  data: 0.0509  max mem: 4294\n",
      "Epoch: [1]  [ 6300/12099]  eta: 0:13:26  lr: 0.000300  loss: 0.0866 (0.1201)  loss_classifier: 0.0196 (0.0289)  loss_box_reg: 0.0461 (0.0498)  loss_objectness: 0.0044 (0.0335)  loss_rpn_box_reg: 0.0023 (0.0079)  time: 0.1517  data: 0.0462  max mem: 4294\n",
      "Epoch: [1]  [ 6400/12099]  eta: 0:13:14  lr: 0.000300  loss: 0.1068 (0.1202)  loss_classifier: 0.0237 (0.0289)  loss_box_reg: 0.0386 (0.0498)  loss_objectness: 0.0118 (0.0336)  loss_rpn_box_reg: 0.0025 (0.0079)  time: 0.1631  data: 0.0538  max mem: 4294\n",
      "Epoch: [1]  [ 6500/12099]  eta: 0:13:00  lr: 0.000300  loss: 0.1211 (0.1202)  loss_classifier: 0.0227 (0.0290)  loss_box_reg: 0.0438 (0.0498)  loss_objectness: 0.0177 (0.0336)  loss_rpn_box_reg: 0.0028 (0.0079)  time: 0.1405  data: 0.0398  max mem: 4294\n",
      "Epoch: [1]  [ 6600/12099]  eta: 0:12:47  lr: 0.000300  loss: 0.0780 (0.1202)  loss_classifier: 0.0208 (0.0290)  loss_box_reg: 0.0377 (0.0498)  loss_objectness: 0.0035 (0.0335)  loss_rpn_box_reg: 0.0026 (0.0079)  time: 0.1712  data: 0.0559  max mem: 4294\n",
      "Epoch: [1]  [ 6700/12099]  eta: 0:12:34  lr: 0.000300  loss: 0.0890 (0.1204)  loss_classifier: 0.0216 (0.0290)  loss_box_reg: 0.0366 (0.0498)  loss_objectness: 0.0132 (0.0337)  loss_rpn_box_reg: 0.0032 (0.0079)  time: 0.1615  data: 0.0473  max mem: 4294\n",
      "Epoch: [1]  [ 6800/12099]  eta: 0:12:20  lr: 0.000300  loss: 0.0889 (0.1204)  loss_classifier: 0.0207 (0.0290)  loss_box_reg: 0.0419 (0.0498)  loss_objectness: 0.0084 (0.0337)  loss_rpn_box_reg: 0.0021 (0.0079)  time: 0.1450  data: 0.0415  max mem: 4294\n",
      "Epoch: [1]  [ 6900/12099]  eta: 0:12:07  lr: 0.000300  loss: 0.1225 (0.1206)  loss_classifier: 0.0315 (0.0291)  loss_box_reg: 0.0570 (0.0498)  loss_objectness: 0.0228 (0.0338)  loss_rpn_box_reg: 0.0032 (0.0079)  time: 0.1362  data: 0.0385  max mem: 4294\n",
      "Epoch: [1]  [ 7000/12099]  eta: 0:11:54  lr: 0.000300  loss: 0.0783 (0.1206)  loss_classifier: 0.0209 (0.0290)  loss_box_reg: 0.0383 (0.0498)  loss_objectness: 0.0021 (0.0338)  loss_rpn_box_reg: 0.0024 (0.0079)  time: 0.1813  data: 0.0607  max mem: 4294\n",
      "Epoch: [1]  [ 7100/12099]  eta: 0:11:40  lr: 0.000300  loss: 0.1091 (0.1207)  loss_classifier: 0.0250 (0.0291)  loss_box_reg: 0.0562 (0.0498)  loss_objectness: 0.0126 (0.0339)  loss_rpn_box_reg: 0.0029 (0.0079)  time: 0.1333  data: 0.0396  max mem: 4294\n",
      "Epoch: [1]  [ 7200/12099]  eta: 0:11:26  lr: 0.000300  loss: 0.1107 (0.1206)  loss_classifier: 0.0243 (0.0291)  loss_box_reg: 0.0437 (0.0499)  loss_objectness: 0.0155 (0.0338)  loss_rpn_box_reg: 0.0027 (0.0079)  time: 0.1626  data: 0.0518  max mem: 4294\n",
      "Epoch: [1]  [ 7300/12099]  eta: 0:11:12  lr: 0.000300  loss: 0.1275 (0.1208)  loss_classifier: 0.0239 (0.0291)  loss_box_reg: 0.0432 (0.0499)  loss_objectness: 0.0136 (0.0339)  loss_rpn_box_reg: 0.0042 (0.0079)  time: 0.1344  data: 0.0382  max mem: 4294\n",
      "Epoch: [1]  [ 7400/12099]  eta: 0:10:58  lr: 0.000300  loss: 0.1035 (0.1208)  loss_classifier: 0.0226 (0.0291)  loss_box_reg: 0.0380 (0.0498)  loss_objectness: 0.0055 (0.0340)  loss_rpn_box_reg: 0.0029 (0.0079)  time: 0.1316  data: 0.0360  max mem: 4294\n",
      "Epoch: [1]  [ 7500/12099]  eta: 0:10:44  lr: 0.000300  loss: 0.0908 (0.1207)  loss_classifier: 0.0180 (0.0291)  loss_box_reg: 0.0290 (0.0498)  loss_objectness: 0.0031 (0.0339)  loss_rpn_box_reg: 0.0016 (0.0079)  time: 0.1519  data: 0.0492  max mem: 4294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1]  [ 7600/12099]  eta: 0:10:31  lr: 0.000300  loss: 0.0954 (0.1206)  loss_classifier: 0.0219 (0.0291)  loss_box_reg: 0.0377 (0.0498)  loss_objectness: 0.0055 (0.0339)  loss_rpn_box_reg: 0.0022 (0.0079)  time: 0.1579  data: 0.0480  max mem: 4294\n",
      "Epoch: [1]  [ 7700/12099]  eta: 0:10:18  lr: 0.000300  loss: 0.1177 (0.1208)  loss_classifier: 0.0194 (0.0291)  loss_box_reg: 0.0453 (0.0498)  loss_objectness: 0.0078 (0.0340)  loss_rpn_box_reg: 0.0074 (0.0079)  time: 0.1435  data: 0.0418  max mem: 4294\n",
      "Epoch: [1]  [ 7800/12099]  eta: 0:10:03  lr: 0.000300  loss: 0.1277 (0.1207)  loss_classifier: 0.0348 (0.0290)  loss_box_reg: 0.0413 (0.0498)  loss_objectness: 0.0236 (0.0339)  loss_rpn_box_reg: 0.0029 (0.0079)  time: 0.1289  data: 0.0352  max mem: 4294\n",
      "Epoch: [1]  [ 7900/12099]  eta: 0:09:49  lr: 0.000300  loss: 0.1136 (0.1207)  loss_classifier: 0.0228 (0.0290)  loss_box_reg: 0.0343 (0.0498)  loss_objectness: 0.0052 (0.0340)  loss_rpn_box_reg: 0.0029 (0.0079)  time: 0.1287  data: 0.0358  max mem: 4294\n",
      "Epoch: [1]  [ 8000/12099]  eta: 0:09:35  lr: 0.000300  loss: 0.0972 (0.1205)  loss_classifier: 0.0248 (0.0290)  loss_box_reg: 0.0501 (0.0497)  loss_objectness: 0.0049 (0.0339)  loss_rpn_box_reg: 0.0026 (0.0079)  time: 0.1380  data: 0.0387  max mem: 4294\n",
      "Epoch: [1]  [ 8100/12099]  eta: 0:09:21  lr: 0.000300  loss: 0.1050 (0.1204)  loss_classifier: 0.0204 (0.0290)  loss_box_reg: 0.0296 (0.0497)  loss_objectness: 0.0048 (0.0338)  loss_rpn_box_reg: 0.0034 (0.0079)  time: 0.1359  data: 0.0390  max mem: 4294\n",
      "Epoch: [1]  [ 8200/12099]  eta: 0:09:06  lr: 0.000300  loss: 0.1021 (0.1203)  loss_classifier: 0.0205 (0.0289)  loss_box_reg: 0.0445 (0.0497)  loss_objectness: 0.0090 (0.0338)  loss_rpn_box_reg: 0.0048 (0.0079)  time: 0.1369  data: 0.0375  max mem: 4294\n",
      "Epoch: [1]  [ 8300/12099]  eta: 0:08:53  lr: 0.000300  loss: 0.0848 (0.1202)  loss_classifier: 0.0196 (0.0289)  loss_box_reg: 0.0431 (0.0497)  loss_objectness: 0.0013 (0.0337)  loss_rpn_box_reg: 0.0029 (0.0079)  time: 0.1420  data: 0.0414  max mem: 4294\n",
      "Epoch: [1]  [ 8400/12099]  eta: 0:08:40  lr: 0.000300  loss: 0.0985 (0.1202)  loss_classifier: 0.0161 (0.0289)  loss_box_reg: 0.0431 (0.0496)  loss_objectness: 0.0096 (0.0338)  loss_rpn_box_reg: 0.0037 (0.0079)  time: 0.1463  data: 0.0439  max mem: 4294\n",
      "Epoch: [1]  [ 8500/12099]  eta: 0:08:26  lr: 0.000300  loss: 0.1063 (0.1202)  loss_classifier: 0.0232 (0.0289)  loss_box_reg: 0.0385 (0.0496)  loss_objectness: 0.0287 (0.0338)  loss_rpn_box_reg: 0.0024 (0.0079)  time: 0.1347  data: 0.0378  max mem: 4294\n",
      "Epoch: [1]  [ 8600/12099]  eta: 0:08:12  lr: 0.000300  loss: 0.0915 (0.1202)  loss_classifier: 0.0208 (0.0289)  loss_box_reg: 0.0443 (0.0496)  loss_objectness: 0.0040 (0.0338)  loss_rpn_box_reg: 0.0028 (0.0079)  time: 0.1380  data: 0.0392  max mem: 4294\n",
      "Epoch: [1]  [ 8700/12099]  eta: 0:07:58  lr: 0.000300  loss: 0.0956 (0.1201)  loss_classifier: 0.0263 (0.0289)  loss_box_reg: 0.0450 (0.0495)  loss_objectness: 0.0081 (0.0338)  loss_rpn_box_reg: 0.0029 (0.0079)  time: 0.1623  data: 0.0475  max mem: 4294\n",
      "Epoch: [1]  [ 8800/12099]  eta: 0:07:44  lr: 0.000300  loss: 0.0887 (0.1201)  loss_classifier: 0.0265 (0.0290)  loss_box_reg: 0.0333 (0.0495)  loss_objectness: 0.0052 (0.0337)  loss_rpn_box_reg: 0.0027 (0.0079)  time: 0.1541  data: 0.0447  max mem: 4294\n",
      "Epoch: [1]  [ 8900/12099]  eta: 0:07:31  lr: 0.000300  loss: 0.0889 (0.1201)  loss_classifier: 0.0185 (0.0290)  loss_box_reg: 0.0472 (0.0496)  loss_objectness: 0.0134 (0.0338)  loss_rpn_box_reg: 0.0024 (0.0079)  time: 0.1468  data: 0.0416  max mem: 4294\n",
      "Epoch: [1]  [ 9000/12099]  eta: 0:07:17  lr: 0.000300  loss: 0.1257 (0.1201)  loss_classifier: 0.0258 (0.0290)  loss_box_reg: 0.0547 (0.0495)  loss_objectness: 0.0069 (0.0337)  loss_rpn_box_reg: 0.0033 (0.0079)  time: 0.1563  data: 0.0474  max mem: 4294\n",
      "Epoch: [1]  [ 9100/12099]  eta: 0:07:03  lr: 0.000300  loss: 0.1372 (0.1201)  loss_classifier: 0.0237 (0.0290)  loss_box_reg: 0.0402 (0.0495)  loss_objectness: 0.0238 (0.0338)  loss_rpn_box_reg: 0.0033 (0.0079)  time: 0.1633  data: 0.0495  max mem: 4294\n",
      "Epoch: [1]  [ 9200/12099]  eta: 0:06:49  lr: 0.000300  loss: 0.1164 (0.1200)  loss_classifier: 0.0303 (0.0289)  loss_box_reg: 0.0531 (0.0495)  loss_objectness: 0.0098 (0.0338)  loss_rpn_box_reg: 0.0036 (0.0078)  time: 0.1310  data: 0.0369  max mem: 4294\n",
      "Epoch: [1]  [ 9300/12099]  eta: 0:06:35  lr: 0.000300  loss: 0.0925 (0.1200)  loss_classifier: 0.0201 (0.0289)  loss_box_reg: 0.0404 (0.0495)  loss_objectness: 0.0072 (0.0338)  loss_rpn_box_reg: 0.0026 (0.0079)  time: 0.1350  data: 0.0389  max mem: 4294\n",
      "Epoch: [1]  [ 9400/12099]  eta: 0:06:21  lr: 0.000300  loss: 0.1327 (0.1200)  loss_classifier: 0.0220 (0.0289)  loss_box_reg: 0.0451 (0.0495)  loss_objectness: 0.0192 (0.0337)  loss_rpn_box_reg: 0.0025 (0.0079)  time: 0.1777  data: 0.0548  max mem: 4294\n",
      "Epoch: [1]  [ 9500/12099]  eta: 0:06:08  lr: 0.000300  loss: 0.1106 (0.1200)  loss_classifier: 0.0278 (0.0289)  loss_box_reg: 0.0550 (0.0495)  loss_objectness: 0.0159 (0.0337)  loss_rpn_box_reg: 0.0030 (0.0079)  time: 0.1399  data: 0.0407  max mem: 4294\n",
      "Epoch: [1]  [ 9600/12099]  eta: 0:05:53  lr: 0.000300  loss: 0.0720 (0.1199)  loss_classifier: 0.0125 (0.0289)  loss_box_reg: 0.0338 (0.0495)  loss_objectness: 0.0042 (0.0337)  loss_rpn_box_reg: 0.0012 (0.0079)  time: 0.1403  data: 0.0409  max mem: 4294\n",
      "Epoch: [1]  [ 9700/12099]  eta: 0:05:39  lr: 0.000300  loss: 0.1097 (0.1198)  loss_classifier: 0.0219 (0.0289)  loss_box_reg: 0.0436 (0.0495)  loss_objectness: 0.0087 (0.0337)  loss_rpn_box_reg: 0.0020 (0.0079)  time: 0.1540  data: 0.0443  max mem: 4294\n",
      "Epoch: [1]  [ 9800/12099]  eta: 0:05:25  lr: 0.000300  loss: 0.0861 (0.1198)  loss_classifier: 0.0260 (0.0289)  loss_box_reg: 0.0375 (0.0495)  loss_objectness: 0.0029 (0.0336)  loss_rpn_box_reg: 0.0027 (0.0079)  time: 0.1309  data: 0.0386  max mem: 4294\n",
      "Epoch: [1]  [ 9900/12099]  eta: 0:05:11  lr: 0.000300  loss: 0.1024 (0.1198)  loss_classifier: 0.0243 (0.0289)  loss_box_reg: 0.0373 (0.0495)  loss_objectness: 0.0062 (0.0336)  loss_rpn_box_reg: 0.0040 (0.0079)  time: 0.1275  data: 0.0362  max mem: 4294\n",
      "Epoch: [1]  [10000/12099]  eta: 0:04:57  lr: 0.000300  loss: 0.0881 (0.1198)  loss_classifier: 0.0221 (0.0289)  loss_box_reg: 0.0497 (0.0495)  loss_objectness: 0.0034 (0.0336)  loss_rpn_box_reg: 0.0013 (0.0079)  time: 0.1259  data: 0.0354  max mem: 4294\n",
      "Epoch: [1]  [10100/12099]  eta: 0:04:42  lr: 0.000300  loss: 0.1273 (0.1199)  loss_classifier: 0.0243 (0.0289)  loss_box_reg: 0.0448 (0.0495)  loss_objectness: 0.0055 (0.0336)  loss_rpn_box_reg: 0.0048 (0.0079)  time: 0.1273  data: 0.0370  max mem: 4294\n",
      "Epoch: [1]  [10200/12099]  eta: 0:04:28  lr: 0.000300  loss: 0.0843 (0.1199)  loss_classifier: 0.0197 (0.0288)  loss_box_reg: 0.0372 (0.0495)  loss_objectness: 0.0154 (0.0336)  loss_rpn_box_reg: 0.0024 (0.0079)  time: 0.1211  data: 0.0331  max mem: 4294\n",
      "Epoch: [1]  [10300/12099]  eta: 0:04:13  lr: 0.000300  loss: 0.0860 (0.1199)  loss_classifier: 0.0220 (0.0289)  loss_box_reg: 0.0530 (0.0496)  loss_objectness: 0.0109 (0.0336)  loss_rpn_box_reg: 0.0021 (0.0078)  time: 0.1211  data: 0.0321  max mem: 4294\n",
      "Epoch: [1]  [10400/12099]  eta: 0:03:59  lr: 0.000300  loss: 0.1060 (0.1199)  loss_classifier: 0.0228 (0.0289)  loss_box_reg: 0.0591 (0.0495)  loss_objectness: 0.0086 (0.0336)  loss_rpn_box_reg: 0.0026 (0.0078)  time: 0.1200  data: 0.0327  max mem: 4294\n",
      "Epoch: [1]  [10500/12099]  eta: 0:03:45  lr: 0.000300  loss: 0.1024 (0.1198)  loss_classifier: 0.0211 (0.0289)  loss_box_reg: 0.0504 (0.0496)  loss_objectness: 0.0077 (0.0336)  loss_rpn_box_reg: 0.0043 (0.0078)  time: 0.1364  data: 0.0393  max mem: 4294\n",
      "Epoch: [1]  [10600/12099]  eta: 0:03:30  lr: 0.000300  loss: 0.0887 (0.1200)  loss_classifier: 0.0224 (0.0289)  loss_box_reg: 0.0443 (0.0496)  loss_objectness: 0.0224 (0.0337)  loss_rpn_box_reg: 0.0075 (0.0078)  time: 0.1232  data: 0.0343  max mem: 4294\n",
      "Epoch: [1]  [10700/12099]  eta: 0:03:16  lr: 0.000300  loss: 0.0966 (0.1199)  loss_classifier: 0.0219 (0.0289)  loss_box_reg: 0.0377 (0.0495)  loss_objectness: 0.0148 (0.0336)  loss_rpn_box_reg: 0.0023 (0.0079)  time: 0.1203  data: 0.0338  max mem: 4294\n",
      "Epoch: [1]  [10800/12099]  eta: 0:03:02  lr: 0.000300  loss: 0.0902 (0.1198)  loss_classifier: 0.0220 (0.0289)  loss_box_reg: 0.0495 (0.0495)  loss_objectness: 0.0033 (0.0336)  loss_rpn_box_reg: 0.0020 (0.0078)  time: 0.1560  data: 0.0517  max mem: 4294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1]  [10900/12099]  eta: 0:02:48  lr: 0.000300  loss: 0.1210 (0.1199)  loss_classifier: 0.0264 (0.0289)  loss_box_reg: 0.0423 (0.0496)  loss_objectness: 0.0104 (0.0336)  loss_rpn_box_reg: 0.0036 (0.0078)  time: 0.1290  data: 0.0367  max mem: 4294\n",
      "Epoch: [1]  [11000/12099]  eta: 0:02:34  lr: 0.000300  loss: 0.0918 (0.1199)  loss_classifier: 0.0203 (0.0289)  loss_box_reg: 0.0334 (0.0496)  loss_objectness: 0.0052 (0.0336)  loss_rpn_box_reg: 0.0022 (0.0078)  time: 0.1299  data: 0.0369  max mem: 4294\n",
      "Epoch: [1]  [11100/12099]  eta: 0:02:20  lr: 0.000300  loss: 0.0806 (0.1198)  loss_classifier: 0.0238 (0.0289)  loss_box_reg: 0.0334 (0.0496)  loss_objectness: 0.0014 (0.0335)  loss_rpn_box_reg: 0.0022 (0.0078)  time: 0.1617  data: 0.0572  max mem: 4294\n",
      "Epoch: [1]  [11200/12099]  eta: 0:02:06  lr: 0.000300  loss: 0.1000 (0.1197)  loss_classifier: 0.0205 (0.0289)  loss_box_reg: 0.0489 (0.0495)  loss_objectness: 0.0217 (0.0335)  loss_rpn_box_reg: 0.0011 (0.0078)  time: 0.1446  data: 0.0476  max mem: 4294\n",
      "Epoch: [1]  [11300/12099]  eta: 0:01:52  lr: 0.000300  loss: 0.0865 (0.1197)  loss_classifier: 0.0223 (0.0289)  loss_box_reg: 0.0363 (0.0496)  loss_objectness: 0.0058 (0.0335)  loss_rpn_box_reg: 0.0021 (0.0078)  time: 0.1359  data: 0.0386  max mem: 4294\n",
      "Epoch: [1]  [11400/12099]  eta: 0:01:38  lr: 0.000300  loss: 0.1091 (0.1197)  loss_classifier: 0.0231 (0.0289)  loss_box_reg: 0.0263 (0.0496)  loss_objectness: 0.0086 (0.0335)  loss_rpn_box_reg: 0.0023 (0.0078)  time: 0.1243  data: 0.0339  max mem: 4294\n",
      "Epoch: [1]  [11500/12099]  eta: 0:01:24  lr: 0.000300  loss: 0.0805 (0.1196)  loss_classifier: 0.0194 (0.0289)  loss_box_reg: 0.0366 (0.0495)  loss_objectness: 0.0075 (0.0334)  loss_rpn_box_reg: 0.0018 (0.0078)  time: 0.1264  data: 0.0348  max mem: 4294\n",
      "Epoch: [1]  [11600/12099]  eta: 0:01:09  lr: 0.000300  loss: 0.1221 (0.1197)  loss_classifier: 0.0242 (0.0289)  loss_box_reg: 0.0398 (0.0495)  loss_objectness: 0.0395 (0.0335)  loss_rpn_box_reg: 0.0027 (0.0078)  time: 0.1354  data: 0.0418  max mem: 4294\n",
      "Epoch: [1]  [11700/12099]  eta: 0:00:56  lr: 0.000300  loss: 0.1072 (0.1197)  loss_classifier: 0.0219 (0.0289)  loss_box_reg: 0.0404 (0.0495)  loss_objectness: 0.0031 (0.0335)  loss_rpn_box_reg: 0.0028 (0.0078)  time: 0.1508  data: 0.0446  max mem: 4294\n",
      "Epoch: [1]  [11800/12099]  eta: 0:00:41  lr: 0.000300  loss: 0.0737 (0.1197)  loss_classifier: 0.0263 (0.0289)  loss_box_reg: 0.0421 (0.0495)  loss_objectness: 0.0033 (0.0335)  loss_rpn_box_reg: 0.0019 (0.0078)  time: 0.1293  data: 0.0347  max mem: 4294\n",
      "Epoch: [1]  [11900/12099]  eta: 0:00:27  lr: 0.000300  loss: 0.1013 (0.1196)  loss_classifier: 0.0252 (0.0289)  loss_box_reg: 0.0540 (0.0495)  loss_objectness: 0.0023 (0.0334)  loss_rpn_box_reg: 0.0027 (0.0078)  time: 0.1433  data: 0.0410  max mem: 4294\n",
      "Epoch: [1]  [12000/12099]  eta: 0:00:13  lr: 0.000300  loss: 0.1025 (0.1196)  loss_classifier: 0.0165 (0.0289)  loss_box_reg: 0.0259 (0.0495)  loss_objectness: 0.0046 (0.0334)  loss_rpn_box_reg: 0.0031 (0.0079)  time: 0.1333  data: 0.0356  max mem: 4294\n",
      "Epoch: [1]  [12098/12099]  eta: 0:00:00  lr: 0.000300  loss: 0.0668 (0.1195)  loss_classifier: 0.0187 (0.0289)  loss_box_reg: 0.0360 (0.0495)  loss_objectness: 0.0045 (0.0333)  loss_rpn_box_reg: 0.0022 (0.0079)  time: 0.1372  data: 0.0384  max mem: 4294\n",
      "Epoch: [1] Total time: 0:28:17 (0.1403 s / it)\n",
      "Epoch: [2]  [    0/12099]  eta: 0:30:51  lr: 0.000300  loss: 0.0796 (0.0796)  loss_classifier: 0.0170 (0.0170)  loss_box_reg: 0.0600 (0.0600)  loss_objectness: 0.0004 (0.0004)  loss_rpn_box_reg: 0.0022 (0.0022)  time: 0.1530  data: 0.0395  max mem: 4294\n",
      "Epoch: [2]  [  100/12099]  eta: 0:25:49  lr: 0.000300  loss: 0.0949 (0.1185)  loss_classifier: 0.0228 (0.0286)  loss_box_reg: 0.0528 (0.0481)  loss_objectness: 0.0040 (0.0307)  loss_rpn_box_reg: 0.0027 (0.0111)  time: 0.1162  data: 0.0318  max mem: 4294\n",
      "Epoch: [2]  [  200/12099]  eta: 0:24:31  lr: 0.000300  loss: 0.0981 (0.1170)  loss_classifier: 0.0213 (0.0297)  loss_box_reg: 0.0397 (0.0475)  loss_objectness: 0.0042 (0.0313)  loss_rpn_box_reg: 0.0033 (0.0085)  time: 0.1166  data: 0.0320  max mem: 4294\n",
      "Epoch: [2]  [  300/12099]  eta: 0:23:51  lr: 0.000300  loss: 0.1078 (0.1177)  loss_classifier: 0.0224 (0.0297)  loss_box_reg: 0.0560 (0.0492)  loss_objectness: 0.0075 (0.0311)  loss_rpn_box_reg: 0.0025 (0.0076)  time: 0.1164  data: 0.0316  max mem: 4294\n",
      "Epoch: [2]  [  400/12099]  eta: 0:23:25  lr: 0.000300  loss: 0.1063 (0.1170)  loss_classifier: 0.0210 (0.0295)  loss_box_reg: 0.0511 (0.0494)  loss_objectness: 0.0127 (0.0306)  loss_rpn_box_reg: 0.0030 (0.0075)  time: 0.1170  data: 0.0321  max mem: 4294\n",
      "Epoch: [2]  [  500/12099]  eta: 0:23:02  lr: 0.000300  loss: 0.0948 (0.1152)  loss_classifier: 0.0182 (0.0287)  loss_box_reg: 0.0394 (0.0485)  loss_objectness: 0.0039 (0.0305)  loss_rpn_box_reg: 0.0020 (0.0075)  time: 0.1168  data: 0.0314  max mem: 4294\n",
      "Epoch: [2]  [  600/12099]  eta: 0:22:55  lr: 0.000300  loss: 0.0986 (0.1172)  loss_classifier: 0.0276 (0.0289)  loss_box_reg: 0.0417 (0.0486)  loss_objectness: 0.0041 (0.0318)  loss_rpn_box_reg: 0.0029 (0.0078)  time: 0.1215  data: 0.0317  max mem: 4294\n",
      "Epoch: [2]  [  700/12099]  eta: 0:22:46  lr: 0.000300  loss: 0.0946 (0.1161)  loss_classifier: 0.0271 (0.0285)  loss_box_reg: 0.0576 (0.0487)  loss_objectness: 0.0100 (0.0316)  loss_rpn_box_reg: 0.0017 (0.0073)  time: 0.1191  data: 0.0319  max mem: 4294\n",
      "Epoch: [2]  [  800/12099]  eta: 0:22:36  lr: 0.000300  loss: 0.0899 (0.1161)  loss_classifier: 0.0179 (0.0283)  loss_box_reg: 0.0364 (0.0487)  loss_objectness: 0.0032 (0.0316)  loss_rpn_box_reg: 0.0027 (0.0075)  time: 0.1210  data: 0.0328  max mem: 4294\n",
      "Epoch: [2]  [  900/12099]  eta: 0:22:23  lr: 0.000300  loss: 0.0969 (0.1155)  loss_classifier: 0.0256 (0.0280)  loss_box_reg: 0.0376 (0.0484)  loss_objectness: 0.0106 (0.0316)  loss_rpn_box_reg: 0.0026 (0.0075)  time: 0.1195  data: 0.0330  max mem: 4294\n",
      "Epoch: [2]  [ 1000/12099]  eta: 0:22:10  lr: 0.000300  loss: 0.1015 (0.1151)  loss_classifier: 0.0185 (0.0278)  loss_box_reg: 0.0484 (0.0483)  loss_objectness: 0.0355 (0.0314)  loss_rpn_box_reg: 0.0020 (0.0076)  time: 0.1182  data: 0.0316  max mem: 4294\n",
      "Epoch: [2]  [ 1100/12099]  eta: 0:21:59  lr: 0.000300  loss: 0.1042 (0.1149)  loss_classifier: 0.0198 (0.0279)  loss_box_reg: 0.0579 (0.0486)  loss_objectness: 0.0088 (0.0309)  loss_rpn_box_reg: 0.0031 (0.0075)  time: 0.1158  data: 0.0308  max mem: 4294\n",
      "Epoch: [2]  [ 1200/12099]  eta: 0:21:48  lr: 0.000300  loss: 0.0917 (0.1159)  loss_classifier: 0.0209 (0.0279)  loss_box_reg: 0.0392 (0.0484)  loss_objectness: 0.0196 (0.0318)  loss_rpn_box_reg: 0.0031 (0.0077)  time: 0.1227  data: 0.0333  max mem: 4294\n",
      "Epoch: [2]  [ 1300/12099]  eta: 0:21:34  lr: 0.000300  loss: 0.0790 (0.1158)  loss_classifier: 0.0160 (0.0278)  loss_box_reg: 0.0446 (0.0482)  loss_objectness: 0.0030 (0.0320)  loss_rpn_box_reg: 0.0030 (0.0078)  time: 0.1143  data: 0.0303  max mem: 4294\n",
      "Epoch: [2]  [ 1400/12099]  eta: 0:21:22  lr: 0.000300  loss: 0.1090 (0.1161)  loss_classifier: 0.0221 (0.0281)  loss_box_reg: 0.0541 (0.0486)  loss_objectness: 0.0198 (0.0318)  loss_rpn_box_reg: 0.0025 (0.0077)  time: 0.1201  data: 0.0325  max mem: 4294\n",
      "Epoch: [2]  [ 1500/12099]  eta: 0:21:08  lr: 0.000300  loss: 0.0914 (0.1174)  loss_classifier: 0.0197 (0.0279)  loss_box_reg: 0.0326 (0.0484)  loss_objectness: 0.0161 (0.0333)  loss_rpn_box_reg: 0.0029 (0.0078)  time: 0.1144  data: 0.0310  max mem: 4294\n",
      "Epoch: [2]  [ 1600/12099]  eta: 0:20:54  lr: 0.000300  loss: 0.0972 (0.1168)  loss_classifier: 0.0234 (0.0280)  loss_box_reg: 0.0402 (0.0480)  loss_objectness: 0.0123 (0.0330)  loss_rpn_box_reg: 0.0020 (0.0078)  time: 0.1163  data: 0.0316  max mem: 4294\n",
      "Epoch: [2]  [ 1700/12099]  eta: 0:20:41  lr: 0.000300  loss: 0.1127 (0.1171)  loss_classifier: 0.0218 (0.0280)  loss_box_reg: 0.0402 (0.0483)  loss_objectness: 0.0223 (0.0329)  loss_rpn_box_reg: 0.0034 (0.0079)  time: 0.1188  data: 0.0311  max mem: 4294\n",
      "Epoch: [2]  [ 1800/12099]  eta: 0:20:29  lr: 0.000300  loss: 0.1171 (0.1164)  loss_classifier: 0.0187 (0.0279)  loss_box_reg: 0.0286 (0.0481)  loss_objectness: 0.0236 (0.0326)  loss_rpn_box_reg: 0.0043 (0.0079)  time: 0.1204  data: 0.0328  max mem: 4294\n",
      "Epoch: [2]  [ 1900/12099]  eta: 0:20:18  lr: 0.000300  loss: 0.0856 (0.1160)  loss_classifier: 0.0205 (0.0279)  loss_box_reg: 0.0389 (0.0482)  loss_objectness: 0.0050 (0.0320)  loss_rpn_box_reg: 0.0021 (0.0078)  time: 0.1188  data: 0.0313  max mem: 4294\n"
     ]
    }
   ],
   "source": [
    "# TRAIN\n",
    "\n",
    "all_train_logs=[]\n",
    "all_trans_valid_logs=[]\n",
    "all_cis_valid_logs=[]\n",
    "\n",
    "num_epochs = 15\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # train for one epoch, printing every 100 images\n",
    "    train_logs = train_one_epoch(model, optimizer, train_dataloader, device, epoch, print_freq=100)\n",
    "    all_train_logs.append(train_logs)\n",
    "    \n",
    "    # update the learning rate\n",
    "    lr_scheduler.step()\n",
    "    # evaluate on the test dataset\n",
    "\n",
    "    for images, targets in trans_valid_dataloader: # can do batch of 10 prob.\n",
    "        images = [image.to(device) for image in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            trans_loss_dict = model(images, targets)\n",
    "            trans_loss_dict= [{k: loss.to('cpu')} for k, loss in trans_loss_dict.items()]\n",
    "            all_trans_valid_logs.append(trans_loss_dict)\n",
    "\n",
    "\n",
    "    for images, targets in cis_valid_dataloader: # can do batch of 10 prob.\n",
    "        images = [image.to(device) for image in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            cis_loss_dict = model(images, targets)\n",
    "            cis_loss_dict= [{k: loss.to('cpu')} for k, loss in cis_loss_dict.items()]\n",
    "            all_cis_valid_logs.append(cis_loss_dict)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Step1_TransferLearning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Animals",
   "language": "python",
   "name": "animals"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
